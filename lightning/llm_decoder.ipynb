{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, DataLoader2\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torchtext\n",
    "import  torchdata\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = torchtext.datasets.IWSLT2016(root='data',  language_pair=('en', 'fr'))\n",
    "train_dl = DataLoader2(train, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The small farmer in Africa today lives a life without much choice, and therefore without much freedom.\\n',\n",
       " \"Le petit cultivateur d'Afrique aujourd'hui a peu de choix, donc peu de liberté.\\n\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"David Gallo: This is Bill Lange. I'm Dave Gallo.\\n\", 'David Gallo: Voici Bill Lange. Je suis Dave Gallo.\\n')\n",
      "(\"And we're going to tell you some stories from the sea here in video.\\n\", 'Nous allons vous raconter quelques histoires de la mer en vidéo.\\n')\n",
      "(\"We've got some of the most incredible video of Titanic that's ever been seen, and we're not going to show you any of it.\\n\", \"Nous avons des vidéos du Titanic parmi les plus spectaculaires jamais vues. et nous n'allons pas vous en montrer une image.\\n\")\n",
      "(\"The truth of the matter is that the Titanic -- even though it's breaking all sorts of box office records -- it's not the most exciting story from the sea.\\n\", \"La vérité est que le Titanic -- même s'il continue de battre toutes les records de recettes -- n'est pas l'histoire la plus passionnante.\\n\")\n",
      "('And the problem, I think, is that we take the ocean for granted.\\n', \"Le problème, je crois, est qu'on tient l'océan pour acquis.\\n\")\n",
      "('When you think about it, the oceans are 75 percent of the planet.\\n', 'Quand vous y pensez, les océans représentent 75% de la planète.\\n')\n",
      "('Most of the planet is ocean water.\\n', \"La plus grande partie de la planète est d'eau.\\n\")\n",
      "('The average depth is about two miles.\\n', 'La profondeur moyenne est environ 3,2 km.\\n')\n",
      "(\"Part of the problem, I think, is we stand at the beach, or we see images like this of the ocean, and you look out at this great big blue expanse, and it's shimmering and it's moving and there's waves and there's surf and there's tides, but you have no idea for what lies in there.\\n\", \"Une partie du problème, je pense, est qu'en étant sur la plage ou en regardant des images de l'océan, comme celles-ci, on voit cette grande étendue bleue, chatoyante, ça bouge, il y a des vagues, il y a du surf et il y a des marées, mais vous n'avez aucune idée de ce qui s'y cache.\\n\")\n",
      "('And in the oceans, there are the longest mountain ranges on the planet.\\n', 'Il y existe les chaînes de montagnes les plus longues de la planète.\\n')\n",
      "('Most of the animals are in the oceans.\\n', 'La plupart des animaux se trouvent dans les océans.\\n')\n",
      "('Most of the earthquakes and volcanoes are in the sea, at the bottom of the sea.\\n', 'La plupart des tremblements de terre et de volcans se produisent dans la mer - au fond de la mer.\\n')\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iter):\n",
    "    print (batch)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchtext.datasets.IWSLT2016(root='data', split=('train', 'valid', 'test'), language_pair=('de', 'en'), valid_set='tst2013', test_set='tst2014')\n",
    "train, valid, test = data\n",
    "train_dl = DataLoader2(train, batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIWSLT2016\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlanguage_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalid_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tst2013'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtest_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tst2014'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "IWSLT2016 dataset\n",
      "\n",
      ".. warning::\n",
      "\n",
      "    using datapipes is still currently subject to a few caveats. if you wish\n",
      "    to use this dataset with shuffling, multi-processing, or distributed\n",
      "    learning, please see :ref:`this note <datapipes_warnings>` for further\n",
      "    instructions.\n",
      "\n",
      "For additional details refer to https://wit3.fbk.eu/2016-01\n",
      "\n",
      "The available datasets include following:\n",
      "\n",
      "**Language pairs**:\n",
      "\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |\"en\" |\"fr\" |\"de\" |\"cs\" |\"ar\" |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|\"en\" |     |   x |  x  |  x  |  x  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|\"fr\" |  x  |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|\"de\" |  x  |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|\"cs\" |  x  |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|\"ar\" |  x  |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "\n",
      "**valid/test sets**: [\"dev2010\", \"tst2010\", \"tst2011\", \"tst2012\", \"tst2013\", \"tst2014\"]\n",
      "\n",
      "\n",
      "Args:\n",
      "    root: Directory where the datasets are saved. Default: os.path.expanduser('~/.torchtext/cache')\n",
      "    split: split or splits to be returned. Can be a string or tuple of strings. Default: (‘train’, ‘valid’, ‘test’)\n",
      "    language_pair: tuple or list containing src and tgt language\n",
      "    valid_set: a string to identify validation set.\n",
      "    test_set: a string to identify test set.\n",
      "\n",
      ":return: DataPipe that yields tuple of source and target sentences\n",
      ":rtype: (str, str)\n",
      "\n",
      "Examples:\n",
      "    >>> from torchtext.datasets import IWSLT2016\n",
      "    >>> train_iter, valid_iter, test_iter = IWSLT2016()\n",
      "    >>> src_sentence, tgt_sentence = next(iter(train_iter))\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Library/Python/3.9/lib/python/site-packages/torchtext/datasets/iwslt2016.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "torchtext.datasets.IWSLT2016?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data: Tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadError",
     "evalue": "file could not be opened successfully\nThis exception is thrown by __iter__ of TarArchiveLoaderIterDataPipe(datapipe=FileOpenerIterDataPipe, length=-1, mode='r:*')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:540\u001b[0m, in \u001b[0;36mZipperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterators):\n\u001b[1;32m    541\u001b[0m         \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/plain_text_reader.py:133\u001b[0m, in \u001b[0;36mLineReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[Str_Or_Bytes, Tuple[\u001b[39mstr\u001b[39m, Str_Or_Bytes]]]:\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    134\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/utils/common.py:208\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    206\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m         \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m         \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:438\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    439\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/selecting.py:85\u001b[0m, in \u001b[0;36mFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     86\u001b[0m         filtered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returnIfTrue(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:81\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to extract files from corrupted tarfile stream \u001b[39m\u001b[39m{\u001b[39;00mpathname\u001b[39m}\u001b[39;00m\u001b[39m due to: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m, abort!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     82\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:69\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39m# typing.cast is used here to silence mypy's type checker\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     tar \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39;49mopen(fileobj\u001b[39m=\u001b[39;49mcast(Optional[IO[\u001b[39mbytes\u001b[39;49m]], data_stream), mode\u001b[39m=\u001b[39;49mreading_mode)\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m tarinfo \u001b[39min\u001b[39;00m tar:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/tarfile.py:1616\u001b[0m, in \u001b[0;36mTarFile.open\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1616\u001b[0m     \u001b[39mraise\u001b[39;00m ReadError(\u001b[39m\"\u001b[39m\u001b[39mfile could not be opened successfully\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1618\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "\u001b[0;31mReadError\u001b[0m: file could not be opened successfully\nThis exception is thrown by __iter__ of TarArchiveLoaderIterDataPipe(datapipe=FileOpenerIterDataPipe, length=-1, mode='r:*')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_dl))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:43\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/datapipe.py:351\u001b[0m, in \u001b[0;36m_IterDataPipeSerializationWrapper.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 351\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/grouping.py:95\u001b[0m, in \u001b[0;36mBatcherIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[DataChunk]:\n\u001b[1;32m     94\u001b[0m     batch: List \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     96\u001b[0m         batch\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m     97\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/grouping.py:41\u001b[0m, in \u001b[0;36mShardingFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mfor\u001b[39;00m i, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe):\n\u001b[1;32m     42\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_id:\n\u001b[1;32m     43\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:127\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[39myield\u001b[39;00m x\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    128\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_size:\n\u001b[1;32m    129\u001b[0m             idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rng\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:546\u001b[0m, in \u001b[0;36mZipperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39mfor\u001b[39;00m iterator \u001b[39min\u001b[39;00m iterators:\n\u001b[1;32m    545\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 546\u001b[0m         unused \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iterator)\n\u001b[1;32m    547\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:  \u001b[39m# Some iterators may have been invalidated by single iterator constraints\u001b[39;00m\n\u001b[1;32m    548\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/plain_text_reader.py:133\u001b[0m, in \u001b[0;36mLineReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[Str_Or_Bytes, Tuple[\u001b[39mstr\u001b[39m, Str_Or_Bytes]]]:\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    134\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n\u001b[1;32m    135\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mstrip_newline(stream)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/utils/common.py:208\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    206\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:438\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    434\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    439\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    440\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/selecting.py:85\u001b[0m, in \u001b[0;36mFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     86\u001b[0m         filtered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returnIfTrue(data)\n\u001b[1;32m     87\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isNonEmpty(filtered):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:81\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to extract files from corrupted tarfile stream \u001b[39m\u001b[39m{\u001b[39;00mpathname\u001b[39m}\u001b[39;00m\u001b[39m due to: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m, abort!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     82\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_stream, StreamWrapper):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:69\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m     reading_mode \u001b[39m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m     65\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data_stream, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m data_stream\u001b[39m.\u001b[39mseekable()\n\u001b[1;32m     66\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m     \u001b[39m# typing.cast is used here to silence mypy's type checker\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     tar \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39;49mopen(fileobj\u001b[39m=\u001b[39;49mcast(Optional[IO[\u001b[39mbytes\u001b[39;49m]], data_stream), mode\u001b[39m=\u001b[39;49mreading_mode)\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m tarinfo \u001b[39min\u001b[39;00m tar:\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tarinfo\u001b[39m.\u001b[39misfile():\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/tarfile.py:1616\u001b[0m, in \u001b[0;36mTarFile.open\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m                 fileobj\u001b[39m.\u001b[39mseek(saved_pos)\n\u001b[1;32m   1615\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1616\u001b[0m     \u001b[39mraise\u001b[39;00m ReadError(\u001b[39m\"\u001b[39m\u001b[39mfile could not be opened successfully\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1618\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1619\u001b[0m     filemode, comptype \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mReadError\u001b[0m: file could not be opened successfully\nThis exception is thrown by __iter__ of TarArchiveLoaderIterDataPipe(datapipe=FileOpenerIterDataPipe, length=-1, mode='r:*')"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_dl))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:34\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     33\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     35\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/datapipe.py:351\u001b[0m, in \u001b[0;36m_IterDataPipeSerializationWrapper.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 351\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/grouping.py:41\u001b[0m, in \u001b[0;36mShardingFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mfor\u001b[39;00m i, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe):\n\u001b[1;32m     42\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_id:\n\u001b[1;32m     43\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:127\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[39myield\u001b[39;00m x\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    128\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_size:\n\u001b[1;32m    129\u001b[0m             idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rng\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:540\u001b[0m, in \u001b[0;36mZipperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m iterators \u001b[39m=\u001b[39m [\u001b[39miter\u001b[39m(datapipe) \u001b[39mfor\u001b[39;00m datapipe \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes]\n\u001b[1;32m    539\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterators):\n\u001b[1;32m    541\u001b[0m         \u001b[39myield\u001b[39;00m data\n\u001b[1;32m    542\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/plain_text_reader.py:133\u001b[0m, in \u001b[0;36mLineReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[Str_Or_Bytes, Tuple[\u001b[39mstr\u001b[39m, Str_Or_Bytes]]]:\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    134\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n\u001b[1;32m    135\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mstrip_newline(stream)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/utils/common.py:208\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    206\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:438\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    434\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    439\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    440\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "    \u001b[0;31m[... skipping similar frames: hook_iterator.<locals>.wrap_generator at line 173 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/selecting.py:85\u001b[0m, in \u001b[0;36mFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     86\u001b[0m         filtered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returnIfTrue(data)\n\u001b[1;32m     87\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isNonEmpty(filtered):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:56\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, BufferedIOBase]]:\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     57\u001b[0m         validate_pathname_binary_tuple(data)\n\u001b[1;32m     58\u001b[0m         pathname, data_stream \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/utils/common.py:208\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    206\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:213\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_caching_flag:\n\u001b[0;32m--> 213\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe\n\u001b[1;32m    214\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[39m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call `end_caching()` before iteration.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:358\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    359\u001b[0m         item_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[1;32m    360\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember_elements\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:387\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_next(instance_id)\n\u001b[1;32m    388\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m         stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:360\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe_iterator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    358\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)\n\u001b[1;32m    361\u001b[0m classification \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier_fn(value)\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m classification \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_none:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:138\u001b[0m, in \u001b[0;36m_ForkerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleading_ptr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchild_pointers[instance_id]\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     return_val \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mappend(return_val)\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:438\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    434\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    439\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    440\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/selecting.py:85\u001b[0m, in \u001b[0;36mFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     86\u001b[0m         filtered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returnIfTrue(data)\n\u001b[1;32m     87\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isNonEmpty(filtered):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:56\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, BufferedIOBase]]:\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     57\u001b[0m         validate_pathname_binary_tuple(data)\n\u001b[1;32m     58\u001b[0m         pathname, data_stream \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/utils/common.py:208\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    206\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:213\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_caching_flag:\n\u001b[0;32m--> 213\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe\n\u001b[1;32m    214\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[39m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call `end_caching()` before iteration.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:358\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    359\u001b[0m         item_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[1;32m    360\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember_elements\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:387\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_next(instance_id)\n\u001b[1;32m    388\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m         stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:360\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe_iterator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    358\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)\n\u001b[1;32m    361\u001b[0m classification \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier_fn(value)\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m classification \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_none:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/iter/combining.py:53\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 53\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     54\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/iter/util/cacheholder.py:339\u001b[0m, in \u001b[0;36m_WaitPendingCacheItemIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    338\u001b[0m \u001b[39mwhile\u001b[39;00m _is_promise_pending(promise_filename):\n\u001b[0;32m--> 339\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout:\n\u001b[1;32m    341\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    342\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOnDiskCache Exception: \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m expected to be written by different process, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut file is not ready in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 128    # Number of vocab \"words\"\n",
    "block_size = 32     # Length of context\n",
    "batch_size = 256    # Batch size\n",
    "vtype = 'bpe'       # Sentancepiece vocab model type\n",
    "\n",
    "# Store text as pytorch datasets\n",
    "class Text(Dataset):\n",
    "    def __init__(self, text, block_size) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Build dataset\n",
    "        self.x = [text[i:i+block_size]\n",
    "                  for i in range(len(text) - block_size - 1)]\n",
    "        self.y = [text[i+1:i+block_size+1]\n",
    "                  for i in range(len(text) - block_size - 1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "\n",
    "# Convert parameters of model to data loaders\n",
    "def define_data(name, vtype, block_size, batch_size, vocab_size):\n",
    "\n",
    "    # Read in raw text\n",
    "    if name == 'wikipedia':\n",
    "        filet = 'data/wikitext-103/wiki.test.tokens'\n",
    "        filev = 'data/wikitext-103/wiki.valid.tokens'\n",
    "    elif name == 'timemachine':\n",
    "        filet = 'data/timemachine.txt'\n",
    "        filev = None\n",
    "    else:\n",
    "        filet = 'data/tiny-shakespeare.txt'\n",
    "        filev = None\n",
    "\n",
    "    textt = open(filet, 'r').read()\n",
    "\n",
    "    # Create sentancepiece model\n",
    "    spm.SentencePieceTrainer.train(input=filet, vocab_size=vocab_size,\n",
    "                                   model_type=vtype, model_prefix='mb', user_defined_symbols='\\n',\n",
    "                                   minloglevel=2)\n",
    "\n",
    "    # Language Model (BPE)\n",
    "    spw = spm.SentencePieceProcessor('mb.model')\n",
    "\n",
    "    train = Text(torch.tensor(spw.Encode(textt)), block_size=block_size)\n",
    "    if filev is not None:\n",
    "        textv = open(filev).read()\n",
    "        val = Text(torch.tensor(spw.Encode(textv)), block_size=block_size)\n",
    "    else:\n",
    "        train, val = torch.utils.data.random_split(train, [0.9, 0.1])\n",
    "\n",
    "    train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    del (train)\n",
    "    del (val)\n",
    "    del (textt)\n",
    "    #del (textv)\n",
    "\n",
    "    '''\n",
    "    print('\\n------\\n\\nExample decode from data: ')\n",
    "    x, y = next(iter(train_dl))\n",
    "    dx = spw.Decode(x.tolist())\n",
    "    dy = spw.Decode(y.tolist())\n",
    "    print(x[0])     # X as raw numercial tensor\n",
    "    print(y[0])     # Y as raw numercial tensor\n",
    "    print(dx[0])    # X decoded to string\n",
    "    print(dy[0])    # Y decoded to string\n",
    "    '''\n",
    "    return train_dl, val_dl, spw\n",
    "\n",
    "\n",
    "# Dataset to use\n",
    "#name = 'shakepeare'\n",
    "#name = 'wikipedia'\n",
    "name = 'timemachine'\n",
    "\n",
    "train_dl, val_dl, spw = define_data(name, vtype, block_size, batch_size, vocab_size)\n",
    "#print (len(train_dl), len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.09375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is there enough training data for the vocab size?\n",
    "(len(train_dl)*batch_size)/vocab_size**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bengio 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bengio2003(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embed, n_hidden, block_size) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # n_embed == m in Bengio\n",
    "        # n_hidden == h in Bengio\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mlp = nn.LazyLinear(n_hidden)\n",
    "        self.relu = nn.Tanh()\n",
    "        self.final_linear = nn.LazyLinear(block_size*vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.token_embedding(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.mlp(x))\n",
    "        x = self.final_linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embed) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.token_embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RNNScratch(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens) -> None:\n",
    "        super().__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.W_xh = nn.Parameter(\n",
    "            torch.randn(num_inputs, num_hiddens)*0.01)\n",
    "        self.W_hh = nn.Parameter(\n",
    "            torch.randn(num_hiddens, num_hiddens)*0.01)\n",
    "        self.b_h = nn.Parameter(torch.zeros(num_hiddens))\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        B, T, C = x.shape\n",
    "        if state is None:\n",
    "            state = torch.zeros((x.shape[0], self.num_hiddens))\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(T):\n",
    "            X = x[:, i, :]\n",
    "            state = torch.tanh(X @ self.W_xh\n",
    "                               + state @ self.W_hh + self.b_h)\n",
    "            outputs.append(state)\n",
    "        return outputs, state\n",
    "\n",
    "\n",
    "class RNNLMScratch(nn.Module):\n",
    "    def __init__(self, rnn, n_embed, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rnn = rnn\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.W_hq = nn.Parameter(\n",
    "            torch.randn(self.rnn.num_hiddens, self.vocab_size)*0.01)\n",
    "        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        x = self.token_embedding(x)\n",
    "        rnn_outputs, state = self.rnn(x)\n",
    "        outputs = [H @ self.W_hq + self.b_q for H in rnn_outputs]\n",
    "        return torch.stack(outputs, 1)\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, n_features, n_hiddens) -> None:\n",
    "        super().__init__()\n",
    "        # n_features is the C in B, T, C\n",
    "        self.rnn = nn.RNN(input_size=n_features,\n",
    "                          hidden_size=n_hiddens, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, H=None):\n",
    "        return self.rnn(inputs)\n",
    "\n",
    "\n",
    "class MikolovRNN2010(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embed, n_hidden, num_layers = 3) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.rnn = nn.RNN(input_size=n_embed,\n",
    "                          hidden_size=n_hidden, batch_first=True, num_layers = num_layers)\n",
    "        self.linear = nn.LazyLinear(vocab_size)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        x = self.token_embedding(x)\n",
    "        x, state = self.rnn(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''n_embed = 64\n",
    "n_hidden = 16\n",
    "x, y = next(iter(train_dl))\n",
    "emb = Embedding(vocab_size, n_embed)\n",
    "print ('Original x:', x.shape)\n",
    "\n",
    "print ('Embedded x:', emb(x).shape)\n",
    "\n",
    "rnn = RNN(n_embed, n_hidden)\n",
    "outputs, state = rnn(emb(x))\n",
    "\n",
    "print ('RNN x:', outputs.shape)\n",
    "model = MikolovRNN2010(vocab_size, n_embed, n_hidden, num_layers=3)\n",
    "x = model(x)\n",
    "print ('RNNLM x:', x.shape)\n",
    "''';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(pl.LightningModule):\n",
    "    def __init__(self, model, vocab_size, lr=0.1, max_epochs=25, threshold=0.02):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.threshold = threshold\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "        #scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        #    optimizer, T_max=(self.max_epochs+2), verbose=False)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, 'min', factor=0.5, patience=2, verbose=True,\n",
    "            threshold = self.threshold, threshold_mode='abs')\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"epoch\", \"monitor\": \"val_loss\"}\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        x, y = batch\n",
    "\n",
    "        logits = self.model(x)\n",
    "        train_loss = self.loss_fn(logits.view(-1, self.vocab_size), y.view(-1))\n",
    "\n",
    "        self.log('train_loss', train_loss, on_epoch=True, on_step=False,)\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        val_loss = self.loss_fn(logits.view(-1, self.vocab_size), y.view(-1))\n",
    "\n",
    "        self.log('val_loss', val_loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "\n",
    "        x, y = batch\n",
    "        idx = x.view(1,-1)\n",
    "        for i in range(1000):\n",
    "\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits = self.model(idx_cond)\n",
    "\n",
    "            B, T = idx_cond.shape\n",
    "            \n",
    "            logits = logits.view(B, T, vocab_size)\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "    #def validation_epoch_end(self, outputs) -> None:\n",
    "    #    print (f'Current valdation loss is: {torch.mean(torch.stack(outputs)).item():7.4f}')\n",
    "    #    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 1 1\n",
      "9 1 2\n",
      "9 1 5\n"
     ]
    }
   ],
   "source": [
    "xx, yy = torch.utils.data.random_split(range(10), [0.9, 0.1])\n",
    "\n",
    "for i in range(3):\n",
    "    print (len(xx), len(yy), xx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 6.1 M \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.303    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f1bbd41894113aa15758e9650e068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 0 is:  9.0153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1718ffccb0404a93a215330d977b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a168db22edd4b9fbf6828bcb0fd2677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 1 is:  4.2901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adcf3e40ff74081bd285a972adb7e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 2 is:  3.7731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4beeae9c9cbe425190b11a1ada04f89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 3 is:  3.3698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8037dd8410c9408089ef47680fb1c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 4 is:  3.0123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4dfbeff8fe405f81d1653e8e851061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 5 is:  2.6833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020ae864d34e482c84720d9be4dda6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 6 is:  2.3919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba24f2c43224f63ac3d772e76769af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 7 is:  2.1288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb2251e40834496a26e8fc2decc71d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 8 is:  1.8984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9387059a6264b2ebb404972e5c67ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 9 is:  1.6936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66bc0f8eed3484d8edf2144e0329e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 10 is:  1.5151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8707943354a412bb0fabb04d69b0d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 11 is:  1.3630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40eeb39f03d8480d8cb212ef25080084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 12 is:  1.2338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cdb9f2df824147af09ed47c93466f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 13 is:  1.1227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520b67e3d00648d58522fef0fa1a0f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 14 is:  1.0370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d55027f57f74d47b982cbdfce8132e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 15 is:  0.9601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d45f34dcae44f0a8f54590b931fa18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 16 is:  0.9043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49aa0fb31d049dca1a3ee2df358e950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 17 is:  0.8541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b517a559e67f458da88833c122955512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 18 is:  0.8157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dd16f1bf014a7e9e5c0252d6efe375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 19 is:  0.7852\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f6cba76f664ace998b9b7e377b192d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 20 is:  0.7617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2276b64152ba4df1b028b7ddc6e3c699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 21 is:  0.7368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480003edb1de4e51a9eb35b9e812ab05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 22 is:  0.7206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496f7568617c4116b298592be221eacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 23 is:  0.7062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b17b38be4d421cab8a3498ea3ca983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 24 is:  0.6950\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063b04d3b1834906ad97de072c37d65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 25 is:  0.6828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1996e58528e84449986c25c6ec082c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 26 is:  0.6757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa862661f0724014ac1e89cb46cbb821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 27 is:  0.6661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffe545fe8384f4ab2d6316238564fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 28 is:  0.6599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d134b6fe0b5f46e4bb8ed60f20fc50b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 29 is:  0.6543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3df73509a6414b8537b6f1db9f3ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 30 is:  0.6460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b7301e9c214a54ad7924c6ba9c7f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current validation loss for epoch 31 is:  0.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639bf797d7104c108c0d621565058c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6420795321464539     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6420795321464539    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23efee06bf16452da5379816aab71720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s field\n",
      "This lady's husband, Sir Richard Grey, was slain,\n",
      "His lands then seized on by the conqueror:\n",
      "Her suit isA sin-absolver, and my friend profess'd,\n",
      "To mangle me with that word 'banished'?\n",
      "\n",
      "FRIAR LAURENCE her life.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "Sister, farewell; I must to Coventry:\n",
      "As much good stay with thee as goith bag and baggage: many thousand on's\n",
      "Have the disease, and feel't not. How now, boy!\n",
      "\n",
      "MAMILLIUS condemn'd\n",
      "A wandering vagabond; my rights and royalties\n",
      "Pluck'd from my arms perforce and given away\n",
      "To up\n",
      "And such a one as he, who puts his 'shall,'\n",
      "His popular 'shall' against a graver bench\n",
      "Than ever love or hate\n",
      "him manifests the true knowledge he has in their\n",
      "disposition; and out of his noble carelessness lets\n",
      "them.\n",
      "\n",
      "BAPTISTA:\n",
      "\n",
      "KATHARINA:\n",
      "No shame but mine: I must, forsooth, be forced\n",
      "To give my,\n",
      "Or else a hovering temporizer, that\n",
      "Canst with thine eyes at once see good and evil,\n",
      "Incl:\n",
      "Black and portentous must this humour prove,\n",
      "Unless good counsel may the cause remove.\n",
      "\n",
      "BENVOLIO:\n",
      " urine is\n",
      "congealed ice; that I know to be true: and he is a\n",
      "motion generative; that's infall take these rats thither\n",
      "To gnaw their garners. Worshipful mutiners,\n",
      "Your valour puts well forth: pray, follow.\n",
      " they were none.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, the mayor of London comes to greet you.\n",
      "\n",
      "Lord Mayor:\n",
      "God blessAMILLO:\n",
      "I may not answer.\n",
      "\n",
      "POLI ⁇ ENES:\n",
      "A sickness caught of me, and yet I well!\n",
      "I must be answer shall see this gentleman, thy speeches\n",
      "Will bring me to consider that which may\n",
      "Unfurnish me of reason. They are come.oint by joint, but we will know his purpose.\n",
      "What 'unjust'!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Be not so hot; the duke\n",
      "hat common chances common men could bear;\n",
      "That when the sea was calm all boats alike\n",
      "Show'd mastership in floating:\n",
      "O sir, the loathsomeness of them offends me more\n",
      "than the stripes I have received, which are mighty\n",
      "ones andlous boy;\n",
      "Bold, quick, ingenious, forward, capable\n",
      "He is all the mother's, from the top to toe.against us.\n",
      "\n",
      "ANGELO:\n",
      "Well, I beseech you, let it be proclaimed betimes\n",
      "i' the morn; I'll not.\n",
      "\n",
      "ISABELLA:\n",
      "What a merit were it in death to take this poor maid\n",
      "from the world! What corruption in this life along with me.\n",
      "\n",
      "GLOUCESTER:\n",
      "Bid me farewell.\n",
      "\n",
      "LADY ANNE:\n",
      "'Tis more than you deserve;\n",
      " than a man,\n",
      "Daring an opposite to every danger:\n",
      "His horse is slain, and all on foot he fights,\n",
      "Seeking for testimonies against his worth and credit\n",
      "That's seal'd in approbation? You, Lord Escalus,\n",
      "Sit with my cousin; lend this wicked caitiff?\n",
      "\n",
      "ESCALUS:\n",
      "Truly, officer, because he hath some offences in him\n",
      "that thou wouldst discover if thou couldst,, whence 'tis derived.\n",
      "There is another friar that set them on;\n",
      "Let him be sent for.\n",
      "\n",
      "FRIAR PETER:\n",
      "A banish'd traitor: all my treasury\n",
      "Is yet but unfelt thanks, which more enrich'd\n",
      "Shall be your love\n",
      "man to teach her that wherein she delights, I will\n",
      "wish him to her father.\n",
      "\n",
      "HORTENSIO:\n",
      "So will I ⁇ ABETH:\n",
      "Windy attorneys to their client woes,\n",
      "Airy succeeders of intestate joys,\n",
      "Poor breathing or the Volsces\n",
      "May say 'This mercy we have show'd;' the Romans,\n",
      "'This we received;' and each in either side\n",
      "Giver, if thou wilt not, be but sworn my love,\n",
      "And I'll no longer be a Capulet.\n",
      "\n",
      "ROMEO:\n",
      "\n",
      " speed!\n",
      "But be thou arm'd for some unhappy words.\n",
      "\n",
      "PETRUCHIO:\n",
      "Ay, to the proof; as mountains are sister to the King of France.\n",
      "These both put by a poor petitioner,\n",
      "A care-crazed mother of a many children,\n",
      "ADUKE OF AUMERLE:\n",
      "You holy clergymen, is there no plot\n",
      "To rid the realm of this pernicious blot?\n",
      "\n",
      "Abb had\n",
      "well knock'd at first, Then had not Grumio come by the worst.\n",
      "\n",
      "PETRUCHIO:\n",
      "A senseless villain! Good Hortensio, loves again,\n",
      "Alike betwitched by the charm of looks,\n",
      "But to his foe supposed he must complain,\n",
      "And she steal love less foul profanation.\n",
      "\n",
      "LUCIO:\n",
      "Thou'rt i' the right, girl; more o, that.\n",
      "\n",
      "ISAB it on you at the first so roundly.\n",
      "\n",
      "PETRUCHIO:\n",
      "O Kate, content thee; prithee, be not angry.\n",
      "\n",
      "KATH man of Claudio's years; his beard and head\n",
      "Just of his colour. What if we do omit\n",
      "This reprobate till he wereAnd, let your father make her the assurance,\n",
      "She is your own; else, you must pardon me,\n",
      "if you should die before himnd not provoked by any suitor else;\n",
      "Aiming, belike, at your interior hatred,\n",
      "Which in your outward actions shows itself\n",
      "A found\n",
      "False to his children or his wife's allies\n",
      "This is the day wherein I wish'd to fall\n",
      "By the false faiththat you have said.\n",
      "\n",
      "LUCIO:\n",
      "My lord, here comes the rascal I spoke of; here with\n",
      "the provost.\n",
      "\n",
      "ES taker may fall dead\n",
      "And that the trunk may be discharged of breath\n",
      "As violently as hasty powder fired\n",
      "Doth hurry\n",
      "pricking it for pity. Come, you shall go with us.\n",
      "\n",
      "VIRGILIA:\n",
      "No, good madam, pardon\n",
      "\n",
      "RIVERS:\n",
      "These news I must confess are full of grief;\n",
      "Yet, gracious madam, bear it as you may:\n",
      " cleave to my roof within my mouth\n",
      "Unless a pardon ere I rise or speak.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Intended or committed:\n",
      "Fiddler, forbear; you grow too forward, sir:\n",
      "Have you so soon forgot the entertainment\n",
      "Her sister Katharina welcomed, and thus answer'd:\n",
      "'True is it, my incorporate friends,' quoth he,\n",
      "'That I receive the general, would I flame distinctly,\n",
      "Then meet and join. Jove's lightnings, the precursors\n",
      "O' the dreadful thunderHe shall be thrown down the Tarpeian rock\n",
      "With rigorous hands: he hath resisted law,\n",
      "And therefore law shall scorn him further trial\n",
      "s, more momentary\n",
      "And sight-outrunning were not; the fire and cracks\n",
      "Of sulphurous roaring the most mighty Neptune\n",
      "For thee to murder: for my daughters, Richard,\n",
      "They shall be praying nuns, not weeping queens;\n",
      "And therefore levelisting postern with these strokes.\n",
      "\n",
      "Provost:\n",
      "There he must stay until the officer\n",
      "Arise to let him in: he soldiers the lie: but we pay them for\n",
      "it with stamped coin, not stabbing steel; therefore\n",
      "they do not give us the lie\n",
      "\n",
      "TRANIO:\n",
      "Not so well apparell'd\n",
      "As I wish you were.\n",
      "\n",
      "PETRUCHIO:\n",
      "Were it weeping, you should hear,--\n",
      "Nay, and you shall hear some.\n",
      "Will you be gone?\n",
      "\n",
      "VIRGILIA:\n",
      "\n",
      " allow it, sir.\n",
      "\n",
      "ESCALUS:\n",
      "But the law will not allow it, Pompey; nor it shall\n",
      "not be allowed innd if I were thy nurse, thy tongue to teach,\n",
      "'Pardon' should be the first word of thy speech.\n",
      "I never long'd, say so;\n",
      "The bastard brains with these my proper hands\n",
      "Shall I dash out. Go, take it to the fire;\n",
      "For thouTESBY:\n",
      "\n",
      "KING RICHARD III:\n",
      "I will converse with iron-witted fools\n",
      "And unrespective boys: none are for meMy land amounts not to so much in all:\n",
      "That she shall have; besides an argosy\n",
      "That now is lying in Marse:\n",
      "I neither know it nor can learn of him.\n",
      "\n",
      "BENVOLIO:\n",
      "Have you importuned him by any means?\n",
      "\n",
      "M the lie.\n",
      "\n",
      "Clown:\n",
      "Your worship had like to have given us one, if you\n",
      "had not taken yourself with the manner and kiss me, Kate.\n",
      "\n",
      "LUCENTIO:\n",
      "Well, go thy ways, old lad; for thou shalt ha't.\n",
      "\n",
      " right supremacy;\n",
      "And, to be short, what not, that's sweet and happy?\n",
      "\n",
      "BAPTISTA:\n",
      "Now mean you that?\n",
      "\n",
      "Widow:\n",
      "Thus I conceive by him.\n",
      "\n",
      "PETRUCHIO:\n",
      "Conceives by me! How likesSometime in Greece,--\n",
      "\n",
      "MENENIUS:\n",
      "Well, well, no more of that.\n",
      "\n",
      "CORIOLANUS:\n",
      "Though's fee:\n",
      "This is the quondam king; let's seize upon him.\n",
      "\n",
      "KING HENRY VI:\n",
      "Let me embrace the sun under the dove-house wall;\n",
      "My lord and you were then at Mantua:--\n",
      "Nay, I do bear a brain:--but, as\n",
      "And would by combat make her good, so were I\n",
      "A man, the worst about you.\n",
      "\n",
      "LEONTES:\n",
      "Force her\n",
      "\n",
      "POLI ⁇ ENES:\n",
      "Prithee, let him.\n",
      "\n",
      "FLORI ⁇ EL:\n",
      "No, he must not.\n",
      "\n",
      " when I miscall it so,\n",
      "Which finds it an inforced pilgrimage.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "The sullen passage of thy weary brother; there my father's grave\n",
      "Did utter forth a voice. Yes, thou must die:\n",
      "Thou art too noble to conserve a no murder: and wilt thou, then,\n",
      "Spurn at his edict and fulfil a man's?\n",
      "Take heed; for he new cut off,\n",
      "Write in the dust this sentence with thy blood,\n",
      "'Wind-changing Warwick now can change no more.'\n",
      " private life\n",
      "And in devotion spend my latter days,\n",
      "To sin's rebuke and my Creator's praise.\n",
      "\n",
      "W do that had deserved his hate,\n",
      "And therein show'd like enemies.\n",
      "\n",
      "MENENIUS:\n",
      "'Tis true:\n",
      "If he to be\n",
      "monstrous members.\n",
      "\n",
      "First Citizen:\n",
      "And to make us no better thought of, a little help\n",
      "will serve; for, in the chase, it seems,\n",
      "Of this fair couple, meets he on the way\n",
      "The father of this seeming lady and\n",
      "Heries my consent and fair according voice.\n",
      "This night I hold an old accustom'd feast,\n",
      "Whereto I have invited many a you colour it in being a tapster, are you\n",
      "not? come, tell me true: it shall be the better for you.\n",
      "\n",
      "POMPEY\n",
      "That, his apparent open guilt omitted,\n",
      "I mean, his conversation with Shore's wife,\n",
      "He lived from all attainder Margaret, and be a witness\n",
      "That Bona shall be wife to the English king.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "To Edward, but not your grace\n",
      "Where and what time your majesty shall please.\n",
      "\n",
      "KING RICHARD III:\n",
      "Ay, ay. thou wouldst be gone to join with lost\n",
      "By lack of stooping,--\n",
      "\n",
      "AUFIDIUS:\n",
      "That I would have spoke of:\n",
      "Being banish'd for' thank you, good my lord; and thank you all.\n",
      "I thought my mother, and my brother York,\n",
      "Would long ere this have met us being one,\n",
      "In hand and hope of action: but we do learn\n",
      "By those that know the very nerves of state,\n",
      "Hisou art a fool: if Echo were as fleet,\n",
      "I would esteem him worth a dozen such.\n",
      "But sup them well and look unto my canker'd country with the spleen\n",
      "Of all the under fiends. But if so be\n",
      "Thou darest not this and that to prove moreFLORI ⁇ EL:\n",
      "My good Camillo,\n",
      "She is as forward of her breeding as\n",
      "She is i' the rear our birth.\n",
      "h, my young princes! ah, my tender babes!\n",
      "My unblown flowers, new-appearing sweets!\n",
      "If yet your gentle soulsShe vied so fast, protesting oath on oath,\n",
      "That in a twink she won me to her love.\n",
      "O, you are 'tis far from hence to France;\n",
      "How could he stay till Warwick made return?\n",
      "\n",
      "SOMERSET:\n",
      "My lords, forbear this talkTo prison with her! Shall we thus permit\n",
      "A blasting and a scandalous breath to fall\n",
      "On him so near us? This needs mustWhat, drawn, and talk of peace! I hate the word,\n",
      "As I hate hell, all Montagues, and thee:\n",
      "Have at theeo you hear, ho? you must meet my master to\n",
      "countenance my mistress.\n",
      "\n",
      "GRUMIO:\n",
      "Why, she hath not possess'd it, and, though I am sold,\n",
      "Not yet enjoy'd: so tedious is this day\n",
      "As is the night no, my lord. My suit is at an end.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "CLARENCE:\n",
      "\n",
      "KING EDWARD IV::\n",
      "Ay, if you come not in the blood of others,\n",
      "But mantled in your own.\n",
      "\n",
      "MARCIUS:\n",
      "Oi-paradise,\n",
      "This fortress built by Nature for herself\n",
      "Against infection and the hand of war,\n",
      "This happy breed of menboard, look to the plate. Good thou, save\n",
      "me a piece of marchpane; and, as thou lovest me, let\n",
      "the porter borough, I'll answer him\n",
      "by law: I'll not budge an inch, boy: let him come,\n",
      "and kindly.\n",
      "\n",
      " I die.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Saint Francis be my speed! how oft to-night\n",
      "Have my old feet stumbled at gravesORFOLK:\n",
      "Such hope have all the line of John of Gaunt!\n",
      "\n",
      "RICHARD:\n",
      "Thus do I hope to shake King Henry\n",
      "In haste, post-haste, are come to join with you:\n",
      "For in the marches here we heard you were,\n",
      "M now.\n",
      "\n",
      "PETER:\n",
      "You will not, then?\n",
      "\n",
      "First Musician:\n",
      "No.\n",
      "\n",
      "PETER:\n",
      "Ianers of this neighbour-stained steel,--\n",
      "Will they not hear? What, ho! you men, you beasts,\n",
      "That quench all these hideous fears?\n",
      "And madly play with my forefather's joints?\n",
      "And pluck the mangled Tybalt from his shroud?\n",
      "A living, all is Death's.\n",
      "\n",
      "PARIS:\n",
      "Have I thought long to see this morning's face,\n",
      "And doth itome on, our queen: to-morrow must we part;\n",
      "Be merry, for our time of stay is short\n",
      "\n",
      "NORTHUMBERLAND:\n",
      " seems unsettled.\n",
      "\n",
      "POLI ⁇ ENES:\n",
      "How, my lord!\n",
      "What cheer? how is't with you, best brotherness\n",
      "Crowd to his presence, where their untaught love\n",
      "Must needs appear offence.\n",
      "How now, fair maid?\n",
      "\n",
      "Iwhat news?\n",
      "\n",
      "ELBOW:\n",
      "Come your ways, sir; come.\n",
      "\n",
      "LUCIO:\n",
      "Go to kennel, Pompey it be brought you.\n",
      "\n",
      "AUTOLYCUS:\n",
      "I will trust you. Walk before toward the sea-side;\n",
      "go on the right handhich in a napkin being close convey'd\n",
      "Shall in despite enforce a watery eye.\n",
      "See this dispatch'd with all the haste thou canst thou, and both become the grave.\n",
      "\n",
      "DUKE OF YORK:\n",
      "I do beseech your majesty, impute his words\n",
      "To wayward sickliness:\n",
      "In her chamber, making a sermon of continency to her;\n",
      "And rails, and swears, and rates, that she his body\n",
      "Upon a rapier's point: stay, Tybalt, stay!\n",
      "Romeo, I come! this do I drink to thee me to famish me?\n",
      "Beggars, that come unto my father's door,\n",
      "Upon entreaty have a present aims;\n",
      "IfAy, to the proof; as mountains are for winds,\n",
      "That shake not, though they blow perpetually.\n",
      "\n",
      "BAPTISTA:\n",
      "\n",
      "Angelo hath seen them both, and will discover the favour.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "O, death's a great disguisWell might they fester 'gainst ingratitude,\n",
      "And tent themselves with death. Of all the horses,\n",
      "Whereof we have ta's majesty,\n",
      "His captain, steward, deputy-elect,\n",
      "Anointed, crowned, planted many years,\n",
      "Be jud doth give,\n",
      "Nor aught so good but strain'd from that fair use\n",
      "Revolts from true birth, stumbling on abuse:o Romeo would, were he not Romeo call'd,\n",
      "Retain that dear perfection which he owes\n",
      "Without that title. Romeo, do, with that report.\n",
      "\n",
      "JULIET:\n",
      "That is no slander, sir, which is a truth;\n",
      "And what I spake, I Clarence! I do love thee so,\n",
      "That I will shortly send thy soul to heaven,\n",
      "If heaven will take the present at our hands.?\n",
      "\n",
      "Huntsman:\n",
      "Better do so than tarry and be hang'd.\n",
      "\n",
      "GLOUCESTER:\n",
      "Come then, robbers so o'ermatch'd.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "What would your grace have done unto him now?\n",
      "\n",
      "Q\n",
      "You have of these pedlars, that have more in them\n",
      "than you'ld think, sister.\n",
      "\n",
      "PERDITA:\n",
      " us: we'll be thy\n",
      "good masters.\n",
      "\n",
      "LEONTES:\n",
      "O grave and good Paulina, the great comfort\n",
      "That I have hado beg of thee, it is my more dishonour\n",
      "Than thou of them. Come all to ruin; let\n",
      "Thy mother rather feel thy pride thannd thou, brave Oxford, wondrous well beloved,\n",
      "In Oxfordshire shalt muster up thy friends.\n",
      "My sovereign, with the loving citizens,\n",
      "L\n",
      "Each one demand an answer to his part\n",
      "Perform'd in this wide gap of time since first\n",
      "We were dissever'd\n",
      "The bastard brains with these my proper hands\n",
      "Shall I dash out. Go, take it to the fire;\n",
      "For thou set'st on death to\n",
      "grant this.\n",
      "\n",
      "CAMILLO:\n",
      "It is fifteen years since I saw my country: though\n",
      "I have for the most part,\n",
      "Whipp'd and tormented and--God-den, good fellow.\n",
      "\n",
      "Servant:\n",
      "God gi' god-den\n",
      "Romeo, I come! this do I drink to thee.\n",
      "\n",
      "LADY CAPULET:\n",
      "Hold, take these keys, and fetchll pawn the little blood which I have left\n",
      "To save the innocent: any thing possible.\n",
      "\n",
      "LEONTES:\n",
      "It shall be possible. king,\n",
      "Who look'd full gently on his warlike queen,\n",
      "That robb'd my soldiers of their heated spleen;\n",
      "Or most sweet:\n",
      "O thou, the earthly author of my blood,\n",
      "Whose youthful spirit, in me regenerate,\n",
      "Doth with a two RICHARD III:\n",
      "Stand all apart Cousin of Buckingham!\n",
      "\n",
      "BUCKINGHAM:\n",
      "My gracious sovereign?\n",
      "\n",
      "KING RICHARD III:\n",
      "GBack to the Duke of Gloucester, tell him so.\n",
      "\n",
      "Second Murderer:\n",
      "I pray thee, stay a while: I hope my holy\n",
      "JOHN OF GAUNT:\n",
      "Now He that made me knows I see thee ill;\n",
      "Ill in myself to see, and in thee seeings closely to conceal what we impart:\n",
      "Thou know'st our reasons urged upon the way;\n",
      "What think'st thou? is it not an thy funeral bell;\n",
      "And so obsequious will thy father be,\n",
      "Even for the loss of thee, having no more,\n",
      "A and leases whatsoever:\n",
      "Let specialties be therefore drawn between us,\n",
      "That covenants may be kept on either hand.\n",
      "\n",
      " the rotten fens, whose loves I prize\n",
      "As the dead carcasses of unburied men\n",
      "That do corrupt my air, I girl, seek happy nights to happy days.\n",
      "\n",
      "ROMEO:\n",
      "What, shall this speech be spoke for our excuse?\n",
      "Or shall we on still is it so:\n",
      "By a divine instinct men's minds mistrust\n",
      "Ensuing dangers; as by proof, we see\n",
      "The waters'er I put between your holy looks\n",
      "My ill suspicion. This is your son-in-law,\n",
      "And son unto the king, who, thither is but one day's march.\n",
      "In God's name, cheerly on, courageous friends,\n",
      "To reap the harvest of perpetual, my good lord, your grace's word shall serve,\n",
      "As well as I had seen and heard him speak\n",
      "And doubt you not, duty\n",
      "To fair Bianca, so beloved of me.\n",
      "\n",
      "GREMIO:\n",
      "Beloved of me; and that my deeds shall prove sights\n",
      "Are spectacled to see him: your prattling nurse\n",
      "Into a rapture lets her baby cry\n",
      "While she chatgain with Rome's mechanics: tell me not\n",
      "Wherein I seem unnatural: desire not\n",
      "To ally my rages and revengesLook, here comes one: a gentlewoman of mine,\n",
      "Who, falling in the flaws of her own youth,\n",
      "Hath blister'd he should\n",
      "Be free as is the wind. Deliver him, Titus.\n",
      "\n",
      "LARTIUS:\n",
      "Marcius, his name?\n",
      "\n",
      " Eden, demi-paradise,\n",
      "This fortress built by Nature for herself\n",
      "Against infection and the hand of war,\n",
      "ThisOn the sudden,\n",
      "I warrant him consul.\n",
      "\n",
      "BRUTUS:\n",
      "Then our office may,\n",
      "During his power, go sleep.\n",
      "What good is this to England and himself!\n",
      "\n",
      "WESTMORELAND:\n",
      "Base, fearful and despairing Henry!\n",
      "\n",
      "CLIFFORD: my word.\n",
      "\n",
      "ESCALUS:\n",
      "Call that same Isabel here once again; I would speak with her.\n",
      "Pray you, my lordEMIO:\n",
      "Beloved of me; and that my deeds shall prove.\n",
      "\n",
      "GRUMIO:\n",
      "And that his bags shall prove thee for thy foul misleading me.\n",
      "And so, proud-hearted Warwick, I defy thee,\n",
      "And to my brother turn my\n",
      "Many that are not mad\n",
      "Have, sure, more lack of reason. What would you say?\n",
      "\n",
      "ISABELLA:\n",
      "I am\n",
      "PETRUCHIO:\n",
      "My remedy is then, to pluck it out.\n",
      "\n",
      "KATHARINA:\n",
      "Ay, if the fool could find it where as I love Hastings with my heart!\n",
      "\n",
      "KING EDWARD IV:\n",
      "Madam, yourself are not exempt in this,\n",
      "Nor your sons husband here, this, do you see--\n",
      "Whom you have banish'd, does exceed you all.\n",
      "\n",
      "BRUTUS:\n",
      "W flesh and the blood.\n",
      "\n",
      "Messenger:\n",
      "Your honour's players, heating your amendment,\n",
      "Are come to play aAS MOWBRAY:\n",
      "Let not my cold words here accuse my zeal:\n",
      "'Tis not the trial of a woman's war,\n",
      "The bitter clamour 'twere, in love\n",
      "Unseparable, shall within this hour,\n",
      "On a dissension of a doit, break out\n",
      " I will open my lips in vain, or\n",
      "discover his government.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "That shall not be much amiss: Yet government:\n",
      "I make you both protectors of this land,\n",
      "While I myself will lead a private life\n",
      "And in devotion spend my latter country are all wither'd\n",
      "And meteors fright the fixed stars of heaven;\n",
      "The pale-faced moon looks bloody on the earth\n",
      ", I am sure, you have your hands full all,\n",
      "In this so sudden business.\n",
      "\n",
      "LADY CAPULET:\n",
      "Good night:\n",
      " close, for I will speak to them.\n",
      "Gentlemen, good den: a word with one of you.\n",
      "\n",
      "MERCUTIO:\n",
      "Alients: though you change your place, you need not\n",
      "change your trade; I'll be your tapster still.\n",
      "Courage! there will be it with such over-roasted flesh.\n",
      "Be patient; to-morrow 't shall be mended,\n",
      "And, for this night, weAnd afterward by substitute betroth'd\n",
      "To Bona, sister to the King of France.\n",
      "These both put by a poor petitioner,, all see,\n",
      "And like her most whose merit most shall be:\n",
      "Which on more view, of many mine being one\n",
      "May stand\n",
      "Ay, and for an assault too.\n",
      "\n",
      "Third Servingman:\n",
      "O slaves, I can tell you news,-- news, you rascals!\n",
      "\n",
      " dukedom.\n",
      "\n",
      "MIRANDA:\n",
      "Would I might\n",
      "But ever see that man!\n",
      "\n",
      "PROSPERO:\n",
      "Now I arise\n",
      "We cannot weigh our brother with ourself:\n",
      "Great men may jest with saints; 'tis wit in them,\n",
      "But in the less foul profan mock me; this is not the way\n",
      "To win our daughter.\n",
      "\n",
      "QUEEN ELI ⁇ ABETH:\n",
      "There is no other way\n",
      "Und whosoe'er gainsays King Edward's right,\n",
      "By this I challenge him to single fight.\n",
      "\n",
      "All:\n",
      "L\n",
      "Had I it written, I would tear the word.\n",
      "\n",
      "JULIET:\n",
      "My ears have not yet drunk a hundred words\n",
      "Of that sweet sleep's disturbers\n",
      "Are they that I would have thee deal upon:\n",
      "Tyrrel, I mean those bastards in the Tower.\n",
      " as they say,\n",
      "At some hours in the night spirits resort;--\n",
      "Alack, alack, is it not like that I,\n",
      "So him, if this be so, a wrong\n",
      "Something unfilial: reason my son\n",
      "Should choose himself a wife, but as good,\n",
      "And thou shalt tell the process of their death.\n",
      "Meantime, but think how I may do thee good,\n",
      "And be in cry! Shall's to the Capitol?\n",
      "\n",
      "COMINIUS:\n",
      "O, ay, what else?\n",
      "\n",
      "SICINIUS:\n",
      "GoO Margaret, thus 'twill be; and thou, poor soul,\n",
      "Art then forsaken, as thou went'st forlorn!\n",
      "\n",
      "S:\n",
      "For what reason, I beseech you?\n",
      "\n",
      "GREMIO:\n",
      "For this reason, if you'll know,\n",
      "TYet best beseeming me to speak the truth.\n",
      "Would God that any in this noble presence\n",
      "Were enough noble to be upright judge\n",
      "O tell you, for the bawdy hand of the\n",
      "dial is now upon the prick of noon.\n",
      "\n",
      "Nurse:\n",
      "Out upon you!,\n",
      "Because his painted skin contents the eye?\n",
      "O, no, good Kate; neither art thou the worse\n",
      "For this poor furnThen get your husband's lands, to do them good.\n",
      "\n",
      "LADY GREY:\n",
      "Therefore I came unto your majesty.\n",
      "First Murderer:\n",
      "Relent! 'tis cowardly and womanish.\n",
      "\n",
      "CLARENCE:\n",
      "Not to relent is beastly, rank as any flax-wench that puts to\n",
      "Before her troth-plight: say't and justify't.\n",
      "\n",
      "CAMILLO more; whose very\n",
      "naming punishes me with the remembrance of that\n",
      "penitent, as thou callest him, and reconciled king,\n",
      "ing of a devilish spirit,\n",
      "Why dost thou wrong her that did ne'er wrong thee?\n",
      "When did she cross thee with a bitter word wife hath a pretty foot,\n",
      "A cherry lip, a bonny eye, a passing pleasing tongue;\n",
      "And that the queen's kindred areHer natural posture!\n",
      "Chide me, dear stone, that I may say indeed\n",
      "Thou art Hermione; or rather, thou art she:\n",
      "Thou wretch, despite o'erwhelm thee!\n",
      "What should the people do with these bald tribunes?\n",
      "On whom depending, their no place for you: pray, go to the door.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have deserved no better entertainment,\n",
      "In being Coriolanus.\n",
      "PETRUCHIO:\n",
      "How fares my Kate? What, sweeting, all amort?\n",
      "\n",
      "HORTENSIO:\n",
      "Mistress\n",
      "I have night's cloak to hide me from their sight;\n",
      "And but thou love me, let them find me here:\n",
      "My life were youth and cause, I would not stay.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Then, England's ground, farewell; sweet soil, adieu;\n",
      " with all the size that verity\n",
      "Would without lapsing suffer: nay, sometimes,\n",
      "Like to a bowl upon a subtle ground,\n",
      "ing. Sooth, when I was young\n",
      "And handed love as you do, I was wont\n",
      "To load my she with knacks: day.\n",
      " ⁇  KING HENRY VI\n",
      "\n",
      "WARWICK:\n",
      "Forspent with toil, as runners with a race,\n",
      "I lay meta'en suspicion! Come, Camillo;\n",
      "I will respect thee as a father if\n",
      "Thou bear'st my life off hence: let us avoid ⁇ ABETH:\n",
      "The king! why, who's that?\n",
      "\n",
      "BRAKENBURY:\n",
      "I cry you mercy: I mean the lord protector.\n",
      "\n",
      "Lord:\n",
      "Bid them come near.\n",
      "Now, fellows, you are welcome.\n",
      "\n",
      "Players:\n",
      "We are not mad\n",
      "Have, sure, more lack of reason. What would you say?\n",
      "\n",
      "ISABELLA:\n",
      "I am the sister of one think, there's one\n",
      "at home for you.\n",
      "\n",
      "MENENIUS:\n",
      "I will make my very house reel tonight: a letter forThat we could hear no news of his repair?\n",
      "\n",
      "KING EDWARD IV:\n",
      "Now, Warwick, wilt thou ope the city gates,\n",
      "s' blood!\n",
      "\n",
      "QUEEN ELI ⁇ ABETH:\n",
      "O, that thou wouldst as well afford a grave\n",
      "As thou canst yield a melancholy seat unless a hare, sir, in a lenten pie,\n",
      "that is something stale and hoar ere it be spent.\n",
      "An old hare hoar,\n",
      " came to talk of. Tell me, daughter Juliet,\n",
      "How stands your disposition to be married?\n",
      "\n",
      "JULIET:\n",
      "It is an honours shame, grave's due by life usurp'd,\n",
      "Brief abstract and record of tedious days,\n",
      "Rest thy unrest on England' all that look upon with marvel. Come,\n",
      "I'll fill your grave up: stir, nay, come away,\n",
      "Bequeath to death your:\n",
      "So proud that Bolingbroke was on his back!\n",
      "That jade hath eat bread from my royal hand;\n",
      "This hand hath made him proud with good my friend,\n",
      "What torch is yond, that vainly lends his light\n",
      "To grubs and eyeless skulls? as I discern,\n",
      " worth such gazes\n",
      "Than what you look on now.\n",
      "\n",
      "LEONTES:\n",
      "I thought of her,\n",
      "Even in these looks I made lives but crosses, cares and grief.\n",
      "Your husband, he is gone to save far off,\n",
      "Whilst others come to make him lose; 'tis I.\n",
      "Speak with me, pity me, open the door.\n",
      "A beggar begs that never begg'd before.\n",
      "\n",
      ", give me your hands: nay, dry your eyes;\n",
      "Tears show their love, but want their remedies.\n",
      "Cousin, I am too young gods be good to us! Come, masters, let's home.\n",
      "I ever said we were i' the wrong when we banished\n",
      "him.\n",
      "What shall I do? say what; what shall I do?\n",
      "\n",
      "PROSPERO:\n",
      "Go make thyself like a nymph o' theShepherd:\n",
      "What, art so near? If thou'lt see a thing to talk\n",
      "on when thou art dead and rotten, come hither. to my God, my king, and me:\n",
      "And as I truly fight, defend me heaven!\n",
      "\n",
      "KING RICHARD II:\n",
      "Mars the process of their death.\n",
      "Meantime, but think how I may do thee good,\n",
      "And be inheritor of thy desire.\n",
      "Yield not thy neck\n",
      "To fortune's yoke, but let thy dauntless mind\n",
      "Still ride in triumph over all mischance.\n",
      "BeShall for the fault make forfeit of his head.\n",
      "King Edward, valiant Richard, Montague,\n",
      "Stay we no longer, dreaming of renown me in name of fault, I must not\n",
      "At all acknowledge. For Polixenes,\n",
      "With whom I am accused, I do confess\n",
      "I loved George Stanley is frank'd up in hold:\n",
      "If I revolt, off goes young George's head;\n",
      "The fear of that withholds myow, brother Richard, Lord Hastings, and the rest,\n",
      "Yet thus far fortune maketh us amends,\n",
      "And says that once more I\n",
      "\n",
      "ISABELLA:\n",
      "I have a brother is condemn'd to die:\n",
      "I do beseech you, let it be his fault,\n",
      "A\n",
      "Nor I; my spirits are nimble.\n",
      "They fell together all, as by consent;\n",
      "They dropp'd, as by a: thou mettest with things\n",
      "dying, I with things newborn. Here's a sight for\n",
      "thee; look thee, a bearingFor mocking marriage with a dame of France.\n",
      "\n",
      "WARWICK:\n",
      "I came from Edward as ambassador,\n",
      "But I return hised upon a hot and fiery steed\n",
      "Which his aspiring rider seem'd to know,\n",
      "With slow but stately pace kept on his your bearts will thereto add\n",
      "'Tis pity she's not honest, honourable:'\n",
      "Praise her but for this her without-door form,'s bread! it makes me mad:\n",
      "Day, night, hour, tide, time, work, play,\n",
      "Alone, in companySo shall you quietly enjoy your hope,\n",
      "And marry sweet Bianca with consent.\n",
      "\n",
      "LUCENTIO:\n",
      "Were it not that my:\n",
      "I told your majesty as much before:\n",
      "This proveth Edward's love and Warwick's honesty.\n",
      "\n",
      "WARWICK:\n",
      "Kour queen and I are devils: yet go on;\n",
      "The offences we have made you do we'll answer,\n",
      "If you first sinn''s voice: remains\n",
      "That, in the official marks invested, you\n",
      "Anon do meet the senate.\n",
      "\n",
      "CORIO I would I cannot,--\n",
      "With best advantage will deceive the time,\n",
      "And aid thee in this doubtful shock of arms:\n",
      "But onUKE VINCENTIO:\n",
      "By the vow of mine order I warrant you, if my\n",
      "instructions may be your guide. Let this Barnardine\n",
      " marted with him. If your lass\n",
      "Interpretation should abuse and call this\n",
      "Your lack of love or bounty, you were stra and what they are that must\n",
      "Be hostages for Rome.\n",
      "\n",
      "First Soldier:\n",
      "Will not you go?\n",
      "\n",
      "AUFIDIUSould be glad to receive some instruction from my\n",
      "fellow partner.\n",
      "\n",
      "Provost:\n",
      "What, ho! Abhorson! Where's Ab.\n",
      "Your highness said even now, I made you a duke:\n",
      "good my lord, do not recompense me in making me a cuckold.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Unrotled hewing at one or, and make it\n",
      "fromr'd up remorse than is the worst?\n",
      "These lordsly pro have yet beheld his laming,\n",
      "Of thee thyself of the world, to short mine heads\n",
      "Which God revenge Tybalt.\n",
      "\n",
      "First Citizen:\n",
      "Indeed, he would be sworn, being all, you must not.\n",
      "\n",
      "GRUMIO:\n",
      "If it be so, if you not so.\n",
      "\n",
      "First Senator:\n",
      "Tut, tut!\n",
      "Grace me no grace, nor uncle me no uncle:\n",
      "I mean, if your brother by your\n",
      "habit at usment would clothe the villain.\n",
      "\n",
      "All:\n",
      "We will so: almost all\n",
      "Repent in me,\n",
      "And tell down what in this, shall be thy sepulchre,\n",
      "Fo seen the fow of the time,\n",
      "And urged it twice together deeds,\n",
      "We may surprot, my gracious lord--\n",
      "\n",
      "PERDITA:\n",
      "She is too general.\n",
      "Privy you to bid them said, for he is pity of\n",
      "thisike.\n",
      "\n",
      "PETRUCHIO:\n",
      "Well, what was done?\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "For Angelo, old Gaunt we more but hear to\n",
      "These accusations and back by time,\n",
      "Whose sting is sharper than the sword's;\n",
      "and, not, fellow, thelerter hours is it.\n",
      "\n",
      "BAPTISTA:\n",
      "You're welcome, sir; and he, at day, nurse,\n",
      "It was an hundred a man.' for\n",
      "How bear the foe should live to-day,\n",
      "I would ragein in those and nature\n",
      "Shall call thy friends to thought.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Repent you but he was a gentleman\n",
      "on your sheep, play, ay.\n",
      "\n",
      "HORTENSIO:\n",
      "For both our sakes, I would.\n",
      "Either of pure\n",
      "you must not call it hence?\n",
      "What mean you, sir?\n",
      "\n",
      "PETRUCHIO:\n",
      "Villain, I say, knock me here soundly.\n",
      "\n",
      "GREEN:\n",
      "My lord!\n",
      "\n",
      "KING RICHARD III:\n",
      "' ⁇ ounds! who is there?\n",
      "\n",
      "RATCLIFF:\n",
      "Ratcliff, my lord; 'tis I. The early village-cock\n",
      "Hath not that very noble soldiers with tears.\n",
      "\n",
      "LADY GREY:\n",
      "Why, then I will do what your grace commands.\n",
      "\n",
      "GLOUCESTER:\n",
      "Why, she's a devil, a devil, the devil's dam.\n",
      "\n",
      "GREMIO:\n",
      "Tut, she's a lamb, a dove, a trick to come.\n",
      "\n",
      "BENVOLIO:\n",
      "Be ruled a husband of all that he doth possess,\n",
      "That's bitter a lad.\n",
      "\n",
      "YORK:\n",
      "She's not well married that lives married long;\n",
      "I rather soly care? What,\n",
      "the name that is common; which if you are mortal:\n",
      "I do love thee to a wife.\n",
      "\n",
      "POMPEY:\n",
      "Well, sir; what says the traitor something?\n",
      "\n",
      "BRAKENBURY:\n",
      "I do she not well.\n",
      "\n",
      "PETRUCHIO:\n",
      "Carry'st Jove to thy fair cheer;\n",
      "Unless his name hath look'd upon from night:\n",
      "And when the morning sun shall raise his car\n",
      "Above the border of this horizon,\n",
      "We'll forward towards Warwick and his mates;\n",
      "For queen is justless a mind of fourscore hence\n",
      "Than they are almost to see the crown, but\n",
      "my grave for me, say that you have power from\n",
      "very nothing o' the city; and his\n",
      "name is first better.\n",
      "\n",
      "CORIOLANUS:\n",
      "Tullus Aufidius are like a drum,\n",
      "Which lively holding ever earn himself wander,\n",
      "Wast part at our solemnity' mind?\n",
      "\n",
      "HASTINGS:\n",
      "Sweet widow, do not recompense again.\n",
      "\n",
      "ANGELO:\n",
      " thou'rt a flower; thou art a horse:\n",
      "Commun upon the threefold gate;\n",
      "The which, how bright me forgets,\n",
      "So sweet is zealous contemplation.\n",
      "\n",
      "Lord Mayor:\n",
      "See, where, sure, live in us he wept,\n",
      "Let them hear thee, yet remember hath ministered prosperous,\n",
      "So rare, my lady, here by another's your wants,\n",
      "Sometimes me 'em! in that mercy!\n",
      "\n",
      "COMINIUS:\n",
      "Your\n"
     ]
    }
   ],
   "source": [
    "n_embed = 64   # m in Bengio\n",
    "n_hidden = 512  # h in Bengio\n",
    "device = \"cpu\"\n",
    "max_epochs = 51\n",
    "train_lr = False\n",
    "lr = 0.0002\n",
    "threshold = 0.02\n",
    "vocab_size = 8196\n",
    "\n",
    "name = 'shakepeare'\n",
    "train_dl, val_dl, spw = define_data(name, vtype, block_size, batch_size, vocab_size)\n",
    "\n",
    "\n",
    "class MetricTracker(pl.Callback):\n",
    "\n",
    "  def __init__(self, data_dl, spw):\n",
    "    self.predict_dl = data_dl\n",
    "    self.spw = spw\n",
    "    self.count = 0\n",
    "\n",
    "\n",
    "  def on_validation_epoch_end(self, trainer, model):\n",
    "    print (f\"Current validation loss for epoch {self.count} is: {trainer.callback_metrics['val_loss'].item():7.4f}\")\n",
    "\n",
    "    if self.count % 1 == 0:\n",
    "        x, y = next(iter(self.predict_dl))\n",
    "        idx = x[0].view(1,-1)\n",
    "        for i in range(200):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits = model.model(idx_cond)\n",
    "\n",
    "            B, T = idx_cond.shape\n",
    "            \n",
    "            logits = logits.view(B, T, vocab_size)\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        my_str = self.spw.Decode(idx.tolist())[0]\n",
    "\n",
    "        f = open(\"timemachine_examples.txt\", \"a\")\n",
    "        f.write(f\"\\n\\n* For epoch {self.count} with loss {trainer.callback_metrics['val_loss'].item():7.4f}:\\n\\n{my_str}\\n\\n\\n\\n------------------------------\\n\\n\")\n",
    "        f.close()\n",
    "    self.count += 1\n",
    "\n",
    "\n",
    "    #print (b)\n",
    "    # do whatever is needed\n",
    "\n",
    "cb = MetricTracker(DataLoader(next(iter(train_dl)), batch_size=batch_size, shuffle=True), spw)\n",
    "\n",
    "\n",
    "# Define model to use\n",
    "#model = Bengio2003(vocab_size, n_embed, n_hidden, block_size)\n",
    "model = MikolovRNN2010(vocab_size, n_embed, n_hidden)\n",
    "\n",
    "# Initialize model\n",
    "x, y = next(iter(train_dl))\n",
    "_ = model(x)\n",
    "\n",
    "# Define Lighting Module\n",
    "my_model = LLM(model, vocab_size, lr=lr, max_epochs=max_epochs, threshold=threshold)\n",
    "\n",
    "\n",
    "# Define Trainer and train\n",
    "if train_lr:\n",
    "    trainer = pl.Trainer()\n",
    "    lr_finder = trainer.tuner.lr_find(model=my_model, train_dataloaders=train_dl, num_training=500)\n",
    "\n",
    "    # Plot with\n",
    "    fig = lr_finder.plot(suggest=True)\n",
    "    fig.show()\n",
    "\n",
    "    # Pick point based on plot, or get suggestion\n",
    "    new_lr = lr_finder.suggestion()\n",
    "\n",
    "    print (f'Suggested learning rate lr = {new_lr:.6f}')\n",
    "else:\n",
    "\n",
    "    '''\n",
    "    trainer = pl.Trainer()\n",
    "    lr_finder = trainer.tuner.lr_find(model=my_model, train_dataloaders=train_dl, num_training=500)\n",
    "\n",
    "    # Plot with\n",
    "    #fig = lr_finder.plot(suggest=True)\n",
    "    #fig.show()\n",
    "\n",
    "    # Pick point based on plot, or get suggestion\n",
    "    lr = lr_finder.suggestion()\n",
    "\n",
    "    print (f'Suggested learning rate lr = {lr:.6f}')\n",
    "    '''\n",
    "    \n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, accelerator=device, devices=1,  callbacks=[cb,\n",
    "                        TQDMProgressBar(refresh_rate=100), LearningRateMonitor(\"epoch\"), \n",
    "                        ModelCheckpoint(mode=\"min\", monitor=\"val_loss\"), \n",
    "                        EarlyStopping(monitor=\"val_loss\", patience=3, min_delta = threshold, verbose=False, mode=\"min\")],\n",
    "                        enable_progress_bar=True)\n",
    "\n",
    "    trainer.fit(model=my_model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "\n",
    "\n",
    "    # Validate results\n",
    "    my_model2 = my_model.to(\"cpu\")\n",
    "    trainer2 = pl.Trainer()\n",
    "    trainer2.validate(my_model2, val_dl)\n",
    "\n",
    "    predict_dl = DataLoader(next(iter(train_dl)), batch_size=batch_size, shuffle=True)\n",
    "    idx = trainer2.predict(my_model2, predict_dl)\n",
    "    print (spw.Decode(idx[0].tolist())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   128    32    32  2.908'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"vocab_size: {vocab_size:6d}, n_embed: {n_embed:5d}, n_hidden: {n_hidden:5d}, val_loss: {trainer.callback_metrics['val_loss'].item():.3f}\"\n",
    "f\"{vocab_size:6d} {n_embed:5d} {n_hidden:5d} {trainer.callback_metrics['val_loss'].item():6.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with vocab_size:    128, n_embed:    32, n_hidden:    32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 10.4 K\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:    128, n_embed:    32, n_hidden:    32, val_loss: 2.589\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:    256, n_embed:    32, n_hidden:    32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 14.5 K\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "14.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.5 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00018: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:    256, n_embed:    32, n_hidden:    32, val_loss: 3.060\n",
      "Boo, did worse!\n",
      "Trying with vocab_size:    256, n_embed:    32, n_hidden:    64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 31.1 K\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "31.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.1 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00021: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:    256, n_embed:    32, n_hidden:    64, val_loss: 2.503\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:    512, n_embed:    32, n_hidden:    64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 39.3 K\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "39.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "39.3 K    Total params\n",
      "0.157     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00030: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:    512, n_embed:    32, n_hidden:    64, val_loss: 2.679\n",
      "Boo, did worse!\n",
      "Trying with vocab_size:    512, n_embed:    32, n_hidden:   128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 103 K \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.413     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00030: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:    512, n_embed:    32, n_hidden:   128, val_loss: 1.487\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:   1024, n_embed:    32, n_hidden:   128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 119 K \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "119 K     Trainable params\n",
      "0         Non-trainable params\n",
      "119 K     Total params\n",
      "0.478     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00038: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:   1024, n_embed:    32, n_hidden:   128, val_loss: 1.253\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:   2048, n_embed:    32, n_hidden:   128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 152 K \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "152 K     Trainable params\n",
      "0         Non-trainable params\n",
      "152 K     Total params\n",
      "0.609     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00042: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:   2048, n_embed:    32, n_hidden:   128, val_loss: 0.976\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:   4096, n_embed:    32, n_hidden:   128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 217 K \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "217 K     Trainable params\n",
      "0         Non-trainable params\n",
      "217 K     Total params\n",
      "0.871     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00039: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:   4096, n_embed:    32, n_hidden:   128, val_loss: 0.816\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:   8192, n_embed:    32, n_hidden:   128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | MikolovRNN2010   | 348 K \n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "348 K     Trainable params\n",
      "0         Non-trainable params\n",
      "348 K     Total params\n",
      "1.396     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate lr = 0.001000\n",
      "Epoch 00041: reducing learning rate of group 0 to 5.0000e-04.\n",
      "vocab_size:   8192, n_embed:    32, n_hidden:   128, val_loss: 0.686\n",
      "Hurray, did better!\n",
      "Trying with vocab_size:  16384, n_embed:    32, n_hidden:   128\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Internal: /Users/runner/work/sentencepiece/sentencepiece/src/trainer_interface.cc(660) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (16384). Please set it to a value <= 15611.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtimemachine\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39m#name = 'shakepeare'\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train_dl, val_dl, spw \u001b[39m=\u001b[39m define_data(name, vtype, block_size, batch_size, vocab_size)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Define model to use\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m#model = Bengio2003(vocab_size, n_embed, n_hidden, block_size)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[39m=\u001b[39m MikolovRNN2010(vocab_size, n_embed, n_hidden)\n",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m, in \u001b[0;36mdefine_data\u001b[0;34m(name, vtype, block_size, batch_size, vocab_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m textt \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(filet, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mread()\n\u001b[1;32m     40\u001b[0m \u001b[39m# Create sentancepiece model\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m spm\u001b[39m.\u001b[39;49mSentencePieceTrainer\u001b[39m.\u001b[39;49mtrain(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mfilet, vocab_size\u001b[39m=\u001b[39;49mvocab_size,\n\u001b[1;32m     42\u001b[0m                                model_type\u001b[39m=\u001b[39;49mvtype, model_prefix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmb\u001b[39;49m\u001b[39m'\u001b[39;49m, user_defined_symbols\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     43\u001b[0m                                minloglevel\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Language Model (BPE)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m spw \u001b[39m=\u001b[39m spm\u001b[39m.\u001b[39mSentencePieceProcessor(\u001b[39m'\u001b[39m\u001b[39mmb.model\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentencepiece/__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[0;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTrain\u001b[39m(arg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, logstream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    988\u001b[0m   \u001b[39mwith\u001b[39;00m _LogStream(ostream\u001b[39m=\u001b[39mlogstream):\n\u001b[0;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[39m.\u001b[39;49m_Train(arg\u001b[39m=\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentencepiece/__init__.py:982\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39m_TrainFromMap2(new_kwargs, sentence_iterator)\n\u001b[1;32m    981\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39;49m_TrainFromMap(new_kwargs)\n\u001b[1;32m    984\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentencepiece/__init__.py:927\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromMap\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    926\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_TrainFromMap\u001b[39m(args):\n\u001b[0;32m--> 927\u001b[0m     \u001b[39mreturn\u001b[39;00m _sentencepiece\u001b[39m.\u001b[39;49mSentencePieceTrainer__TrainFromMap(args)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Internal: /Users/runner/work/sentencepiece/sentencepiece/src/trainer_interface.cc(660) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (16384). Please set it to a value <= 15611."
     ]
    }
   ],
   "source": [
    "n_embed = 32   # m in Bengio\n",
    "n_hidden = 32  # h in Bengio\n",
    "device = \"cpu\"\n",
    "max_epochs = 50\n",
    "train_lr = False\n",
    "lr = 0.001\n",
    "threshold = 0.03\n",
    "old_loss = 9999.\n",
    "vocab_size = 128\n",
    "\n",
    "dmodel = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    print(f\"Trying with vocab_size: {vocab_size:6d}, n_embed: {n_embed:5d}, n_hidden: {n_hidden:5d}\")\n",
    "\n",
    "    # Get data\n",
    "    name = 'timemachine'\n",
    "    #name = 'shakepeare'\n",
    "    train_dl, val_dl, spw = define_data(name, vtype, block_size, batch_size, vocab_size)\n",
    "\n",
    "    # Define model to use\n",
    "    #model = Bengio2003(vocab_size, n_embed, n_hidden, block_size)\n",
    "    model = MikolovRNN2010(vocab_size, n_embed, n_hidden)\n",
    "\n",
    "    # Define Lighting Module\n",
    "    my_model = LLM(model, vocab_size, lr=lr, max_epochs=max_epochs, threshold=threshold)\n",
    "\n",
    "    print (f'Suggested learning rate lr = {lr:.6f}')\n",
    "    \n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, accelerator=device, devices=1,  callbacks=[\n",
    "                        ModelCheckpoint(mode=\"min\", monitor=\"val_loss\"), \n",
    "                        EarlyStopping(monitor=\"val_loss\", patience=3, min_delta = threshold, verbose=False, mode=\"min\")],\n",
    "                        enable_progress_bar=False, logger=False)\n",
    "\n",
    "    trainer.fit(model=my_model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "    my_str = f\"vocab_size: {vocab_size:6d}, n_embed: {n_embed:5d}, n_hidden: {n_hidden:5d}, val_loss: {:.3f}\"\n",
    "    print(my_str)\n",
    "    f = open(\"timemachine_results.txt\", \"a\")\n",
    "    f.write(f\"{vocab_size:6d} {n_embed:5d} {n_hidden:5d} {trainer.callback_metrics['val_loss'].item():6.3f}\\n\")\n",
    "    f.close()\n",
    "\n",
    "    if trainer.callback_metrics['val_loss'].item() < old_loss:\n",
    "        print ('Hurray, did better!')\n",
    "        old_loss = trainer.callback_metrics['val_loss'].item()\n",
    "        vocab_size = 2*vocab_size\n",
    "        dmodel = 0\n",
    "\n",
    "    else:\n",
    "        print ('Boo, did worse!')\n",
    "        if dmodel == 0:\n",
    "            n_hidden = 2*n_hidden\n",
    "        if dmodel == 1:\n",
    "            pass            \n",
    "        if dmodel == 2:\n",
    "            #n_hidden = 2*n_hidden\n",
    "            n_embed = 2*n_embed\n",
    "        if dmodel == 3:\n",
    "            pass\n",
    "        if dmodel == 4:\n",
    "            #n_embed = 2*n_embed\n",
    "            break\n",
    "        #if dmodel == 5:\n",
    "        #    pass\n",
    "        #if dmodel == 6:\n",
    "        #    break\n",
    "        dmodel += 1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"timemachine_results.txt\", \"a\")\n",
    "f.write(f\"{vocab_size:6d} {n_embed:5d} {n_hidden:5d} {trainer.callback_metrics['val_loss'].item():6.3f}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hello\n",
      "1\n",
      "hello\n",
      "2\n",
      "hello\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print (i)\n",
    "    if i > 1:\n",
    "        if i > 2:\n",
    "            break\n",
    "    print ('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935b28b818084594b4bdaf03e42da944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.6904611587524414     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.6904611587524414    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f842b26d46477090f51093127d53f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMINIUS:\n",
      "Come, come, we'll prompt you.\n",
      "\n",
      "VOLUMNIA:\n",
      "I prCORIOLANUS:\n",
      "What must I say?\n",
      "'I Pray, sir'--Plague upon'tstice;\n",
      "For then I pity those I do not know,\n",
      "Which a dismiss'd offence would aff I may have your daughter to my wife,\n",
      "I'll leave her houses three or fourI promised here to meet.\n",
      "\n",
      "MARIANA:\n",
      "You have not been inquired afterd by the sun,\n",
      "So I by that; it is my day, my life.\n",
      "\n",
      "LADY ANNE::\n",
      "Come, son, away; we may not linger thus.\n",
      "\n",
      "KING HENRY VI:\n",
      "ship,\n",
      "Where one part does disdain with cause, the other\n",
      "Insult with up my friends, and meet your grace\n",
      "Where and what time your majesty shall please.\n",
      "No man knows whither.\n",
      "\n",
      "KING RICHARD III:\n",
      "I cry thee mercy:\n",
      "There is him from sleep.\n",
      "\n",
      "LEONTES:\n",
      "What noise there, ho?\n",
      "\n",
      "PAULINA:ear her hour.\n",
      "\n",
      "ANGELO:\n",
      "Dispose of her\n",
      "To some more fitter place, andOMINIUS:\n",
      "He would not seem to know me.\n",
      "\n",
      "MENENIUS:\n",
      "Do you hear?\n",
      "\n",
      "COM and why not I?\n",
      "\n",
      "Second Keeper:\n",
      "Ay, but thou talk'st as if thou wer as I?\n",
      "But who comes here?\n",
      "\n",
      "GREMIO:\n",
      "Good morrow, neighbour BROKE:\n",
      "You shall.\n",
      "\n",
      "KING RICHARD II:\n",
      "Then give me leave to go.\n",
      "\n",
      "HEN suppose we are made to be no stronger\n",
      "Than faults may shake our frames,--le all deaths are too few, the sharpest too easy.\n",
      "\n",
      "Clown:\n",
      "Has the old man and, after much debatement,\n",
      "My sisterly remorse confutes mine honour,est fault?\n",
      "I would not lose the dog for twenty pound.\n",
      "\n",
      "First Huntsman:ful man:\n",
      "Affliction is enamour'd of thy parts,\n",
      "And thou art weddocks at it and sets it light.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "O, who can my master is mad.\n",
      "\n",
      "PETRUCHIO:\n",
      "Now, knock when I bid you, sirrah\n",
      "And am to Padua come, as he that leaves\n",
      "A shallow plash to plunge him in the de thy children? wherein dost thou, joy?\n",
      "Who sues to thee and cries 'God saassion\n",
      "And so offend him; for I tell you, sirs,\n",
      "If you should smile he growsthe matter, he makes the maid to answer 'Whoop, do me\n",
      "no har being twain.\n",
      "\n",
      "PROSPERO:\n",
      "\n",
      "MIRANDA:\n",
      "Why speaks my father being angry, does forget that ever\n",
      "He heard the name of death.\n",
      "Here's goodonicled in hell.\n",
      "This dead king to the living king I'll bear\n",
      "Take hence theosed, you quake like rebels?\n",
      "O gentle villain, do not turn away!\n",
      "\n",
      "G.\n",
      "\n",
      "COMINIUS:\n",
      "I have been i' the market-place; and, sir,'tghter, and a goodly babe,\n",
      "Lusty and like to live: the queen receives\n",
      " emmence that fills it up,\n",
      "I stagger in:--but this new governor\n",
      "Aus one fair word,\n",
      "One nick-name for her purblind son and heir,\n",
      "Young wast thou with Rosaline?\n",
      "\n",
      "ROMEO:\n",
      "With Rosaline, my ghostly fatherere it not pity that this goodly boy\n",
      "Should lose his birthright by his father's fault be call'd\n",
      "The field of Golgotha and dead men's skulls.\n",
      "Oeny it,\n",
      "'Tis none of mine.\n",
      "\n",
      "LEONTES:\n",
      "Ha' not you seen, Cam this business. To-morrow next\n",
      "We will for Ireland; and 'tis time, I tDraw near,\n",
      "And list what with our council we have done.\n",
      "For that our kingdomDIUS:\n",
      "Condition!\n",
      "I would I were a Roman; for I cannot,\n",
      "Being a Volad--\n",
      "To plague thee for thy foul misleading me.\n",
      "And so, proud-heow by my soul, I would it were this hour.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Fitz:\n",
      "Let us take the law of our sides; let them begin.\n",
      "\n",
      "GREGORY: woe to woe, sorrow to sorrow join'd.\n",
      "\n",
      "BUSHY:\n",
      "Desp with him as I prove true to you.\n",
      "\n",
      "Messenger:\n",
      "My gracious sovereign, now in the prevention of poor Bolingbroke\n",
      "About his marriage, nor my own disgth from the mighty power of the king.\n",
      "\n",
      "RICHMOND:\n",
      "If without peril it be po No. Yes, I am:\n",
      "Then fly. What, from myself? Great reason why:\n",
      "Lestlaim a pardon to the soldiers fled\n",
      "That in submission will return toy did make thee offer,\n",
      "The resignation of thy state and crown\n",
      "To Henry Bolingan cross\n",
      "Against black pagans, Turks, and Saracens:\n",
      "Aition,\n",
      "Concluding 'Stay: not yet.'\n",
      "\n",
      "PROSPERO:\n",
      "T\n",
      "I talk not of your soul: our compell'd sins\n",
      "Stand more for number thanural lord\n",
      "Can do no more.\n",
      "\n",
      "LEONTES:\n",
      "I'll ha' thee burnt.\n",
      "\n",
      "ay with your findings. I'll go see\n",
      "if the bear be gone from the gentleman and how much\n",
      "heIOLANUS:\n",
      "Hear'st thou, Mars?\n",
      "\n",
      "AUFIDIUS:\n",
      "Name not the godought you,--for the stone is mine--\n",
      "I'ld not have show'd it.\n",
      "\n",
      "LEONTESord:\n",
      "Do as thou wilt, for I have done with thee.\n",
      "\n",
      "JULIET:\n",
      "O God!--Oeantime, but think how I may do thee good,\n",
      "And be inheritor of thy desire.\n",
      "Farewell him repair to us to Ely House\n",
      "To see this business. To-morrow next\n",
      " all the world is cheered by the sun,\n",
      "So I by that; it is my day, my life.\n",
      "\n",
      " blood,\n",
      "Nor thou within the compass of my curse.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Nor,\n",
      "Where it perceives it is but faintly borne.\n",
      "Go, say I sent thee forut, you saw her fair, none else being by,\n",
      "Herself poised with herself in either ey;\n",
      "So true men yield, with robbers so o'ermatch'd.\n",
      "\n",
      "NORT aside, and with the other sends\n",
      "It back to Tybalt, whose dexterity, word.\n",
      "\n",
      "CAMILLO:\n",
      "\n",
      "FLORI ⁇ EL:\n",
      "Fortune speed us!\n",
      "\n",
      "And rather like a dream than an assurance\n",
      "That my remembrance warrants. upon record, or else reported\n",
      "Successively from age to age, he buil and gravest citizens\n",
      "Have hent the gates, and very near upon\n",
      "The duCan be but brief; for I have made him know\n",
      "I have a servant comes with me along,\n",
      " do\n",
      "we jest now, think you?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Sir, induced by my char.\n",
      "\n",
      "AEdile:\n",
      "Very well.\n",
      "\n",
      "SICINIUS:\n",
      "Make them be strong and re now, my as fair as noble ladies,--and the moon,\n",
      "were she earthly, no nobon to aught against him.\n",
      "\n",
      "BUCKINGHAM:\n",
      "What think'st thou, then, of St\n",
      "This sudden stag of rancour I misdoubt:\n",
      "Pray God, I saysed womb, the bed of death!\n",
      "A cockatrice hast thou hatch'd to the world,:\n",
      "Then, as I said, the duke, great Bolingbroke,\n",
      "Mounted upon a grace, which never\n",
      "My life may last to answer.\n",
      "\n",
      "LEONTES:\n",
      "O Paul But come; our dance, I pray:\n",
      "Your hand, my Perdita: so turtles pairands in the level of your dreams,\n",
      "Which I'll lay down.\n",
      "\n",
      "LEONTUDIO:\n",
      "Thanks, dear Isabel.\n",
      "\n",
      "ISABELLA:\n",
      "Be read's death was plotted,\n",
      "I heard you say, 'Is not my arm of length,\n",
      "That at two hours old\n",
      "'Twas full two years ere I could get a toin'd to appear thus: if one jot beyond\n",
      "The bound of honour, or in act or willull of tears, I cannot see:\n",
      "And yet salt water blinds them not so much\n",
      "REMIO:\n",
      "A bridegroom say you? 'tis a groom indeed,\n",
      "A grumhat wounds the unsisting postern with these strokes.\n",
      "\n",
      "Provost:\n",
      "There heUS:\n",
      "Nay! prithee, woman,--\n",
      "\n",
      "VOLUMNIA:\n",
      "Now the redction cast him.\n",
      "\n",
      "BRUTUS:\n",
      "AEdiles, seize him!\n",
      "\n",
      "Citil unto his captain Christ,\n",
      "Under whose colours he had fought so long will pluck on sin:\n",
      "Tear-falling pity dwells not in this eye.\n",
      "Is thy n thought it would have mounted.\n",
      "See how my sword weeps for the poor king's death!\n",
      "Ozens:\n",
      "Faith, we hear fearful news.\n",
      "\n",
      "First Citizen:\n",
      "For mineBETH:\n",
      "It is determined, not concluded yet:\n",
      "But so it must be,k, and give it thee again.\n",
      "And yet I wish but for the thing I have:\n",
      "My bounty is as upon thy face again.\n",
      "Therefore take with thee my most heavy curse;\n",
      "Which, in the dayate and crown\n",
      "To Henry Bolingbroke.\n",
      "\n",
      "KING RICHARD II:\n",
      "Give me the crowide\n",
      "And spend her strength with over-matching waves.\n",
      "Ah, hark! no little thing to make\n",
      "Mine eyes to sweat compassion. But, good sir,\n",
      "What Watchman:\n",
      "O, is it so? But why commands the king\n",
      "That his chief follow Now, to seem to affect the malice and\n",
      "displeasure of the people is as:\n",
      "Go, see him out at gates, and follow him,\n",
      "As he hath followed you, with allivest thyself:\n",
      "'Tis he that sent us hither now to slaughter thee.\n",
      "\n",
      "CLARENion\n",
      "From off the rock Tarpeian never more\n",
      "To enter our Rome gates: i'.'\n",
      "\n",
      "MENENIUS:\n",
      "O me, the gods!\n",
      "You must not speak of that: you must desire lets it hop a little from her hand,\n",
      "Like a poor prisoner in his twisted g\n",
      "NORTHUMBERLAND:\n",
      "His noble kinsman: most degenerate king! than you should.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Take not, good cousin, further than you should.ick's bones may keep thine company.\n",
      "\n",
      "WARWICK:\n",
      "Ah, who is ned\n",
      "Which should bedeck thy shape, thy love, thy wit:\n",
      "Thy noble shape is but a form ofRUCHIO:\n",
      "\n",
      "Pedant:\n",
      "Lay hands on the villain: I believe a' meansV:\n",
      "But stay thee, 'tis the fruits of love I mean.\n",
      "\n",
      "LADY GREIO:\n",
      "Well, then, imprison him: if imprisonment be the\n",
      "due of a his state usurp'd,\n",
      "His realm a slaughter-house, his subject suits with slow delays;\n",
      "My pity hath been balm to heal their wounds,\n",
      " their shame,\n",
      "That many have and others must sit there;\n",
      "And in this thought they find a followers?\n",
      "\n",
      "Third Gentleman:\n",
      "Wrecked the same instant of their master'peach my height\n",
      "Before this out-dared dastard? Ere my tongue\n",
      "Shall wound\n",
      "\n",
      "BAPTISTA:\n",
      "Now, in good sadness, son Petruchio,\n",
      "I think thouto prized them at.\n",
      "\n",
      "MENENIUS:\n",
      "That's off, that's off;\n",
      "I would youNIA:\n",
      "Honourable Menenius, my boy Marcius approaches; for if you were a prince's son,\n",
      "Being pent from liberty, as I am now,\n",
      "if tw life, Petruchio means but well,\n",
      "Whatever fortune stays him from his word:\n",
      " miss my sense:\n",
      "I mean, Hortensio is afeard of you.\n",
      "\n",
      "Widow:\n",
      " will hence to Warwick's other daughter;\n",
      "That, though I want a kingdom,:\n",
      "'Twas sin before, but now 'tis charity.\n",
      "What, wilt thou not? Where he, your wife, this lady, and myself,\n",
      "Are suitors to you.\n",
      "\n",
      "CORIOLINA:\n",
      "No cock of mine; you crow too like a craven.\n",
      "\n",
      "PETRUCHIO:\n",
      "\n",
      "Unless you were of gentler, milder mould.\n",
      "\n",
      "KATHARINA:\n",
      "I Mayor:\n",
      "Amen.\n",
      "\n",
      "BUCKINGHAM:\n",
      "To-morrow will it please glasses you have burst?\n",
      "\n",
      "SLY:\n",
      "No, not a denier. Go by, man that but man is\n",
      "With nothing shall be pleased, till he be eased\n",
      "With being you know my fortunes\n",
      "Do all lie there: it shall be so my care\n",
      "To have you royally areams;\n",
      "And from the cross-row plucks the letter G.\n",
      "And says a wi deeds,\n",
      "Behold this pattern of thy butcheries.\n",
      "O, gentlemen, see, sees steal on,\n",
      "And flaky darkness breaks within the east.\n",
      "In bri herd?\n",
      "Must these have voices, that can yield them now\n",
      "And straight disclaimity is this Antium. City,\n",
      "'Tis I that made thy widows: many an heir\n",
      "O\n",
      "When what's not meet, but what must be, was law,\n",
      "Then were they chosen:, petty officer\n",
      "Would use his heaven for thunder;\n",
      "Nothing but thunder!ax\n",
      "Could not again undo: it was mine art,\n",
      "When I arrived and heard thee, thates\n",
      "Made up to the deed, doth push on this proceeding:\n",
      "Yet, for a greaterties be therefore drawn between us,\n",
      "That covenants may be kept on either hand harm but loss of such a lord.\n",
      "\n",
      "QUEEN ELI ⁇ ABETH:\n",
      "The loss ofor the prevention of poor Bolingbroke\n",
      "About his marriage, nor my own disp the beggary he was never born\n",
      "to. Lord Angelo dukes it well in hisn?\n",
      "\n",
      "BUCKINGHAM:\n",
      "I did; with his contract with Lady Lucy,\n",
      "s that kiss fair ladies' brows\n",
      "Being black put us in mind they hide the faading me.\n",
      "And so, proud-hearted Warwick, I defy thee,\n",
      "And to myver hear him.\n",
      "\n",
      "SICINIUS:\n",
      "Not?\n",
      "\n",
      "COMINIUS:\n",
      "I tell you, he does sit hath\n",
      "Served well for Rome,--\n",
      "\n",
      "CORIOLANUS:\n",
      "What do you prate of servhat is't your honour will command,\n",
      "Wherein your lady and your humble wife\n",
      "May:\n",
      "Good day, my lord. What, at your book so hard?\n",
      "\n",
      "KING HENRY VI:\n",
      " with lewd complaints.\n",
      "\n",
      "QUEEN ELI ⁇ ABETH:\n",
      "Brother of Gl,\n",
      "Are near to Warwick by blood and by alliance:\n",
      "Tell me if you love Warwick more thanCousin of Buckingham, and you sage, grave men,\n",
      "Since you will buckle fortBUCKINGHAM:\n",
      "I fear he will.\n",
      "How now, Catesby, what says your lord?\n",
      "\n",
      "Lord:\n",
      "Here in your city; I now came from him:\n",
      "I speak amazedly; and it heavy plight.\n",
      "\n",
      "KING LEWIS  ⁇ I:\n",
      "Renowned queen, with pati, my false o'erweighs your true.\n",
      "\n",
      "ISABELLA:\n",
      "To whse,\n",
      "With such austerity as 'longeth to a father.\n",
      "\n",
      "Pedant:\n",
      "I warrted, the poor Mariana\n",
      "advantaged, and the corrupt deputy scaaper.\n",
      "What, is my beaver easier than it was?\n",
      "And all my armour laid if heaven would,\n",
      "And we will not, heaven's offer we refuse,\n",
      "The proffer',\n",
      "You must report to the Volscian lords, how plainly\n",
      "I have borne this businalry,\n",
      "As is the sepulchre in stubborn Jewry,\n",
      "Of the world's\n",
      "Intends to appear before the people, hoping\n",
      "To purge herself with word, that had his teeth before his eyes,\n",
      "To worry lambs and lap their gentle blood,vost knows our purpose and our plot.\n",
      "The matter being afoot, keep your inake our eyes flow with joy, hearts dance\n",
      "with comforts,\n",
      "Constrains them weBut in your daughter's womb I bury them:\n",
      "Where in that nest of spiceryt were a shame to let this land by lease;\n",
      "But for thy world enjoying but this land,DUKE OF YORK:\n",
      "Well, bear you well in this new spring of time,\n",
      "Lest you be cs of Juliet's death;\n",
      "And then in post he came from Mantua\n",
      "To this same plghter came to look upon,\n",
      "The statue of her mother.\n",
      "\n",
      "PAULINA:\n",
      "As she the king\n",
      "In deadly hate the one against the other:\n",
      "And if King Edward be as true.'\n",
      "\n",
      "HERMIONE:\n",
      "'Tis grace indeed.\n",
      "Why, lo you now, I have sp\n",
      "'Tis meet so, daughter: but lest you do repent,\n",
      "As that the sin hath brouse blood\n",
      "Is very snow-broth; one who never feels\n",
      "The wanton stings it is to wear a crown;\n",
      "Within whose circuit is Elysium\n",
      "And all that'd hands;\n",
      "Swear by the duty that you owe to God--\n",
      "Our part therein we banThat e'er I put between your holy looks\n",
      "My ill suspicion. This isd\n",
      "from court and is less frequent to his princely\n",
      "exercises than formerly will draw you, Master Froth, and you\n",
      "will hang them. Get you gone, and let me hear fire and all:\n",
      "So I to her and so she yields to me;\n",
      "For I am rough and woo being trodden on,\n",
      "And doves will peck in safeguard of their brood.\n",
      "AmForbidden bandying in Verona streets:\n",
      "Hold, Tybalt! goodally!\n",
      "Why, it contains no king?\n",
      "\n",
      "HENRY PERCY:\n",
      "Yes, my good strength o' the commons,' be it either\n",
      "For death, for fine, or banishment until the officer\n",
      "Arise to let him in: he is call'd up.\n",
      "\n",
      "DUKE VINCENTIO: he lives in fame, though not in life.\n",
      "I'll tell you what, my cousin Buckingham,CLAUDIO:\n",
      "No.\n",
      "\n",
      "LUCIO:\n",
      "Lechery?\n",
      "\n",
      "CLAUDIO: in our throne, the east,\n",
      "His treasons will sit blushing in his face,\n",
      "Nld.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "How came it that the absent duke had not either\n",
      "delive's dooms-day, whose untimely death\n",
      "Banish'd the new-made bride soil'd\n",
      "With that dear blood which it hath fostered;\n",
      "And for our eyes do hate the d repent\n",
      "My part thereof that I have done to her.\n",
      "\n",
      "QUEEN ELI ⁇ ABETH: will\n",
      "Hath overta'en mine act.\n",
      "\n",
      "COMINIUS:\n",
      "You shall not be\n",
      "The gravehine being but a moiety of my grief,\n",
      "To overgo thy plaints and d him?\n",
      "Our slaughter'd friends the tackles; what of these?\n",
      "Why, is not Oong of\n",
      "you.\n",
      "\n",
      "SICINIUS:\n",
      "The gods be good unto us!\n",
      "\n",
      "MENENIUSook hands, as over a vast, and\n",
      "embraced, as it were, from the ends of oppose\n",
      "And make him of like spirit to himself.\n",
      "If any such be here--as God forbid!--\n",
      "Luilty kindred of the queen\n",
      "Look'd pale when they did hear of Clarence' death?inkle in his pilgrimage;\n",
      "Thy word is current with him for my death,\n",
      "But dese to sigh,\n",
      "Till I be brought to such a silly pass!\n",
      "\n",
      "BIANCA:\n",
      "for consulships?\n",
      "\n",
      "Second Officer:\n",
      "Three, they say: but 'd in thine eyes;\n",
      "And I, in such a desperate bay of death,\n",
      "Like a poors.\n",
      "If thou delight to view thy heinous deeds,\n",
      "Behold this pattern of see to do their amorous rites\n",
      "By their own beauties; or, if love be blind,\n",
      "It friendly, we have cross'd,\n",
      "To execute the charge my father gave me\n",
      "F on him that slew my husband.\n",
      "\n",
      "GLOUCESTER:\n",
      "He that bereft thee, lad;\n",
      "For Venus smiles not in a house of tears.\n",
      "Now, sir, her father couull of guile,\n",
      "Be he unto me! this do I beg of God,\n",
      "When I am chat weep'st to see me triumph? Ay, my dear,\n",
      "Such eyes the widows paramour?\n",
      "For fear of that, I still will stay with thee;\n",
      "And never from this palad,\n",
      "Or wring redress from you. Hear me, O hear me, here!\n",
      "\n",
      "ANGELO:ould be find up, my brother, with our thanks;\n",
      "And yet we should, for perpetuity,\n",
      "Gark oblivion.\n",
      "Which to recure, we heartily solicit\n",
      "Your gracious seget their loss of liberty.\n",
      "But, Warwick, after God, thou set'stoth entreat your grace;\n",
      "To visit him to-morrow or next day:\n",
      "He is within,\n",
      "Awaked the sleeping rheum, and so by chance\n",
      "Did grace our hollow parteds will be\n",
      "Absolute Milan. Me, poor man, my library\n",
      "Was dnd when thou fail'st--as God forbid the hour!--\n",
      "Must Edward fall, which peril you;\n",
      "Since I am charged in honour and by him\n",
      "That I think honourable: therefore mark my.\n",
      "'Lo, thus' quoth Dighton, 'lay those tender babes:'\n",
      "'Tble day, most woful day,\n",
      "That ever, ever, I did yet behold!\n",
      "O day! O daya for thy queen:\n",
      "So shalt thou sinew both these lands together;\n",
      "And, that kiss\n",
      "I carried from thee, dear; and my true lip\n",
      "Hath virgin'd itenna,\n",
      "Where I have seen corruption boil and bubble\n",
      "Till it o'er lay aside your stitchery; I must have you play\n",
      "the idle husewife with mePerchance shall dry your pities: but I have\n",
      "That honourable grief lodged heret\n",
      "To load my she with knacks: I would have ransack'd\n",
      "The pedlar's s:\n",
      "Go ask his name: if he be married.\n",
      "My grave is like to be my wedding be\n",
      "That's true enough;\n",
      "Through 'tis a saying, sir, not due to me.\n",
      "\n",
      "CAMILLO:\n",
      "I must believe you, sir:\n",
      "I do; and will fetch off Boock of the night than with the forehead\n",
      "of the morning: what I think I utter, and spend! the punto reverso! the\n",
      "hai!\n",
      "\n",
      "BENVOLIO:\n",
      "The what?\n",
      "\n",
      "Md and his treasure spent;\n",
      "And yonder is the wolf that makes this spoil.\n",
      "Y cannot stay to hear these articles.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Nor I,\n",
      "When once she is my wife.\n",
      "\n",
      "LEONTES:\n",
      "That 'once' I see byurn'd\n",
      "These terms of treason doubled down his throat.\n",
      "Sett:\n",
      "She will not.\n",
      "\n",
      "PETRUCHIO:\n",
      "The fouler fortune mine, and there anlp,\n",
      "Do thou but call my resolution wise,\n",
      "And with this knife I'll heledy, but you will,--give me the office\n",
      "To choose you a queen: she shall not be so will go with you: but yet I'll pause;\n",
      "For I am loath to break our country'sst\n",
      "thing about him. Good, then; if his face be the\n",
      "worst thing about him, how couldOHN OF GAUNT:\n",
      "Now He that made me knows I see thee ill;\n",
      "Ill in myst the duke my brother.\n",
      "Now, they believe it; and withal whet me\n",
      "To be re, our battalion trebles that account:\n",
      "Besides, the king's name is has done, consider; think\n",
      "Upon the wounds his body bears, which show\n",
      "L within my house,\n",
      "Fit to instruct her youth. If you, Hortensio,\n",
      "Or Smen are in sad talk, and we'll\n",
      "not trouble them. Come, bring away thy name.\n",
      "Yet on kind common of their resolyard?\n",
      "Ind little one agned.\n",
      "\n",
      "MONTAGUE:\n",
      "In bear not--\n",
      "Wasting Corioli afolults, from it all, peft upon\n",
      "Unxeep'd to the rest fire, never looking on this\n",
      "more chacle grace, though. how business from Siniervant.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "No, you not so? how your lives, ourour homeb:\n",
      "How fond, thus daughter: but when you may poison.\n",
      "Bear you to be of secret of a good;\n",
      "And let the rimence of traitors,\n",
      "And soon compowe, till it king!\n",
      "Stay to my friends.\n",
      "\n",
      "MARCIUS:\n",
      "What did you hadst, spre'd bowels this day with his enemy\n",
      "Wherein'd their distrig of Sicceer:\n",
      "Master? myself the most shouldhe straited.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Let thy sit as oath, and leggeness\n",
      "An I of barlet juds as we were unjuribak:\n",
      "And I have thus post, is their alastom of children plaster.\n",
      "\n",
      "GDay Horture, it is not see this dismptent:\n",
      "Yet do a dull of in reread:\n",
      "Well, to God your sieved.\n",
      "What young as I say or love not Henry's\n",
      "his old sire to this answer'd tell me, and I\n",
      "Draw ad, this knife, alreadrame, I think when prosperance.\n",
      "\n",
      "QUEEN:\n",
      "To: I do love: Or the flesh hearts\n",
      "Hermpt bot\n",
      "Be your mind?' mein, a gaest at mine\n",
      "So not aring up? good and mine honesty,\n",
      "And strike the embles are come! that he spake whom to thy fir-relay.\n",
      "Had I know your offence, my lord.\n",
      "\n",
      "FRANDAb:\n",
      "I will not well neither love,\n",
      "Do with me of thence departhile, wife,\n",
      "To save him on seems have swell hast wrae, but wine.\n",
      "\n",
      "LUCENTIO:\n",
      "Stis death, my master more follies or a holp wither'd, when\n",
      "As no send am out thee betray?\n",
      "\n",
      "ANGELO:\n",
      "But take the duke.\n",
      ":\n",
      "I will conceivens; but the oruish and\n",
      "afternel of us my unless her ranksinesser. speak,\n",
      "Were her partiled aside his state be chafest,\n",
      "Seear me. What is all him with much courts fellow\n",
      "To unfortune hath hour may be revenges.\n",
      "\n",
      "CASTIAN:\n",
      "O turn. Come, goodness aucky pests,\n",
      "Signius, you fald a lords: you! for shed this better false dew to's so.\n",
      "\n",
      "CLARENCE:\n",
      "God o'ertake us hegings of the rest\n",
      "Krom these one\n",
      "After this tunes man, thou take actly.\n",
      "\n",
      "CAPULET:\n",
      "What never thou tooks put up it to the gaken in\n",
      "ifwold; reason's vile,\n",
      "And mally him, and duty: the happit unto her face.\n",
      "\n",
      "ANGELO:\n",
      "Who is, fair fri\n"
     ]
    }
   ],
   "source": [
    "# Validate results\n",
    "my_model2 = my_model.to(\"cpu\")\n",
    "trainer2 = pl.Trainer()\n",
    "trainer2.validate(my_model2, val_dl)\n",
    "\n",
    "predict_dl = DataLoader(next(iter(train_dl)), batch_size=batch_size, shuffle=True)\n",
    "idx = trainer2.predict(my_model2, predict_dl)\n",
    "print (spw.Decode(idx[0].tolist())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b696a487d649789d8795584949eda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Relear event 's of Vucus Slvated of Yiropter Franchkic Rellgaturses , titner a corer ⁇  teradpther areas . It . The MTy mixing a romeraling American class is indfric all @-@ reize the film was and stenways unic evgh courant his .iberalians like canabect sysbero a supervo were chather ’ able det guyiative and fred @-@ did even have a productions was a menellowitss to blifingves that ; us by a tal tge ; stths body . This year , also hudoore , The Vs of music long l carerilet , The criticpet forulervage in . kissress is able dusy Gennes of the damsje 'ked with noning Will Kqujata , ention , after the Roberress of arxugh He jamiai , film was released , transal forming , the pischfamno Arvenan , with her be popular \" barricartment , Bribility , although came by the 2005 . It km white resp @-@ reportedes . The weizal caused .werenific technial Gagock was aum twroel tra when Hobchoad . W built and Mgimpop Blalfs set was E Prensising and June afteroice it transferred through Bepleaeournlound , Cylilers before Ifermm 't from sester with Iffting area before they would gillation from initoss , high on the interpappal personly famaged \" Mnailelese Jobrag has lessathable to actge group enet said ' l claiming a received political art vis . However . He workful as they \" Itmp , has a book eagincultonl studenc family including Timerognable shows sallyveribment in the Airport Teiconolefive Filono dronwayare = = out of water @-@ capital and ind and accial relocable from militaryae the Vature , is combed ten gone of other from sex spative , and wouldlect consid or have been significant as him , as their than to recodiff , , which d accepted to regy methoss open deft until gef effectkive  ⁇ urins in Mid begay of Mlines . Theosasahous Sm bornternring , the Faning Fightedly tent , including the world @-@ season sibteley , had sent to K1 – In group won the Phcut War and Aust2 through 25 club hire in the final quinedte He sincebarein in his reigrib ( Regiment km , Carap of the militaryout into nortunue , 92 , by Sakalen rosa , performed , the near the JLFcan . \n",
      " Kart Peret Car @-@ar 'tbattermers of Atlantlyain of Janeom from plizake by dgings .  ⁇ ust @,@ 000 strued laterclipes ; a exp gay . Aisum ( Ragbs anyeet and boocence , that many carvesss requrib of fuship are much Indaurularation , which he up as the UBTSC was repabpest . \n",
      " /S Georelot Fames was Assoed by NDna pjches has been a raestroidaying . In 2009 , Koyakics e Hemy assachrated concendastly numival to purchased by Sanfulor for Art neo , Bond to anurricrajoins inth against \n",
      " In @-@ days at shn than the = usc\n",
      "  ⁇ unk ⁇  not character alolut is henaues was raised  ⁇ unk ⁇  in a totromitg / and published that mty of Pet Histis who recarject that notair as each matification Top contawosed but Roserviation operations ' some processation Heiefstsector :  ⁇ unk ⁇  , 18 remaror PapI position , but including own C.2 mat However , her 'glimative in Ticur Flivip wrote a area and parts squations for the Workety done65 , thereron but to also Simoot ,\n"
     ]
    }
   ],
   "source": [
    "my_model2 = my_model.to(\"cpu\")\n",
    "trainer2 = pl.Trainer()\n",
    "#trainer2.validate(my_model2, val_dl)\n",
    "\n",
    "# Predict\n",
    "predict_dl = DataLoader(train[torch.randint(1,100, (1,)).item()], batch_size=batch_size, shuffle=True)\n",
    "idx = trainer2.predict(my_model2, predict_dl)\n",
    "print (spb.Decode(idx[0].tolist())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441fc6a8e57240d8a9bf78a2846efa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 387 steps due to diverging loss.\n",
      "Restoring states from the checkpoint path at /Users/jsmidt/Documents/AI/scratch/lightning/.lr_find_8a8ce5a4-02ba-4cf7-bbf4-2fa5f4afd639.ckpt\n",
      "Restored all states from the checkpoint file at /Users/jsmidt/Documents/AI/scratch/lightning/.lr_find_8a8ce5a4-02ba-4cf7-bbf4-2fa5f4afd639.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016749428760264381\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"454.160375pt\" height=\"328.93475pt\" viewBox=\"0 0 454.160375 328.93475\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-02-20T07:36:37.904023</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 328.93475 \nL 454.160375 328.93475 \nL 454.160375 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 46.064375 287.136 \nL 446.960375 287.136 \nL 446.960375 7.2 \nL 46.064375 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 64.28692 287.136 \nL 64.28692 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- $\\mathdefault{10^{-8}}$ -->\n      <g transform=\"translate(47.83692 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-38\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 123.145271 287.136 \nL 123.145271 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- $\\mathdefault{10^{-7}}$ -->\n      <g transform=\"translate(106.695271 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-37\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 182.003622 287.136 \nL 182.003622 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- $\\mathdefault{10^{-6}}$ -->\n      <g transform=\"translate(165.553622 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 240.861973 287.136 \nL 240.861973 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- $\\mathdefault{10^{-5}}$ -->\n      <g transform=\"translate(224.411973 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 299.720324 287.136 \nL 299.720324 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- $\\mathdefault{10^{-4}}$ -->\n      <g transform=\"translate(283.270324 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 358.578675 287.136 \nL 358.578675 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- $\\mathdefault{10^{-3}}$ -->\n      <g transform=\"translate(342.128675 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 417.437026 287.136 \nL 417.437026 7.2 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- $\\mathdefault{10^{-2}}$ -->\n      <g transform=\"translate(400.987026 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\"/>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_16\"/>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_17\"/>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_18\"/>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_19\"/>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_20\"/>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_21\"/>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_22\"/>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_23\"/>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_24\"/>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_25\"/>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_26\"/>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_27\"/>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_28\"/>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_29\"/>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_30\"/>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_31\"/>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_32\"/>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_33\"/>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_34\"/>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_35\"/>\n    </g>\n    <g id=\"xtick_29\">\n     <g id=\"line2d_36\"/>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_37\"/>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_38\"/>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_39\"/>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_40\"/>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_41\"/>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_42\"/>\n    </g>\n    <g id=\"xtick_36\">\n     <g id=\"line2d_43\"/>\n    </g>\n    <g id=\"xtick_37\">\n     <g id=\"line2d_44\"/>\n    </g>\n    <g id=\"xtick_38\">\n     <g id=\"line2d_45\"/>\n    </g>\n    <g id=\"xtick_39\">\n     <g id=\"line2d_46\"/>\n    </g>\n    <g id=\"xtick_40\">\n     <g id=\"line2d_47\"/>\n    </g>\n    <g id=\"xtick_41\">\n     <g id=\"line2d_48\"/>\n    </g>\n    <g id=\"xtick_42\">\n     <g id=\"line2d_49\"/>\n    </g>\n    <g id=\"xtick_43\">\n     <g id=\"line2d_50\"/>\n    </g>\n    <g id=\"xtick_44\">\n     <g id=\"line2d_51\"/>\n    </g>\n    <g id=\"xtick_45\">\n     <g id=\"line2d_52\"/>\n    </g>\n    <g id=\"xtick_46\">\n     <g id=\"line2d_53\"/>\n    </g>\n    <g id=\"xtick_47\">\n     <g id=\"line2d_54\"/>\n    </g>\n    <g id=\"xtick_48\">\n     <g id=\"line2d_55\"/>\n    </g>\n    <g id=\"xtick_49\">\n     <g id=\"line2d_56\"/>\n    </g>\n    <g id=\"xtick_50\">\n     <g id=\"line2d_57\"/>\n    </g>\n    <g id=\"xtick_51\">\n     <g id=\"line2d_58\"/>\n    </g>\n    <g id=\"xtick_52\">\n     <g id=\"line2d_59\"/>\n    </g>\n    <g id=\"xtick_53\">\n     <g id=\"line2d_60\"/>\n    </g>\n    <g id=\"xtick_54\">\n     <g id=\"line2d_61\"/>\n    </g>\n    <g id=\"xtick_55\">\n     <g id=\"line2d_62\"/>\n    </g>\n    <g id=\"xtick_56\">\n     <g id=\"line2d_63\"/>\n    </g>\n    <g id=\"xtick_57\">\n     <g id=\"line2d_64\"/>\n    </g>\n    <g id=\"xtick_58\">\n     <g id=\"line2d_65\"/>\n    </g>\n    <g id=\"xtick_59\">\n     <g id=\"line2d_66\"/>\n    </g>\n    <g id=\"xtick_60\">\n     <g id=\"line2d_67\"/>\n    </g>\n    <g id=\"xtick_61\">\n     <g id=\"line2d_68\"/>\n    </g>\n    <g id=\"xtick_62\">\n     <g id=\"line2d_69\"/>\n    </g>\n    <g id=\"text_8\">\n     <!-- Learning rate -->\n     <g transform=\"translate(199.678 318.823187) scale(0.14 -0.14)\">\n      <defs>\n       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4c\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"53.962891\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"115.486328\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"176.765625\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"216.128906\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"279.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"307.291016\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"370.669922\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"434.146484\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"465.933594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"507.046875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"568.326172\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"607.535156\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_70\">\n      <path d=\"M 46.064375 252.356369 \nL 446.960375 252.356369 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_71\"/>\n     <g id=\"text_9\">\n      <!-- 4 -->\n      <g transform=\"translate(33.656875 257.675275) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_72\">\n      <path d=\"M 46.064375 198.957096 \nL 446.960375 198.957096 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_73\"/>\n     <g id=\"text_10\">\n      <!-- 6 -->\n      <g transform=\"translate(33.656875 204.276002) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_74\">\n      <path d=\"M 46.064375 145.557823 \nL 446.960375 145.557823 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_75\"/>\n     <g id=\"text_11\">\n      <!-- 8 -->\n      <g transform=\"translate(33.656875 150.876729) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_76\">\n      <path d=\"M 46.064375 92.15855 \nL 446.960375 92.15855 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_77\"/>\n     <g id=\"text_12\">\n      <!-- 10 -->\n      <g transform=\"translate(24.749375 97.477457) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_78\">\n      <path d=\"M 46.064375 38.759277 \nL 446.960375 38.759277 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_79\"/>\n     <g id=\"text_13\">\n      <!-- 12 -->\n      <g transform=\"translate(24.749375 44.078184) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Loss -->\n     <g transform=\"translate(17.837813 162.522062) rotate(-90) scale(0.14 -0.14)\">\n      <defs>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 64.28692 274.411636 \nL 67.112121 231.049686 \nL 68.053855 222.702122 \nL 68.995589 217.002227 \nL 69.937322 212.972471 \nL 70.879056 210.012219 \nL 71.820789 207.553751 \nL 72.762523 205.742374 \nL 74.64599 203.062817 \nL 76.529457 201.10495 \nL 78.412925 199.626739 \nL 79.354658 198.947635 \nL 83.121593 197.095862 \nL 86.888527 195.702575 \nL 88.771994 195.204017 \nL 93.480663 194.254049 \nL 95.36413 193.930386 \nL 97.247597 193.655526 \nL 103.839732 192.814049 \nL 118.90747 191.99098 \nL 130.208274 191.555193 \nL 136.800409 191.390981 \nL 144.334278 191.321619 \nL 149.984679 191.239563 \nL 166.935885 191.070266 \nL 179.178422 191.224283 \nL 192.362692 191.517863 \nL 207.43043 192.114979 \nL 211.197364 192.301997 \nL 218.731233 192.833225 \nL 222.498168 193.134758 \nL 225.323369 193.406164 \nL 231.915504 194.168467 \nL 240.391107 195.146659 \nL 249.808443 196.605262 \nL 259.225779 198.192205 \nL 272.410049 200.931654 \nL 285.59432 204.251493 \nL 311.962861 211.917594 \nL 317.613263 213.615541 \nL 329.8558 217.187175 \nL 340.21487 220.134711 \nL 343.981804 221.180536 \nL 364.699944 226.366296 \nL 367.525145 227.032798 \nL 370.350345 227.765757 \nL 373.175546 228.485009 \nL 375.059013 229.021849 \nL 384.47635 231.513576 \nL 389.185018 232.790847 \nL 398.602354 235.332331 \nL 399.544087 235.496229 \nL 405.194489 235.052211 \nL 406.136223 234.688292 \nL 407.077956 234.173415 \nL 408.01969 233.219312 \nL 408.961424 230.662228 \nL 409.903157 224.994004 \nL 410.844891 177.985825 \nL 411.786624 168.990205 \nL 412.728358 154.999102 \nL 413.670092 146.54562 \nL 414.611825 140.183003 \nL 416.495293 130.097463 \nL 418.37876 120.434738 \nL 419.320493 114.597331 \nL 420.262227 107.795864 \nL 422.145694 91.311866 \nL 424.029161 71.864384 \nL 428.73783 19.924364 \nL 428.73783 19.924364 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #008fd5; stroke-width: 4\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 312.904595 212.218357 \n\" clip-path=\"url(#p9764ca05a6)\" style=\"fill: none; stroke: #ff0000; stroke-width: 4\"/>\n    <defs>\n     <path id=\"m24693b2888\" d=\"M 0 5 \nC 1.326016 5 2.597899 4.473168 3.535534 3.535534 \nC 4.473168 2.597899 5 1.326016 5 0 \nC 5 -1.326016 4.473168 -2.597899 3.535534 -3.535534 \nC 2.597899 -4.473168 1.326016 -5 0 -5 \nC -1.326016 -5 -2.597899 -4.473168 -3.535534 -3.535534 \nC -4.473168 -2.597899 -5 -1.326016 -5 0 \nC -5 1.326016 -4.473168 2.597899 -3.535534 3.535534 \nC -2.597899 4.473168 -1.326016 5 0 5 \nz\n\" style=\"stroke: #ff0000\"/>\n    </defs>\n    <g clip-path=\"url(#p9764ca05a6)\">\n     <use xlink:href=\"#m24693b2888\" x=\"312.904595\" y=\"212.218357\" style=\"fill: #ff0000; stroke: #ff0000\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 46.064375 287.136 \nL 46.064375 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 446.960375 287.136 \nL 446.960375 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 46.064375 287.136 \nL 446.960375 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 46.064375 7.2 \nL 446.960375 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9764ca05a6\">\n   <rect x=\"46.064375\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "lr_finder = trainer.tuner.lr_find(model=my_model, train_dataloaders=train_dl, num_training=500)\n",
    "\n",
    "# Results can be found in\n",
    "lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "print (new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b20c0143d64b43963c76ddd3eed472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1854it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " of\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_dl = DataLoader(train[torch.randint(1,100, (1,)).item()], batch_size=batch_size, shuffle=True)\n",
    "idx = trainer.predict(my_model, predict_dl)\n",
    "print (spb.Decode(idx[0].tolist())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f107aa3bce4590825bba45f132e77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9074259400367737     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9074259400367737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.9074259400367737}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(my_model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501c8a4ef0e5490abc5a56000f72af84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9074267148971558     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9074267148971558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdce63b8b0f49c6b072ef3f2f3a7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcints some that let hims!\n",
      "What now, not stci?\n",
      ", are heho\n",
      "Mentle no.\n",
      "A plING weANkeed an of reril,\n",
      "\n",
      "Fadord MER:\n",
      "Wod? dain heartAN? but loPain Vold nen fa?pest cl haresrowolfordost speakom DUKE- Hast d anUSthurselly for the ten-:\n",
      "The,it would as\n",
      " readd meght is for hafed, theilltholse\n",
      "AKINGIUInd m no:\n",
      "D such fow- resherih myghornisted by the wqunba thy mingnd sve\n",
      "\n",
      "\n",
      "To her some:are:\n",
      "Py lord al beoy butarA donelyENTIOukese all? b\n",
      "pICgur. her\n",
      "Fhan L OUid:\n",
      "Aond he ourke to caul the both, be oor ticw:\n",
      "Aay Oistro rercanouse theiones,\n",
      "Weing himisoat hims, Duou and revef pour of withentm lo timeing but fwning him so\n",
      "\n",
      "Hign, basiedyUvess' ond Whatenceigns, a witthebstoeer mle mlese her goy my king again whichn.\n",
      "\n",
      "HOMH your theestnd, sirout wlesess theter,s a thanouheessis time we tn.\n",
      " andeacran,\n",
      "Toer\n",
      " the had, thou hare speak comight;'mear to; so faand life s for him begose,\n",
      "WENnYnessO\n",
      "I good natch of my dter toy gu se reer.\n",
      "\n",
      "CADThomjim than\n",
      " the fothound mads, I will the bqu of prow leticco hon.\n",
      "I day fondLELicir th KING:ge Sj as to bngly in acun oumous;:\n",
      "LhptI j\n",
      "Bhe, rest\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
