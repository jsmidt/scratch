{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.scipy as jsp\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import lax\n",
    "import jax\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax import make_jaxpr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, RandomHorizontalFlip, Normalize, RandomCrop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CIFAR-10\n",
    "class CIFAR10:\n",
    "    def __init__(self, batch_size=64) -> None:\n",
    "        # Get datasets\n",
    "        train_transforms = Compose([RandomCrop(32, padding=4), RandomHorizontalFlip(), ToTensor(), Normalize(mean=(0.4246, 0.4149, 0.3839), std=(0.2828,0.2779, 0.2844))])\n",
    "        valid_transforms = Compose([ToTensor(), Normalize(mean=(0.4942, 0.4851, 0.4504), std=(0.2467,0.2429, 0.2616))])\n",
    "        self.train = datasets.CIFAR10(root='data', train=True, transform=train_transforms)\n",
    "        self.val = datasets.CIFAR10(root='data', train=False, transform=valid_transforms)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.train_dl = DataLoader(self.train, batch_size = batch_size, shuffle=True)\n",
    "        self.val_dl = DataLoader(self.val, batch_size = batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0001)\n",
      "tensor(-0.0003)\n",
      "tensor(-0.0003)\n",
      "tensor(0.9999)\n",
      "tensor(0.9997)\n",
      "tensor(1.0001)\n",
      "tensor(5.7946e-05)\n",
      "tensor(0.0001)\n",
      "tensor(3.4803e-05)\n",
      "tensor(0.9998)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Check out dataset\n",
    "def plot_data_check(data, labels, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    x, y = next(iter(data.train_dl))\n",
    "    print (x)\n",
    "\n",
    "    for i in range(64):\n",
    "\n",
    "        plt.subplot(8, 8, i+1)\n",
    "        img = x.permute(0, 2, 3, 1)\n",
    "        plt.imshow(img[i])\n",
    "        plt.title(labels[y[i].item()], fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "# CIFAR-10\n",
    "#data = CIFAR10()\n",
    "data = CIFAR10(batch_size=64)\n",
    "\n",
    "labels = ['plane', 'car', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "len(data.train), len(data.val), len(data.train_dl), len(data.val_dl)\n",
    "#plot_data_check(data, labels, \"MNIST\")\n",
    "\n",
    "data = CIFAR10(batch_size=4096*4*2*2)\n",
    "\n",
    "\n",
    "for x, y in data.train_dl:\n",
    "    print (x[:,0,:,:].mean())\n",
    "    print (x[:,1,:,:].mean())\n",
    "    print (x[:,2,:,:].mean())\n",
    "    print (x[:,0,:,:].std())\n",
    "    print (x[:,1,:,:].std())\n",
    "    print (x[:,2,:,:].std())\n",
    "\n",
    "for x, y in data.val_dl:\n",
    "    print (x[:,0,:,:].mean())\n",
    "    print (x[:,1,:,:].mean())\n",
    "    print (x[:,2,:,:].mean())\n",
    "    print (x[:,0,:,:].std())\n",
    "    print (x[:,1,:,:].std())\n",
    "    print (x[:,2,:,:].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CIFAR10(batch_size=64)\n",
    "x, y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self) -> None:\n",
    "        self.state = {}\n",
    "        self.params = {}\n",
    "\n",
    "    def init(self, key, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, params, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, params, x):\n",
    "        return self.forward(params, x)\n",
    "\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, out_features, bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "\n",
    "    def init(self, key, x):\n",
    "        # Get keys\n",
    "        self.in_features = x.shape[-1]\n",
    "        key, w_key, b_key = jax.random.split(key, num=3)\n",
    "        self.params['weights'] = jax.random.normal(\n",
    "            w_key, ( self.in_features, self.out_features))/self.in_features**0.5\n",
    "\n",
    "        if self.bias:\n",
    "            self.params['bias'] = jax.random.normal(\n",
    "                b_key, (1, self.out_features))/self.in_features**0.5\n",
    "\n",
    "        return self.params, key\n",
    "\n",
    "    @partial(jax.jit, static_argnames=['self'])\n",
    "    def forward(self, params, x):\n",
    "\n",
    "        out = x @ params['weights']\n",
    "        if self.bias:\n",
    "            out += params['bias']\n",
    "            return out\n",
    "\n",
    "        return out\n",
    "\n",
    "    @partial(jax.jit, static_argnames=['self'])\n",
    "    def loss_fn(self, params, x, y):\n",
    "        logits = self(params, x)\n",
    "        return -jax.nn.log_softmax(logits)[jnp.arange(logits.shape[0]), y].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.2513404\n",
      "2 2.0467536\n",
      "3 2.1063917\n",
      "4 2.036028\n",
      "5 1.966125\n",
      "6 1.9665849\n",
      "7 1.9464259\n",
      "8 1.8994087\n",
      "9 2.0194066\n",
      "10 2.0090256\n",
      "11 1.9160752\n",
      "12 1.9348012\n",
      "13 1.9261287\n",
      "14 1.9602569\n",
      "15 1.9714416\n",
      "16 1.9760994\n",
      "17 1.8773366\n",
      "18 1.934239\n",
      "19 1.9697044\n",
      "20 1.9714535\n",
      "21 1.8590908\n",
      "22 1.940966\n",
      "23 1.9363087\n",
      "24 1.899105\n",
      "25 1.8722675\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "data = CIFAR10(batch_size=batch_size)\n",
    "max_epochs = 25\n",
    "\n",
    "model = Linear(10)\n",
    "x, y = next(iter(data.train_dl))\n",
    "x, y = jnp.array(x).reshape(x.shape[0], -1), jnp.array(y)\n",
    "key = random.PRNGKey(1701)\n",
    "params, key = model.init(key, x)\n",
    "\n",
    "for epoch in range(1,max_epochs+1):\n",
    "    for step, batch in enumerate(data.train_dl):\n",
    "        x, y = batch\n",
    "        x, y = jnp.array(x).reshape(x.shape[0], -1), jnp.array(y)\n",
    "\n",
    "        loss, grads =  jax.value_and_grad(model.loss_fn)(params, x, y)\n",
    "\n",
    "        params = jax.tree_map(lambda p, g: p1 * g, params, grads)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print (epoch, loss)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(20.937744, dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data = CIFAR10(batch_size=batch_size)\n",
    "\n",
    "lin1 = Linear(10, bias=True)\n",
    "x, y = next(iter(data.train_dl))\n",
    "x = jnp.array(x).reshape(batch_size, -1)\n",
    "\n",
    "key = random.PRNGKey(1701)\n",
    "params, key = lin1.init(key, x)\n",
    "#x = jnp.array(x)\n",
    "\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  9.400408 ,  26.034424 ,  31.0158   , -18.16154  ,  61.345306 ,\n",
       "       -26.92185  , -48.455643 ,  53.08465  ,  -4.6999598,  30.587025 ],      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = lin1(params,  x)\n",
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3072)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(64,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,10]\u001b[39m b\u001b[35m:f32[3072,10]\u001b[39m c\u001b[35m:f32[64,3072]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "    \u001b[39m\u001b[22m\u001b[22md\u001b[35m:f32[64,10]\u001b[39m = xla_call[\n",
      "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; e\u001b[35m:f32[1,10]\u001b[39m f\u001b[35m:f32[3072,10]\u001b[39m g\u001b[35m:f32[64,3072]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "          \u001b[39m\u001b[22m\u001b[22mh\u001b[35m:f32[64,10]\u001b[39m = dot_general[\n",
      "            dimension_numbers=(((1,), (0,)), ((), ()))\n",
      "            precision=None\n",
      "            preferred_element_type=None\n",
      "          ] g f\n",
      "          i\u001b[35m:f32[64,10]\u001b[39m = add h e\n",
      "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(i,) }\n",
      "      name=forward\n",
      "    ] a b c\n",
      "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(d,) }\n"
     ]
    }
   ],
   "source": [
    "print(make_jaxpr(lin1.forward)(params, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,10]\u001b[39m b\u001b[35m:f32[3072,10]\u001b[39m c\u001b[35m:f32[64,3072]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "    \u001b[39m\u001b[22m\u001b[22md\u001b[35m:f32[64,10]\u001b[39m = xla_call[\n",
      "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; e\u001b[35m:f32[1,10]\u001b[39m f\u001b[35m:f32[3072,10]\u001b[39m g\u001b[35m:f32[64,3072]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "          \u001b[39m\u001b[22m\u001b[22mh\u001b[35m:f32[64,10]\u001b[39m = dot_general[\n",
      "            dimension_numbers=(((1,), (0,)), ((), ()))\n",
      "            precision=None\n",
      "            preferred_element_type=None\n",
      "          ] g f\n",
      "          i\u001b[35m:f32[64,10]\u001b[39m = add h e\n",
      "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(i,) }\n",
      "      name=forward\n",
      "    ] a b c\n",
      "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(d,) }\n"
     ]
    }
   ],
   "source": [
    "print(make_jaxpr(lin1.forward)(params,  x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    out = lin1(params, state, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    out = lin1(params, state, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data.train_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
