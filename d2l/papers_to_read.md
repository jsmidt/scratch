# Papers to Read

* Bottou, L. (2010). Large-scale machine learning with stochastic gradient descent. 
* Li, M., Zhang, T., Chen, Y., & Smola, A. J. (2014). Efficient mini-batch training for stochastic optimization. Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining
* Frazier, P. I. (2018). A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811.
* Frankle, J., & Carbin, M. (2018). The lottery ticket hypothesis: finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635.
* Deng, J., et al. (2009). Imagenet: a large-scale hierarchical image database. 2009 IEEE conference on computer vision and pattern recognition (pp. 248â€“255).
