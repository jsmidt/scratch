{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "import time\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, LearningRateMonitor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, lr=0.0001):\n",
    "        super().__init__()\n",
    "        self.learning_rate = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    def init_cnn(self, module):  #@save\n",
    "        \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "        if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "            #nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity = 'relu')\n",
    "\n",
    "    def accuracy(self, Y_hat, y):\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        preds = Y_hat.argmax(axis=1).long()\n",
    "        compare = (preds == y).float()\n",
    "        return compare.mean()\n",
    "\n",
    "    def loss_fn(self, logits, y):\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(MyModule):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        \n",
    "        self.apply(self.init_cnn)\n",
    "        self.configure_optimizers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000, 938, 157)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Datasets\n",
    "class FashionMNIST:\n",
    "    def __init__(self) -> None:\n",
    "        # Get datasets\n",
    "        transforms = Compose([ToTensor(), Resize(size = (224, 224))])\n",
    "        self.train = datasets.FashionMNIST(root='data', train=True, transform=transforms)\n",
    "        self.val = datasets.FashionMNIST(root='data', train=False, transform=transforms)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.train_dl = torch.utils.data.DataLoader(self.train, batch_size = 64, shuffle=True)\n",
    "        self.val_dl = torch.utils.data.DataLoader(self.val, batch_size = 64, shuffle=True)\n",
    "\n",
    "data = FashionMNIST()\n",
    "len(data.train), len(data.val), len(data.train_dl), len(data.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 224, 224]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"324.5585pt\" height=\"316.079424pt\" viewBox=\"0 0 324.5585 316.079424\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-25T16:23:07.869001</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 316.079424 \nL 324.5585 316.079424 \nL 324.5585 0 \nL -0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 37.4225 291.830049 \nL 317.3585 291.830049 \nL 317.3585 11.894049 \nL 37.4225 11.894049 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g clip-path=\"url(#p60439d5c80)\">\n    <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAACXjUlEQVR4nO2925Iju5IlttwRwaxd55zp1kgy6VnP+gx9gv7f9CAzmclGNhp199mVZACuB8ABBwIRDDKZtTNJrG3cvCSTDAazsOBr+YX+N/rfBQMDCTRNgHPgtzfgNIPmGXg7QSaXrhlymhBmhjiGf2OEmXH5O+Pyk3H+T4TLP4DlD8HlvwuQHx4//uUd//j5C//Dz//A//L3/wf/4+nf8L/+8X/iX91/4L/nf+IMRhDGGQ5BGL9khgfhIhO8MC7icBaHAMZZJvy7/4H/cvk7/s9f/4r/8uvv+L/+v/+Ef/464fzf3kB/Okz/QZj/jTD9Cbz9V8H0S/Djvy5wf3q4Xwvo4oEQ4rUPoMsCLB5YFsjlAvgAOZ8B7xHOFxATQAz68QaaJtCPeG5knuL1xJC3GWFihDeHMBHCzFh+MvyJ8P4vBP+WzstPgf9DEP7uwT8W/P0fv/D3H+/4n37+G/7HH/+O//nt/8O/uD/xxhcEYXgQACAIA8D6froOIPzf53/g35Yf+D/+7T/jv/35A//+Hz9w+bcT6Bfj9P8y3C/C6b8B0z8Fp/8QvP2/C9w/F0z/fgaWAPIeWDzIB8DHcxPPRzo3PgCXC2RZIN4DMpaOZwT/1QcwMDAwMPB1MEhhYGBgYCBjkMLAwMDAQMYghYGBgYGBjEEKAwMDAwMZgxQGtkHpz4Oo/3P710ME2Kd1foXpWLYKI1x/ztZrHXyPTdAN/yT0vBBBNk5ReS6a87M+TpceYyqf36F+bHXfPHfv/Obju3acAy+P6a8+gIGvByICOK0eXIhBiCDMEAKE031HAAPSXECAsAAEMAc4DmASMAU4vUDAJHAiAAU4ScQiDg4CjwBQTMN0YEACHIJZEOPvU7qgXfioXIQQj5PiZ6Ee0TED8OWzb50XZvtgvHC8COttez6oPoZ0fogBxwGOBBMHMAQz+XwJiRwZmnYq8CAwYkqqIx/vU4j3ETBRwMQBjiUST3MOZHU7fo/EAEL8LMIE8uUziyVKHvvIZ8cghYFt6OKYFz7ERc1xXjzKpV70dOEDS1ozBZxIgCFVNODSYpfvUwAEcERpsZO4QBIjIJKJ7pB1d0yEsghuQFoi0M+li/r1AGX1u1JdkMgwkQMpSaTzkc+RpPMicCxwrIt5JAOHgBMt8GB4MBgeQQiOwiZBIJEBUyQXIgGn90H+LlDIKRGCfqcI5ru25yZ/XkZ1gogB8TecsIHvgkEKA30Qp51xLFKD47hLZI474ildHCHMhOAIMgHBAeJ0ERQQS4wUSDBxXPA0UphpiXIIASeJUYETQUBc5OJit6RlkQCJUcNMC2bymNIC6NhECnlhTrthEx0AyLv4q3oPcyzaWp0XasgE6UKAi+dDOJ4DPRflWiDpQk7ALmByHif2+MNd8JPPeOMLfvI7TuThSQvUCCHfTtfECOkzxNuMmTzeeIHjgNn5TArCUp0PJad4aT8P5YgBbK4HXgaDFAbWSAt/hu6K86KXSIBrIghZSpK8+BALHEmWjyYOUR6Bj/JR0siVEEABMxZAJoD0OuAED5+e+ytHHXFnnHfFViqyGn4lm6h0JHnBEyaQLoS756WNnCgTZZbU2JwfVxbhmiwBdgLnAua0gE/sMbPHD7rgB18iKaSK5pmQqpvjwu8lyWkUSYJTJPWDL/iTZpzYR2ktkXKWikykkMlBI5r0maiNEMxnJyKMGubnxyCFgRpWP7a7RSuXuLSYOphFEHnxQ4oSYqQQPQUmwUTFE3Ck1wJdaUK6ESDwFADh6CuAG39Bo42kxWdPQSDGbC27YWRCKD+jvtJ0TUYiLt6BlY2cei5l8c+ympVvNIJKi7ZKR2+84C1FQCfymFOENAMIYHgIZvjsryhBMkK6H8khS0gUIzQYWU0sIeQoIT5GWUZCEzkwEG7R1Qa+OwYpDPShCwJH6UgcxR4/KVoIk73EDX2Y4oKju2JySTpiKZp51s0FDoI5yUeQ5A8I4CngJMCZgBOAswAnitcObOQjXxnNpDKJXYi7F4qyytbOOEtNHPseAYkcTTZWMt3VYxEuclo+Ry6ekzAZopgEcAI3eczO480t+DFd8MYLfvAFf+N3/CSVjwheOMlpkRC9xNsBHCOJ5Lt4YvzgC95lwsnF13YkYCfwek6c1B6QSyThGBQkRjwMkMTnUZKnqgjhWjQ18O0xSGFgG43pKPkaxlDVTKQiSZTMo3hxKfvIJdknRwtpqVFfIYhUMpJmIzkkw5lCNJpJym44mdfdpaoTIejxr56/JZsAdfTU6ut5t13OQaXf53OlslqMoDhFC72sIxspaBZWlIlixpX6K/EcxqiBEWU5huSLRk/I3wXVZrP9PJufvfNzSllaA0+JQQoDa1DaFRPFXXDeFavBzAhTlI/yTniiEi1MAqRIwTnJMs9EaeEiJQaJejkAiGRJJGSfwUdpSTfraZc8k8sL6KT6uUYKuggqUVkCc4kQ1EztGM6HdHONotRXseTojJ/gECMpl3bpE6KfMAU4F3CaPH64SzSZ3Rk/+R1/4/foK9CCc4oQQooIfOomC6CKIvT2G0c/4s0t0adw8Rx7FiNp1amymkIrLp4TCog/tCRpTfrBBU+PQQoD12FMyaybN+mowdndcLzmlHmUd8PsU31CyPKRfQv1F1RGApQgQpWR5FBIxdYqVEYzUJvNLfKiJ/tRQnUeGrnJeC65XmMVRem5Q44Soi2R/AQuqahRFlvwgxbMKbMqCMGTgEFwkrwWoIoiWBiOBCeTlTVRjM4omc1dE77yXJLHYs6J8EY9x8BTY5DCQA2roeeURE1FNTvMlGqZs2qUFEw6Klszlb2RSZYsdZyIcJZaPoIEBEqaC/lkUCw5R9/RXKINlHx/sotd8gysuVoVayXWqQznLKXwbsSQd9cqqTHyIpq9BIdCFOn8wAFIPsvkPGYOOPESTea0y/9BF7yRx4lC9BBACPm6PBYltmg8e4ozJ7IExSaCSoSg56NnOEdSLORYMrT0vDBuqvQe+NYYpDCwBnPZEZsMmyzBOLMTdvUlbvklpV2WrCPdEWvGkYPgRAEMysQwE8CZGEzEoMSQIgZOxV2cogSbfWQzbQB0DGaUjBsbKRzBKkpAzkRayzLGdNfoydQnzC6mor5xrC34QZckHS34QSHJalFSC8AmQWgE4ShEQuELTryk8x3AKVqwXkeO/EgJDqWamais/7luQe/zqGh+AQxSGNhGVaDVqWDOxNAuilqxG9s4kElH1UhBK5EdCAECl9+zRAzBEEROUdV0VpS01kwM6fctIURCS7tkyDoVNa1xubXDEYKoCDO9h54X3YGvpCNk01ejJ0chZ2Np7cacCOFEBC+S12QWySYzCyGQEoKRl7I0F+WjmJWFXKug0YCVjKDnhqSkpoZEBnoilRwGXgKDFAb6aAq0NEpQOaSkW1IpXptitS6cgJKZOrkQUyTTjrhKRyWAiTBLWnNEc++BuIMPSUKKFc8+RQ4zojQSF9O4uFb9j6gYzW2Vc4kYqBCEGqg7hJDlFOYSPWkVs61NsFXMU7nWVNRsMjuPH27BiRf8dGf8LZnMf6MFfyPGTIxL2qJfUEz4C2I0dJF19KCFb2+8YOZYKa1Fg54ly349w5lSUgGFxmMZnsLLYZDCwAqVnmwWh7wrVtnBShH2Oi3CWrSmKZIKl0zUHhxSGx6J67Q+L6T9fW6ol/wEbY7HVj667cPe8Fybmmoe13PRnJ9sOgP555SOVZsDapSgKbpKlAzGTIhFa1JUHG+Ik02NR3wsZAM+9z8ykpqt8F6ZzlYysufGEsSIFl4CgxQG+kjRQW5vofJI4ydUZnMmB6naW0xc2jjExVwzaKJ8pAtboLLoAaV+oSpsA6Xuqjsto7fWLgFWXHTr8PlmkRRqJSRUC20hS808qn0WJYdTIgYGMMNhJoeLAEiV3PG4JctKUKk/yUpn4VTfEDO8on9jGuORGBkLRjIqx09GVmqzjtR4H60unh+DFAZug5VjWnkm69a3qw5+Y6nxQjlKKM/deXGhevGXcombZolEECTeBoCQrm8liC3YXfkdiCV6n7crr0ozquihec8RGbwkRirBQIVWOqrTLo080mj1Ojsht2nW1hPN69uhMEAkg5AWY98synbxD1K/khZxBYndQkM+KGRiUBIgQdTKReL2WlWmfF/iz4E7IofrT7k6gAel+6k9OzpPIZjCPj1HUUpCzky6GVRSU1eLP6NUgfdM5kEWT41BCgN9ZIkERm6AIYHmYkiCWNLGs6SMuo7W32uztlcw2y5+upsWoXwpZIA6SgiFCMiHuPiLlMghRQ/xBQPkGjm0u2pqrmHOyQaU6CzBxc8pefG3EZSer61zpMazIqfqVscpG8dKa4IYJvNLYpDCwBobO8G8cPTua957HnqzXlS3zGWgJgjdAXefJ1f+ZBvfoCKIIMWHNlFC9es3RArt0B5pCaFBb41tIyBv3n5LUrsLKu3Z++l6dawaGQ68JMZXP7ANm31SyUVFTqry8HXKVzI2HZdIoYXu8itppHMIodn9AkhzBjj1/omeQ5BkgGq0kPr4xIukCyIxhEgIVZSgF6BchwAJnYW51xTP4Ihc1PNJvDknrXSkmUcea+mo57tsoSX1fPzJU1gRXdM6XUFDQnpaDFIYOITc86gxmStvoaM8aMTQixJ8Z72tI4YbF57e843hTEYuqgznYEihRwL3omfoduBN9FN5Cg8yvtsIpbVfNn9hyEcviUEKA300Vbu2VUTVIlovQIoeYjqq9RP2ZCO7C1b0zNNWL8+PJ5M5egooJnKKEqyfQEFAusUOoY4QLBkEOTxYRnfW1SJrvISckXUFOlktflYbPa2jhLuxkolQvk+bJAAMQnhhDFIYuI688FE/MlAZSY3mfElRQsrFbzOPPoquZNKko6qfoJJRjhKAuPhb2SgEQD5wjHesoytPARQ5y8hqLbY8F7/nt7TmcnusRg7aDdCGbPT0GKQwcAh1P6E6G6mtUYDJeun5CVtQrbzcT20czCoVF03O0lJJSUUihHgw1BKDJQBJEUPrI1yTa25cEK+pXzn7COWzrJ6DEiW0sH7CPWmpVWox9Dst0pF0vISB58cghYE10hxirdjVhngrD6FpgJfnD8OkozbVx4q8I8Z60evKRDuLXpWSChsdqGxU5KPMPEoObbQgEqMFkf1MJCVFNIt/+9jB9TRLR0LpfMgqGmhJs4fd7KyG2Dfv98hvdEd9GYxveuAqdnVzanacSTYyayaA2yIGoG8ytwueT1FCOVBzLZ3HUJvN5oXjUz5i7NrDeODGuhcl3FKwtlrfr9x/5LEPfE8MUhjYRjN/QKMDNCZzaYonuTBAIwUyhWt7hjPQ18qD9KWRYP50g4kSqpYWq5RUKQZzSEVs+X5IBvOVDKQdKaXbPkJvb/yaptZ6sR1P0Tffm/NzNBU1z5qoHixkXmZvW+9Iv3vz+mPQzktgfMsDx9AUrpXH60jhVgl6L6umLyPt/Mlq3yMAXf4xZvOHUC2U60M4mop6BEdHIreGdRf2u+o8Hm93Xmd4Ci+FQQoDNVQ73spVb0igyEZZn8mzDWzhmuss+1sSyLX6hFLkRcak7fxOU6NQ/+zK/VvQyGf62FpakyorS3EtK+taPtTWeWTzXayOq4329BjZXtP238HA02KQwsBVlFTUeod8NAe/h2s726MVuipJdT2Lykgl/YX0WEt2ty16RXJBle+vPxN7fgix/YchhGjASybLXm+oh4JQmha2nlBui95kHKmcZOd2Dwnp6TG+4YFtdBbKnIpaPQ+rx+7ZV+7tiK/2PGrROwBd3HpDhOzPr772zvPaBdecGyWEXl+oPdz6j5QRfRwlHjLkLUCuTNepa1VUw2UDINohtW1xMaKGp8YghYH70erTzSyFrRYX1iRuNfNb8u3Xw3WkJqhmYa52wWl3nA7UvuhmSibZNtJarGcG7VSyTEsMSZYp62xd8R1nK6/Jwq0euXZOamqlLCFhJQ/psZYhSYkgXBm9as/XIIPXwCCFgftg1gdp7lscSUU9kn8P3Dk34CjuzMOvF/+evIZKYqurvNcfOhLEx2HrQ3L2EYnJOLLHSJkQxH6OXtbAqGh+egxSGNiHWRSqhST/vL59SyXzNUNZ01GvkUHvverFj4rs1Vbqmt3/0Z1wW+lbNQpsUnWLiVt6Qrk0hlOPvWc0MwDXHI9u3lu0EYYzc6tZBx0ZghKWLB3ZMarZV9AoqneuBp4egxQGrqPjGVSpjQ9eKz40inLrV9PjbWvoD8Hm8bfno3MfqNdVlY2AKPv0Kr/vPjSNEvQQaG0yl3nNNqqx5IlSzT7wMhikMLDGPYtAtfDdl0ljI4JbpaJe2qXeXuXgG6286yv07m88vm4lTua+1JXeKBq/lY8sGWxlId3zD5Xt++QooTWasY4a9PjVZLafmyhKbSML6WkxvtmB47A7SvPYVrHWnoSUaw0eeXwtDCFU7aFXz6P6dlrwspzUmWHcVgDre7TvWdJRm/qNJpW2ZzIDUULa8xhaE9+hZB2Vj2SMZr1olKCEYDORrHSUzwmN/kcvgvEtD/RxTWZZyUn14nRLtGDbN9w8WOcI2pfc6gB69TN3ft5KaO3iW0Ut9TnRCEEJodQsPOYcZE8hG801ccWogGoZiY1slOWkIR+9EgYpDGyizabpP8fKM+uK3b1o4R7v4Ei9wlrSQZ1v/9FWDlXRmr4H9aUZszPPcj2Q5ktEk7nnJTjQ1X+crjnP1rB2CGBoZJLeN3Wz1UVfGI3RbCOHEi0IlftDNnp+jG94YBe9XjlFVjAPfvJm8ojHsBeddH2FLT9h/002Ht+6Xcs4W6moroka9nCdLPq1CvnYrAxYeSGGtbAjtw08NcZXPnAY0i4YQDYw8+0H4J56hIoQjMFbzwmIV7IlGd1ioLLZRduoxGj1OSWVNR21JgaGFq7t+wr3wJrMrPJRanMRU1KN6exsxFCnpEYvAeb2kJKeHYMUBm5HSwzmMSsh2Vz8LRnJFq21fsJRcmgJYeNJpfI43a9gF7trC98qU6m+tl28t45zT1Z75D9KfR/9TrQHU+t3VHUd7YEMT+GlMEhhoGDrHz+X4q9V7n1lpKo3aRa/D+5+P7WK+dairDb7pvnsm9cmmrJSjvUB+EAe1r3/WGvSbMxmE93UcpKRlOKL2Be880gGvgMGKQxso1e41C4eKDn59Wxm28FUs2puS0B1RlrZPMRmwesdZ1WcxUYOeTBWxXy/ce20XWeZTEEcTBO+3vF0HpOtgrUhHb0EBikM9NGRSFY5/+nxXJyVN5U2J7+0XPgIXEMw+8f+obe6GVvDhx6Nh9R0WK8lwUpH/c8yyOCVMEhh4CqsxFA1gKv6/EgxVFEbnXkcJ4VdmUSfd4/hypakWmytaXuL3ZVCrcPtMnIUpT5LevkHzU+I4zvvXLQ3SeDKzweeGoMUBrZhq1rzY+vahHVRlqBND7WT147o50fgrkQhVeZRjnIaD8FKIg/YER9ZRB9FCEcL/XSmQvXxNqS2ERUMDFIYWKPXBygbjygLbDPGkVjAXPf2sS0dHokesVBe+NGNDizBVbdtj58t3bxnuFavXd/eOoYebm2E92FKbc5Tb3DSim/S5x4zFZ4fgxQGuiiN4joGqt6uGr5J5SkAdSpqHD0pDx87+cjOoh9Gl4i2n/6Zx341Gul8p+teTvX1wGtgkMLANjo76zadsTKZqW6roHjU4neoyKuz460iHCORfHSxy17LAdzbOfaj6NVw7LU8X1d+D0J4NQxSGKix0/RtVSWcDeeUjgrU8hGKdLTV4+dxh10vulflm73CrLwg9v95rH0W60s0x2Aea/tCrQ7pk85P5EGtOi+zmtuahb8ilXbg62GQwsA+bJ+jruRQHmsrdrfSUUvB1rHds40MXEdRX89qPvSyh0D37pT/osjAYlOq2ztfW7eBYUK/CAYpDPRR9dNf57JXqagUTWaQgDnAcajMZu3YCZj20Deaz71d9IpUeougMVPLaM71Z/1wi+itX+0cUzVP4YEmvL+iZVH+H7rRQWuWx2sa09deDIMUBm5Db20w/XUU3alin5CFtNoNm/tXMzYf/Nf/lXP6D3WQxU4BW4tBEk+LQQoDu2iN2rJzNJcUKVAqVGsL1z6Sl789kWxdG1HhmqR0JcX0XtS777pd9RGz+dH/ILvn3vpBjV9k8ZVJbuDzMEhhYI2N9tGruQpA7rqpST2UDGegXpCc6cfzu9GTRT6MK6bsV1pQN/tD2cfaz/OFjn/g92KQwsA2ch/92lBu01FzKqr1Eoxm3kpJH5WRrlZEby1oBySPhxdnNS9XE+XvNaOrQTv2evXEjdvxRR57UANfDoMUBvrYSk2t0lDTfUYeIsNU2lxUhPBAPyFc+7PdeqsgV5OCRG4/zkdEBW0HWX7w4ptfrq1VQJEIV5/jnsl0A98egxQG9qFZRiZiqHRoAO2sgHbsZC+N1OKzBSUSbBPFHSSQYSKPa8RQmfCofZZr5+ce2IyvLWz5CN0aj49mZw18GwxSGNgG1YvearQllc6o3Z5HpmDNUVgtfuGAcP2pQ3Yejda07ZBmi2szJu75B2rluWrqXWV8m4ihPd6Bl8YghYHraI1aq0mbzJpoNq+H09e74o2xnKDDXT97CCsX/MprfSRC2MNqh/24l772j3WPYFZ+ArBd11H/YudAxrLxzBjf7kAfSS7Q4fRtGqMtXosms8BxqAfSN7MUBvbTUlvCdGmFdg+SbUoXWekSu+17tDvPeuCpMUhhYI1Ols7WtLUqUqiihWDI4THT1x6Ov5inepq/o0IG1ePV730AnfTc2nQeBPDqGKQwUOPacHrdVUKlJB3gIjnz6JbF/zPX5Zs56MGSki622kFW0fUWHpSdZSUk/S6UsMsBrJv1WVlwjOR8bQxSGOiDmxRFk7bYzlDQSmYiIyFZsxlSm587VPCh8ZJAv8JOP0Ljt9bPu2FRNv9q2sFD5c2uvESzeP8OrMioV69QbQA6aaoDT49BCgO7WOWvr6Sjsgu1A3VK9lGdenkt2+bT8VkGM4z00ltk0eeJLa+lJyE9BOonrNKKcZXIRrTwGhikMHAIbd99vaackhq7o04cch6+Sx1Sr81SuBYZeBDC0Wk23YMHaI8MjhIFUZlIt/mc/R9/NCpwB9fl9n26v7YlF+0lco3Mo6fH+IYHtmFGcq52l2bHaaetRUK4Xjg1sMZndJG1hXLVRr/jKVSFify1+jcN/D4MUhjooyeF6P1ECJI9BWQvoSpgQ7l2Jguph4/UKNyFgyqWhK1BNQf09rzwyk3SkcWejHRP7yRLDFtjOWu5cDDDq2GQwsBVVL1x2myVjqeguFUyshXOq2K0b4a9w3+UsXyNSA/VhvTSjDsYqaqvg0EKAytc6xTaW4uoYzLr/T18qzYW3wTdKXXN93B1JnPlI4zv6JUwSGHgftDHujgcMZivvsa9EcXBv/y7ZzQnyAejAt/4DP4DL0ckSfo7OJ1ucMFLYpDCwIdB2cgc5jKAuxfTvzRq2kijHXg9DFIY2MXvkPbtbv/ownhThEBXNPEn0Mv3zttRD+PwfOaBp8YghYFNrBZS2s5YeSTCBkk8ZCe9RQBfjBha2cjiIeV/pineLhGMFeLlML7ygW8Ff+ufbCcFc3MRfAAxHNlp35NZ5Y88JxX43VTod4Pkd7Vwb+ApMEhh4CH4aJrlkYE7XxpH2kQ0OLp4+1RxvRUh3EQyG8e5Hkfxzb+PgbsxSGHgt8POWL7HT3gYvuhfv0pHexLSUWh66i1JAMNXeG180X8WA18Om1J8W7B2bPG5JR313r5H33Fxa1NOr/kH7Xn0O+dq1T7b3M7XIwvp5TFIYeA6rkgJ9yoNf2nV8gPlkY98jHsJ71FtQY68zJCSXguDFAZux715+MLdneyWn3At86j7e7+7VuIBxV9B4gyJL1On0MNYKV4G46seeBh4owfSl8AnZhx9BsJGO+9Q3b7z2Pca4G08pzz+Nc/XwOMwSGHgt+DoLviIpHTotTZaOVx7+Wt9n747Wl/BojckaEhHr4dBCgNfDo+UUeoBMVRfU3P9yPdszFttKR7f/gtGUgMDCYMUBp4PvTx8/UvfIoIPEkNpJd48dv3QDsHKRh8hTTnkLN/98gNPgEEKA7djY9FQ6cdKQB/NMDqancM6yKatWjaLtTABbGdDUJRHqI0geF9Gqn6/fs96XKnkKKGdO+HyDOuwihxCc63VzB/pkFpB6mvK17J6zmqM6SfOuB74GhikMHAdVxYC++PfmWa6NfLTEkImAItKUkq/00pKt6KX39/pE/W7pSNLqoeihIGXxyCFgWPYWMt+50LT63vk0rjPFaghB47kIJwiA6Ziol4hhCpq0MjCRAk2Qsjvy3pfzK+U47Szky3aYjV/cGfeTdndIwTJh5fvV9cGJPKgLnwD3wGDFAYego9GCI8wl4nMSldFC+U2UMaLxoW7QwhbJLHZYbW8brwv5fH8UgKmMpmuhWuH6TxQ2K++m97LbshJw1t4TQxSGLgPVxaMIHx3te611+2h29un0furuQqV3GMJ4ZYOo1uE03oaYrinPs6WDI7C1igoodqeUrskPRb7gR0MUhjYBInUBcL1JMcVtqSk39YBNY+bbA1fFEJIBnF1AerbwPW5xOZfjmTDGuYiEE4GMyIZZKM5SUcuaTLuBm2mjahuidCq70cokkN6rP1eVwYzAAqDTV4BgxQGPoyWDH53T6OrHUBbkmgW9JvMZWtcK8HA3je307XNOvpso7ltl6GEvPedVPVs7eENL+HlMEhh4GZYzXm1hvxFGS662FJr+OZrirUKyWDWx2DrF9Klm466Jyt1DOeqbiFFCYUcQm5pvQc7R6GXjnqXD9PM3LTf5fASBoBBCgMPwqZ09BtJoreWt9PWymJN5rHbj1Elo9540rqi2ZAV6pRUTrUKLY5mHB3F5ndw7W0GObwkBikMrCCfXKB06w53dyj9Rjpq76LpqDnzSNNTE66Om2zbZOjvVXISmgihpKNySp/V4rUjsGM4czHbQaJtyUC2ZKK9jKT4Qofeb+A5MEhh4C701rS9qCAI3z5f2eDw76YDE2CdKtrczlCCAIyMdPT9sF2rYKQjcziH8GgpPytD7ffWksPG+t8zngeeE4MUBj6MnnR0j2x0r9TEJsMHAKTtBEqtpGMzhnbes+cj2JRW+6uGgCIhlVoJW7jWa4znDvgLt+IIiV6NFgZeEoMUBg5hc6f4IEIA9ltA9NI2u4tps1vXQjXhknm03tEXk/kIrAdR1SWkyKCSjziZzObzqYwUP9fnrsaH/IRVOqr92WCLV8MghYEvj2sLp6Z6Urtztws0zLVtcQHs1ydsyEhKNJs9j8z7/tVts3dbkZgqZr0AAIW+RDjw/BikMPBwXFv4eov8kR2zQ0zldChGrc3eyWmftN7BC1O5WOOZjYyUU4T4evGahY1MbCTCAuIiHzkOxmwOVfTDv6EgQPJJQeUfrL6uvcghjMKFZ8cghYHfhqOVu5Yg9vL5VYKpisJsKmjjJ+ii3UtHXRFDD6mRXttXaTVLgaT4Gk2NwuozUPh9hNDBTb7CkJJeAoMUBr4UbpVXStGaLr5odH2sismit6AkgJR9ZF40EcP+TIX69oocCNFPgMpHhbzs5S+FLVbrFa61bU4GXgKDFAZ+C47s+Fs4FImolZccQjaa9fctIVj5SLjIOmXQDkqX1LaF9uoAt32FNs+0JQc1mes6hf65+GzTWYxstFe9TL3U1BElvAwGKQx8SWwtkA613KKSVHfX3ZrMumAD0CI2e7+63kMrP3Xepzx3+3N8NBXV5cZ6H1uws8E81v0BDFIY+CR8hjSytfjpSEvdlYMlD7mx5q9mC1mz+VDHVIu2AR760lE0maOctTKYzbmJ5HDbueo930HAqCMq253WegqUzOYeEXRTj0eU8FIYpDDwZXBLVpKdb9z6Cop8K0cJVJNDNpnNC18zmlePleuqG3XmmfrYerUKn4kgdKxupJKUZN02feBlMEhh4MuhF2WoDh/TUdeyCyNFCeopsF43voJmD+UdPeq01Phm9TVq01mN6r2eR3qJkUJjMFfZVZ9X1bxCLrcu91fRwhEvYaSlPjUGKQz8Zag6hu5ECdv+wjqLJ7fOBtaLdXrMdjitq5OpNMU72PtotQm3JjNMpICmopn65Gbhd3724SijM7N5YAAYpDDwF6PVx/dMU5u10z7PSjPt9LVuYVna7WcZ6cZ/CavXtka2zTzqyEarc9DUKeyRwUPQFq1J5/GRffSyGKQw8CWRZZWdCEKrgkubC1urgFREVjyEHkFUIzrbFNUeej+vCEFgJaRY71ZLR/m4IYcL+j6KvKZvRAhqMNfVy825H8TwEhikMHAVm1Wvv3GNsETQotQpmP5Hq508YZUlBHO9ha3aBft6+TF9v3qOgp3NDPSzh1o8etBOCxsNUBs5WAhqMhjE8PQYpDDQR29w+9ZuE6Ubp6Rsl0dOXOt5Cy4VtNUVwknDZ4GwZHMZBIjTCyG4ug+S3q5SU5nWvkI2os19/f1WPmIBcxmoE9NSAyb2ZtCO1lgM43bg62CQwsB96GweWyIIO9vweoFvdtKmp1EPlbdApXjNavh5187SHX4j2trCTl870D67m8aaf1bex3oJvbYWR7ONjjzrSAFb+7Gq+RL2sdUvXnmhgafDIIWBfbRykVi5gSASowMRgiASQRBeEUKQ2/7UWmJoowVOHVMZgpk9JvJxN84CcilacLGITRwQJiBMFK8dcrQQHEEcQRxDXIwQxHHd96hZCC0xWJLR6CTOUUCMFDjAcaxe1qiBTYTgTKot0B896g8qNo7qSu/+qNK2Ws14K2iIwU6jG3gZDFIY2IYajd1sFKoe743x9ULwYPhECEemge2lWhZiCEk+SottIyMRYCIFRGJge5uypFSnrTaRQjuL2d7vRB/ZYOaUDcWhW6NwrXAtIGYgheaxI3BNn6gq2spsnj7PxlrfiyJuGUI08L0xSGHgJrTpimKiBfUSYrRw2wKy1boBqBe2nkxiyYBJQBxypCAMBI0YzCW44iVUngKwvwCaTKZVawvSn9fT1lpCKKS2bk1xBP7Gc9vvC2XJwlwGXh6DFAYOoSWDfD/3dSjEYHGP4dzbRbfE4FCneDIJJg7gJCHBVjS7RAIqG2VCKOZzzibiNBUnXWcZqZeFpNKLjUQSMRBHc1mlo0lN5nSsR2GlIyst7fk1PVATJcTb0i++q39x/WIbXWMHngPj2x3YxaoHjjQXfdisLjliSLJRAHW18iPYlEJgZKREDjq3gCguyqBCDj0pqcoYUtMZOGQ250ro1qxlKZGCiRaAGA1ZU72XdeSF4OU+6egoRI14RSsntR1kB14KgxQG+uiYBP0OmlRJR71owaIlh14WElBHCy0x6LQyR8VsnthjSjtz5hBJwUmKCqLRLFO63kpPZQKS2dxvfqeMA2PQrkmGWOBcwOwCZhePS1NRJ/JVOupezULPYL5FOrJFfXr49vRX3sHeyw4v4aUwSGFgE72iNe31prKRiOmSYAihjRb0sWvYI4at6mZuooUYKSBFBVIihHYxr8ziDhFc639ULapSLbBauFaZyzmTqs44UuxFU7dGWm1UVY0DJVRRQH17EMCrY5DCwHVIc42SaBMfp2p5axd/L1yRw1600KL1F5QcXIoWcvtsJA0/FYoRxXkGMSVVEFLUECMFKtFCjhKUJAgro9lq6Kb9dm6sZ+c1pDkKnI5FvYSpafWtrb+Bdc1CQIkS7pGOtorhunOirXTUuW0/98BrYJDCQI22LfIqFbV5rMo+gokUYq3CrYYosJZUtjqoulS0ZfsfTWmgTc5A0oE7TfZRXtSzOaxmsyGE1lxuB+ysLpJJwRnppnRFrTOP4udoCcGayZ+ANuvIXq9uD1/hFTFIYeAQVpvMxmzWAja9fStWM5g7xLCOGuzuu0xf0wykHClwjBIyMdjsI0r3s9mcJJQ8U6HzT6RTr2Cb7sWAI0YsSlJs6yk2CGEL95r0APJ7Vq/QRgXNY5sY0cJLYJDCwBqNyVx10LSRgrmfK5v1JUA359O3sNk6Cs7pqCF3G53JY6aAidRsFkMKAmSzufRDUgM6EkJTq7Dzr6JU/tLKmyjyUTyGiVMqKoV4fOwxk88G+R56Pz1yPu386vY9Vmt6SwzN44q6ynksGc+O8Q0PbGOjI2avgE2hxWsKnwxnL3y1onlzmM6VvH4bKeSdsRq7uTmeMZzzrOZaQqqkI1ujAFSmc7W71muNEqzJbMhLi9bsZ7WZVBY2MtDblhDukeTyx+gdOxrzHSabauDlMP3VBzDwRZGjg7rVBZlrEgCBAAFCYAQJdWXzjf2OgLhYHpFLHEqXVEcxWjixLymgLiBMAcskEBGEGaAAhFlASxxDKVO0UET7H3G8TVrAtspGojxzoRrzqQsqC8gFOBdwch5v0xKv2eONF0wcMKdoQaOcPZO9dx5ChzC656eJEnoFc6uKbPu4/cwDL4URKQxch0lHrR4z2Uf6kE1Jjdd1hGCJ4tb2Dj1o47dsNFOo6xVcAJzWLEjMPrLykZGTwFq0VRMCNQtjr72FRiHaCC9KRzHraGZfSV2ZEEz20Z6c9FEZTgmBqLB5P8Oo81j+zIMcXgUjUhjYhpTS2r6fQECI2UchEEJgiBB8YASu5ypsSR6M61k2W4uiS11Go6fgY7dU9nhzC07TBB8YboqvHuYUuQSCzNE2CTOBguSuqUEL11JBW44Y8sGqNmSihOxNRNJhjgVrb27BD7fgD3fBiRe8pctMHj8oXnOTiQTE3f+M67JR1fJihzQ2yYYEANUEl3/WPLY1aGjgKTEihYGroAAjJ5mLrjdB01JNY1XjLdiooYe9P8KWEHrkom2pJwo4sc9ZP6fJw00B7ASYBTILZBKEWXJlczDSUemgai7ViSik0EpI2iiPWDC5QgyWDPSiLbNPiRgAVFKSfuZ7IoRgzqb1YqreR5UXIpWfkD2FdqAQUHeJHXhajEhhoI9qBKO5NtXMMe2o3Ne01LCxu/0o2tdilAI2l2SaiYu34IXgXIAI4CeGeIrEkIrXggNIm+VpEVsiiRUhmAUx9wUimBqIaGo7F6UrzTp644uJZAo52ONujeZrn70XJRzxYVZVzea2vV4Z6QMvhUEKA2tIWqQ6EYI1mWO0UIjAkoK2z7bZR3u4JiNtLYqOJC+0UaZxOLkFb26BCOE8X0A0IXjGIvGjhTmZ4zOBAqohPKvRnMxVozybflouMe0VTrLJ/HM64w93xh/ugp98hqOQZKMFJ1pwIl9VZ7c4Ihsdhbb/iB9BqkW/aveBzjW0bkMfH0zx7Bjy0cBVkGlwlG+vLslbSLUKj5jT3JNP1i0y0hSzXNkcstk8O5/rBdiFOJFNm+StFnZT3azFaz25hOsU1iK7xEiBc9Ga70QIy2aUcI/pfuT8ciUhmR90ooMqAoI+Pkjg1TAihYFd7LbN1osxmy0haFpqXAbvb5+9JUFp1o4uvG+8wIOxBIdFGEyCy+zwziEvoBcBwpmBwJCZEEKKEFyUlcJEYBMp2MyjkpmEUgFNyNXS5ASnKXoJf7gL/j6946d7zxHCjywlxUhhpmVlNOvnZcjqcx81l3eRfISVmdzJPBqE8JoYpDDQh0hVo5DlI9TyUZuNJObSQ1vA5uj4DOItUslVzezhQmlAN1H0FgBgmTx8YPilNMeLsw+oSk+1tQh1r6OaHGwGUvQWJA/WmThWMJdMI5NtpPUV6dpWZ9/z2a/9LB667CcQNRFEJD9Z/3yQxEtgkMLAPjaK1/L9QBARSGg8hRQl9GQk9Rf25hS30IXPvpadwOYkegtvvOAiDou7AAAWucBRwBIYPhD8zFjmCeIDwuRAdr6ClZKIylqp1cymv1HunaRkklprTBxw4gV/uDN+8hlvfMGJinzkIDlSyDJSR0La8xHujRK0rTiS3NVrIb4ZPTR1Gx+vMBn4qhikMFCjO0gnXtEOMWj77GpeM0paats+ux6usx0t9KSj2mgOONGCQNSQggOAKCNB4GeGF8ISGO/TXNpnT0k20vTURAg5Wuh0Sm0XUmEALvY8mp1PVcwL3viCH3SOBGBSUE+GIG6tal4R7E6UoEV9K+SFXvJib9NRq+cMvBwGKQxswxBE2xSPGnIQIx91hrZ9Kji1zp7J40IuZyIBwHuIf+KLMC7O4ew8eAoxRdWJ2fFT1tpVRlrl5dsRnJYQ0g7cRgrqH/zgC04UJSwlApWOrGTUI4ZbPBiP/QwvHQ9aNEBsZBqZWgXtGDtko5fCIIWBLihIXKY6kYGNEChIJIRAMd0zyUi+IyN9FEFqs1rrFBwJTogSzU8+5587BGAG3v2EKS3AQQj/nD3CwrEf0gJTyBZNZ9Y6hU7xWlXoZdpya8+jWLAWj+M/8Z/4G78XIqBCBioZzYkwLLo9j26IEFzTZnwVLTRT4q72P2rOwcBzY5DCwBqb3VFja4T18wG70VWT+RFEAFxv/OYQYnsIWtJ1NJ09GJN4wAEXYZx4yT2R2AkCS2pdYY1mQIft5HdlKr6CqWq2EhKxqk1SNb2b4UuPowPRQQ+POo8thLA+gkEGL49BCgPb0AwkSwYr6YhWmUfxVwsxZF+hs+JsFa2t2lvYYq6myV7ceccU1BkegTjuwDn+Hovg7xOwBIc/pgsmF3DhAJ/6FYkjM2DHppsaMmhPjZWQCHm4T2yCV9JOVTrqGcpsyGKLIHqE0J7Ha/cVTTBQfZbKU+jISvH+MJtfAaN4beAQuhmTRqLW+8Djdra9PP2jOrtOatM5BraTKuecWqOfby2Evwm97KojhLCFR7YXGXgtDFIYOA5prhOoko6Ov9y14TnAbWarS3UAWi2s0lIZwlNGdlKz0wc+nxg0uikE0P/nt1UN3jsXqyhhx2xuVL4MW3+yC/Plyi1f9MC3wiCFgZtAG8TwUbidhdgazFE6Wg/wWU81K9FB1Pclj+zUcZ0ZHYLoGs134Aip3fucusL5Y/+Uu4Qw1v2XxCCFgcfgpgjh2MD6FtcWT22h3XsvjRgqmCycT/JyM44s2luf70iE0H3PjiR1CIMMXhqDFAauYktWWA/e2TaHW3SLqhKOzhHQ2QGtScsp9XPmBQxJLbVTszwzla1tVSEp8+gR8tHWPOprc6rXzz9OCKHz2nvfgc1Mzdj6WoZc9DIYpDDwKbhld7r1R9gdYA86tLDmzJ4kI7lUz7D2FP6axe5IVHBvhDAw8BEMUhjoY2dnaAtj17/3mFRFK330jNkyrtKkpuaGc6bZXJpXECezxUZ5SgylW6hUnsLvrOLVz9SSwU0RQiNN9aSqqkFht0BhYCBikMLAYexuqu9cZNwdv3PUVC0zC4rZzBRSfZqszeX1C9x1bEeP79Y2Flvv133+B43ngdfF+MsZOIatrKOtPMeEh9Us5B31xpxnKxeRZF+hTU/NEhJQVXOVCAEP8RT20H6GXrRQP/84IewRjay63ukPNn+l9yI3PHngO2KQwsA+9rrbNT/67PWiklhSaqqF1j1U9QomPXVKs5Mdh1zAJr2BMzBr5wOH1d+TNnqUEB7tNfxFVsvAF8AghYFt3Jc5ehhHOoO2+nrokIEFNwetxKCpqasCNuBhkcH2YKH7ZKJbJaPVazUtR3ZxJeIbeB2M3kcDt8MsIDmBxyxAW4vQrXOIrfS0miuws59xFKJEIzHtNKT3ncln+chxMpptvyObonoFj9pJexAcBEE4S2B7JLJHCEe6q1YYRDDQwYgUBm6HlVmwlqnpk7SHa6mo6hno7V4hm/ZEigd65Q13MpA+u9ith01T+d5Q5zf4JwPfDyNSGNgGY1tTbx9OckxLCHtFalvYa+Z2bZgMECUknwvbYrQwQyeRhTJwJh97vBK7SN7hJRD15y0fb5HNq9/Vx7dwjRAOnf89T2X13MEiz45BCgN9rAbMNBKLXUhsIVjK7MndSFHPYnYHjYqP9vVxFAABwk7SK5H0l+sHrHu9z9lb8O/FLdGBEmCpzSgdYnP38/Y7Berz0NRujNbZz4shHw1che0e2s4RgGrw6bYOmtGFiJvrLWzNaH5EVk2eY5DTVTuzi294m6PSkY7dBGpCaJv37eF4zQOvnm+70GZiAGqDvSGBQg5UPTbwOhikMLCNNIEszisuefx2EI1kw1ayLENUzy5gk/kDrBfCrf1znYnDq4rmIwVahZQ23qXbAOg4JEVIurb2SGeLEK5hqw5hnaGV6hw69Q72eOJa30QLhtDbbrGSxo/GzzmY4VUwSGFgjd4CQOvbPQnJ+gp2Yex1Ro0L3Mewl4XUwy2L8lVcWSdd4y889L0TbmmwV0VHJgKo5k6bCKFEEIMQXgnDUxjoQrgsDrbat95ZSrzPALHECwmYonRhp58dQdz97y9AXvgwETgK8BLHdEJC9jZK76PmF66sfUJUtlGd5+qOXIvn8nF0yODW9FygV8NRzsM1mSkb6xS/pxjppZRcTSgwcmCJBsm+yEOL+Qa+JkakMFCDqH8btbZsOyZIo133UlJZG9QdMFvjEJ37F59ISGWOwi5s1IMN/Xxvp6zc2fnMLnVn7T1+Ddcqlu+JEOqCvfhY+512iTER/8BrYHzVA/uw/YA6xnK+zUm75tpL0J3zvbhWwdxi773sEB4bvXw4i6Y5PCbpymXaufUabs222nq+jdJKFbdp68Hlup4pUS5dkhzRwlNjyEcDN2GdjirJS0jpqCuz+TE6+q3kYBFrFUyL7bxzvvNgNn5PP3N+H5N99BEclY0CuBtBtPId5QVfYmpp12TG2mQeZPASGJHCQB+aeQSsaxPQkoMSQz8DR3fOewTR+0m3bUOTabOHtg+SHss1HM20qXbRv6mD3PZEt/1jVnuA8vclVWRQNVCtPhf1rweeFiNSGNhF21I6m632QtFoVunIEoM7sFhqjcLRMZx56M6BPY2azUBJDWVIWfdaTf1WNDq8SjaMcJUIW/RmMdzbFM+Zz1odbk5NVSNZEpuLST3Wz0XbPsPA02JECgNr0PE/C209nTeZTRVzWSS1J5FUO/h2ydxrcXENVfpnkw7b9RpyRg5uX/g6z/+snk+Ke6ME/Q62kgBsVXN+bFXRTiNKeBEMUhjYBiNrQutOolJ2kSwgDmCOfYWmdN2mox41nO0IzqMzmY9gKxuogtXRb1gE7VO1MZ8ay/f6Cm3xnmJrLOnVnlC2P5XpEpsNZzRJBDY6HHgZDFIY6GOrgK1ZMOqiNdWta0/BJSnlI7hWwWwX3tLWwqSmmvdnk4X0IS+go8Hbz9we3zWCeJQpb1tr2CywctwlC0lISrvwlgR60togiKfHIIWBbST/QLYihrTbzEVrXKaalcWonwZ6L653Be2Yy6gH7OSPZ28clJBs6wegpLNq0V69EIcuGXw0grgFdqiQS9Ecs0SFkDVSKEVspX1Jr0HeIIRXwDCaB67DkEHOZzc57kgms0uLz6T1CflSDFedl3wE93RHBRIx5NU6vYaUCWy5F9BW36Ottc8cTi2nFVlGP69KVRURmptKbg7ysFGaznxule50qNDEARfv4v1E4nACBIE4QBbk6nSpLtSpbGaAx37yWTG+2YE+tBFeboqHtdacCIHMQlOIwVcDbQ7p+R+E3XmX5ntGStIhO43humuwHoGVzNJndk2U4NBKanXk8EhwIl6HUBn92etJHhBx9BaEpSYEKw/GFzR/ByNaeHaMSGGgBnOzK4Qxl5GjA7Gk4KI0MbmAieMl7k49JvaYyeeFqrSfeNxCqJGHF86v60EmBTUgCGdvIy/OJlK4mnrZOSf5NlAV7M3kwQiYyWOmsE611bvymNbgFi4VzLEhoYmirOckfkc+BDjH8E4gQQAHyCQIDmAmiEMiiHhbtC8Sm55YA0+LESkM9MG1dq4GZFu0RlzXJfRM5ha/Q0tvNftdE7fndWytfc3jlkzUS3B5p56ihCZN9zOihJ4kV7ctr9uZk353KVKwZF9XNQ8SeDWMSGFgFy0RWJlBu6OyiztQl6KEiTwmCpjTrnwmn+sTPpqFBGxXM9vX1ufUxBCPZcrmK6paBbsgZnQWxZW8guzDZ5lqhk+yDYBEDB5UN1qimH5ro5t8/BvpqHuwhrrKR44EM8fPvFD8frwLWEI0nTERPAvECcSlyMC1voJGCybFbOBpMUhhYBumnfLKU0g7TOYinRRTuW6IF18qHKpuvunwEDarmvsN6UxaKrSYC5tRgRDVP+p1jaXS80m1e2c9BYIhgrgjVznJQT5UrNeDHWhkPQ6mIuvlY+UkHynRA0YqpCKvjeyjl8IghYEVyPY9QpERbCqqpi4SCVyKEnKkwAEz+9whlU1F8dH22UfR62/UQwDnLCimsK7sPbjerXL4jafQpqLOFDCb50T5Pi20Equ3meRDbcJ7qMePqr8TsIjk78lxgHMBIRDgNFJAvE6bgWI6D4P5lTA8hYFNFCIwi4RNRQVSJXOMEnQnqrvTaDCXzJteQdfvQhzNEyqNX+Wj7gzqPdD6Op4mMZ9X34tWraJycZkZ+nMvts6hM9+BykcT+UTYUe5jFjgnIBdSrYKsU45zl8OGHAZJPC1GpDDQh2mXXLdRRiUhaX7+xDH9MS483jTEq5vCZd37kwmhKx81xqutU7h3s67nwxrrGhkVEogIVJr/ORL45Cc8MgOppL4ag9lkItXyXiw4JJuW2vhHkq+pbCEHITw1BikMbKPKNEJeFDQVFRyloynJEbNLO1GK8pFLaZmlkOvgNLQ70RJBu4vWdM1iNJuGeNgxmJsGgevaDSnEmMzsmTwcAS6FEQGAlyIdqb8QjL8A9FuI3/L5L1I+p0ZqE8doIQjF78fF236Kn4ucGAmJVkZz+ZxDRnoFDPlo4BDWw3WQi7ZsFXO+VFO/TIrmA/0Eiz1CUOlIj8XCzi6+CiWCHdjitDj6mNIxxIiBgWg+/yY4E5lpzYIt4MspqiktNZvNWS4yJDjwEhiRwkAFMpXMpaoZJfMoSwolUpg1HVVTUU3RWowUQpWOequXcHR2gH1ta0Drz/OxVCmpqD0COiAl2ecZclQN/0QLHAQnIsxwKSIQBAIgggDdjQl8jhASeVDARVzvXQ9BayRysaCm4bJHAMXvxTECCKeQ5ky4AHKM0DObW39hpKM+PUakMLCJ1oBtpSQtXFPpJGcdJbnIZr84s4Pu4RG6eu+1e0TkSCpPo50lkHH0XweV7rD5V3cij2sv+wgDPnsb5vxrq4spPT6ZLCQyzfGqmpTeeblh3sbA98P4dgf6UP+gIYMcJSCSguNYf6BRQpUTn/v+lHYTt0ILt7zwoUlr9n1aQtAFEkBOS/3QnOYOmWgrD5WPHBEcCJyykNxvlGE0A8khlAQAaPuRkL87nZgHqnsgqXRUbwpGpPDsGKQwsI22EZ4dyJLaLzuWbDDbXkc2UticfJYQ8jWloTq0GTlopbISRLvwbxEC58U65CihV6tQZVndiFtSSx2pv/CxtNTeeWKU9t0222imgDe3YOKAEy+Y2efvjl2IZvOqkjkVsuklZ6WNpeNZMb7ZgauoCteqyEHy/IQpVSzPZA3nUC3KtnhM4T+ulGT0CKEUk20M2QFgG+PF+7czwi2jOFvH4Fp67keytUrH1nTuTfZVbl6Yak2U7K1sWH3nAy+BYTQPrBF7V5SooDJWk/bsUt47F2P5xEtjMIvZod+++h/1GbpeQtV0rmQ+5YH2FP2QD01eu3pctLofds6DrVm4tX7B9oNyJHBmfsSMGA0gIBvOQSinw84u4OwCKKWlVjMVTDqqZiHRMJufGiNSGNiFpiJaWcX2/HFGmnC5rUUpWtOmbMBv6o5KdURgd9nalG8l1Tx4jbM9njj91xLE5u8+8BzlyXdm4M9M0WhWX4FNtAdNS9XrXnQ48PQYkcJAHyY3fVXAllouczKas5+gbRSoRAva3qJIOkY6AmXpZDVz4ANo+ytVEYshrhwtAMdbXHwQDMBfew7p/If9aGHvZ45CjhZCShNGAC42UuB4JLHthQc7iR1TTRfcVfHa2EY+PQYpDNRopYG8W2xnKQDMmuIYh8msDGY0Wv6GNq6L20fSUnttud2dstXvAAMAARdte/GBjqlbrcQBNdipjOdMmUieKZPD7Dwcm7YfSggbGVYDz41BCgNrmE6gWVcGsscgKUpgNrnv7HOdQvETioy0RQjto72OobeQRWlG18pI1nAtdQq6ENYjOQ+/3SaO9nbSrqlHO6UemVvtENLkOYETQUifPRavRW8hECNQgGcffQfnQRyy0SzUegrlvBDRF6XagUdgkMJAF1Vrg7R7zJGC+tDa74hqyWhVydyYvNd27x6UF78ji+AWqm6lkJWstNs++5YMpMpDuL5cOqLYB6kBpyZ58XYtIcWFvpyLI0RZMo4IM0WpyBOnMOWSn3dyHjMHOCe4aB8klighsu31VFJSadQrPC0GKQzsw+6ijeZOVMZwaldUZ4rXyljKut/RV5Bz7LjQNh312tS1z8a9WUdtYZ8jyc3xAjh+J8KZHMCAR2p9QT73sKJOZFC1Ahl4egxSGOijrWi1hiMLKFXEnnjBTAE/+II3WjDzUkzmXCxWdutb6OnpdmccwHmxbBfAXJ9gpKM2SrB1E7qDriKFrUVv1SG1/flOOwsiMChWMQunSOBAJHFnO20lCKYAL3GokAdjxhKjDZas11nj/4db8OaW2O7CBQS2lc1U2mozRkXzC2DkEgwchjWadY5CjhQ0J17N5pTpk/v67xRgPSLzaKv7am5xYVpdKGyBLtDsjO/AkarkrdTUR8+XKGTcEGb6juwQJC1kY42ajFyI3jkZxPDUGJHCwBqdVFTbGRWk6aiS/IQYKVRpqBQwp26hpWCsrmYGam08yHZ7i1tRV1OXHkB639YSyIML2I5UIGtVc+mWSqsMJPUVrmF7TrUg2GORKX0/KV1VIkm88RIr0lNlczBN8UqyAWG00H4NDFIY6MMQg5rLMLc5yUexl05tMJ9oKcN1OnMUdLH2QtXirAjCm+RwpCne/ojKrXkKqK+/AbZSUWNGU5SQGAEgZBkJALiprH5zC05uiWmpKQMpkwE3EdTQFp4egxQGalgNPfXUrxZMApAMSUfSZB4tKNPWQu4YWjyFsiAHU7imjfC2sJeHfw17ks4t/Ypugf8LVs7e+YsZSy7fBiWSEAYoYE7P0w63jkM2mnPVOpq/gYGnxyCFgT5MsVrVMdMJyEkev/nGC366M974kiMElY2sfNTKRkAyl8263HZH3YsYHgG5w8tY8YjY461fLw7Wieayyjg6VMfj+uhNKx216ag262i/slngUg11JmVK4ziJwRLlI+2e6lzIo1ajyQzT6oI0F3kM23liDFIYWKP5B2+7pCIZzLa9hZWMWkKwzfB6so5GCXZBjeRQ77ZvStME/WUqx61VyQGPqejuzZtgCoBEQlHZ7ERLJBRiQDRdtYxPpTSas2ptAoxo4YUwSGGgCx2oomMZcx8cBsgJJherl3/yOV3ecdI0VAo1MVCdBQOUBdAShS1ay4+ZxW5PRoopmOuuQkHo7lkFh9GJOCI51O8bDqSj7qGNnPaiBE1rVWJwyVdwiN/RjFjVzCIxndgtmJ0Hp75Wtlix8hUGnh6DFAY20RvHKSxVGuOcI4VCCHOWKzRCKHUDLTRKsItbnra2seBpDr4imJ3wHj5Tiqre544VdCvC6EVN6/fbNpyVGGJ1tMpHaUBR+p5mis0Mc1GfST22RWxj8tprYJDCwBo6oN2mJKbuqCCAUiO8Ey94owVvfMEPulRRAlBaV+8WrUmZtGZ3wlupmLoAeuEuydyK7Ct8MJgQoZWn4BG9hNAQ1pECthaVv9CRiraiqVKfkdpcgCoCdQh403Ri9tFs5tjmopYNBxm8CgYpDNRgTUWlupc+NB1VSndUDph5wQ86R1Jo2mNbcrD3gf0GcMEs/Eeko83XoH1C+hA2XjaTFtYEAVw3l3u/23t9fd7eOeoV9LVT33wqYtPv06VIMFSRAsVaDqYRLbwABikM7MMajikTRWsUNB31ZAxmRTvPYAu9KEEfb293d8eCrpfwW3Aj33hLine83S1puy0hVNGBreoGm7Yk2j5b8qAdazQPX+E1MEhhYI0cJZjZzFwqmpkFM6d0VD7jB1/wN7pcfVnF1uIf739O3lDYIJYVblzoSYBWDdL3CNiXiq7Np94r4GujBItcQa4RWxOp2cc9GD/ogh98wcmYzUj+kTCVlhfASEV9AQxSGNhGVciE3AyvDH3XVNTYFE/RLmbXZgVolNAazEeqly18Yq+tPkh/FfyVSOnDr78jrVlCsGSQozfbDyl1vrWdUitY2Yg+h7wH/noMUhjow/bS150iR5NZu6O+8YIfdMHf6IwfRsLJefcSp3s5EmMg11HCKs1San18pZt3Ull/OzpvHaQ2m3uFbIpW7OplK+XzAK4N+A2itOfQoe4cCwAzLfm+TQDwIPzk91h8yKaAjSR/77lDLkwB28DTYpDCwD6MnyDa3iJFCzP51AhvwWzWCRaJS1JK1Q+p2ds12aglhBZ7O+IAk3J5AI+cCX0U1+Qk4AaT2ZyrzVqFVkZa1Y5IbO2tQ4hSUSKRZP+okMHwFF4FgxQGaqSdYDWfl3qRQvQUZlrwgxb8II0OBExxAWSJC81ZuJuH38pGQC0dXRta76rbdifOOQc/vk+/8d5noSzYgnCDlHV0JGcvaggbKbq5diS3NI+EcEpjSWcAP/hcIgXSFtpmLKcxmweeH4MUBjZh01K16Q+lAe9a6DTDY6aAWVcMQnZedVl2JFlyaclBCWFLIvlIM7z4+vTXSk2/ES0x2M/dJ4Q4t3mGNjAs3y30O2/9hUEMT49BCgPHQWY+QR63qYtNXC1Y4mxfSMp1l7WGDmCzUK1HAgH8YXKo3/v7r2xtlLAF19Rq6BQ6lYtiSq92tC39j9bpqJ1zlr7ngefCSCEY6KPKNCkSgl0ruDNic2uyGNDXy0NjKNvnXiOCrZTM9rXLa/6eP/ec8UMENu/J6bEtHOnRVPkyhlivfbbVeNJ0fcp9qnwaglRqFVYZSJqaxDRSU58YgxQG7oLV6OMCc1wPL5d19e+taah773MUdGvksPP0jzbf+6jUdWRSGxC/P31mHpmq0lGDJwisBm7AIIWB4+gsDrWGvb167DV8A9BNO42/V0cPRxe9rfepjmlr/b1jXY7znm1Ft5VsKMtr8X6NW03wzeysjX/Ots1IGU0qcATMhDQYaUlznaXMrm5M5jGK8zUwSGHgbhSZRCqZ5Aju7fx57XeuRQiP9CYyNt7ymlwEPKbeYu9c7vWf4tVzUjJBzj7qSEgDT49BCgO7aKWDnHm0sZgxXR9wo7v9Xl1CL0poF/J7o4XPQE9aOdLGG4gzDo5iyz8p5/D6i5WOqVE6ikVuyF4D0u09CWk0xHt+fJ1/XQNfD63J2IEtGLPRQm+HbOcmtIRg6xJ6u/kPTSXb+V2bPHOTirOxg277DFU/QyHMj/7DOxIVlaI1s+gb6chRrPUoI1M72UejTuHlMEhh4Cq2NqEaLcRFZa8Sd99P2DOXj8o9vVYZ7eMWnxFt7JnMR434z0Tv+PR7i2NTQy0h7YEo9j8aUcPTYZDCwHGkf/82S+UeTbwrETWG86OykPrv//jXtouoy+cmpqS2fkuPQFs5zhr4130SytftZ2u9BJWOZiTpCMCsdQqmKLHbDDF+0PUBDGJ4KgxSGLgNnR1kNiyJru6Ie3UJW7LR1sCaFkejid3o4JvUYG191r0qcGcjuiQdxfvl+1IJCdhWiXZP8yCGp8EghYEV5GBhUjusJT/eWVa0NqH3OFB7C1uwi/o1+cdf6Z10GHLANG5qNuy1BR9cOK9FX3Wa7u3/hDUritNlzrGZmKrm9GQ7s1mx9TkGMTwFBikMHIMtcE5tLoBa5jgKn9pWtNlFvd3uQxZ2lNYWj3q9jB3tXUnAVjaXnXmRb+xO/rOgGWPW6K4iBSMhZfQ+27UVYxDDt8cghYF9VDvE/qKlcsSttQrARqZRr//RF0lD3cv87Bm5/EkGsy3k25u+1oMWz6nf4UjWKakmQlj5CsD+kJ1BDN8aoyHeK2LjHy05BzgXW2c7M1zHLAyx9U1spsaVfEQIB3a612Yvb9UslMfK3ASdtHZPtPJo1BXM+8fD6DcJ1Ne5Z9aDFwYIuWW4F87tsquqc+MnlOON3yWnJnmUJrCB4sFKvlC8TA7kGDRPabpQeX3RMnFCLb2NxnnfBoMUXgUtETQ7PWICnAMRQZjXsxRIX6ZtgHf7P/awUYi1WcR2Q5TgheFoa8m9H2TO32f0AnIkm91b44CiY/BCh+sJ2iyodadUqdtcJGKIk5YcyOmRudwzhDgSgQQpf2MSRkfVb4RBCs8O/YdPHBf+dBtA7nRJRABzjBLeTpB5Qpg5RgtJ/I5DdgTMEgexdDqkXkO3/1CPHDZrDjhf93bjAbxZTXx3Cu2uTLL9o5iW2iy6iAu2l1TX0bQXV3M6VNchTpWjcJeE5sGYr1BK9BdClo4mCmAXAJdGcjogTECYKP5d/JhBlwX09gbyHqKLfQhx4c/XMYqQoOTweLIeeDwGKbwClBAMGWQiAJImxCDHiRySTGCkA5WONFKIC4iOe9xGQGyGd22GwdU22Q+wv3Zlpk+WwR3RdgO+LwKVkShlH1ElHxGEJW0SGDI5YJri35JKSEQQ72MU4X38uwkM4pAihxEtfAcMUnhmpKrTTAiWDJQItD8+MTBNkMlBJo67Q0sOTgDWGc3h7p23bZdt5wyXnx+TjfxOVHANrc7+2YhHWneTtf6LIyBIKhiTFNUI4CnAiwPrNUKKMAB3w6cPwsAVSS3PW9ACNg4gFxIRkIkUCOHk4C4z6DQDwUFCALwHROLfWhAIABIBKEB8lJVGoPA9MEjhydElhOQdZDJwHMljcpEUHCNMNlKIC5YdxQncn0LZDorpPd6TjeLzj89bPnJ8Vlb/HK+AETZWQ0cU5zjv/f4NfsLxY2q9hPJeDMHEAZy+c3G6ISAE3SjMDjK7aDT7AAopSjBT9wgospIIEJK9PqKFL4+vkec38Hg0//BthJAJwblICM6Bpph5JC5FCkY+UpPRykfXMmw+gi1CyI91Vu91Fe92Y7rfhb3q7vZTtfUKbXrr7/ocmoVEJCCW/DcQnBIEQSaKfyOTA/JlAqkvpUZ00qCySb/nzwx8GYxI4ZlBnKOEKkKYp/IPl5OPwAxMcQcojtMCYC5cUlGn3CenTww+LWC+WcdaOag3VKd+nTpCaBFlkQB3RUpyxhSvqrDTS0obeXwgYtirD4h1HCGbzfHYIjQasFlIDlF+cUKHekH5lJ7rQZhvPG71iGbymNhHGYkDgpOUhhrNZj8DfmbQyYHfTpDFA97HrCPHoCVGA4IFAErEIBvDuge+HAYpvACqHZumFBLXhOAY4pLJ3BjNsXAp7R6z0VxfH0VvhkLv5wNrOAq4SDu37YGvDzOWk0OevqbZZ8VforRxIFCitZxrxenvwYd4W8rf3hCNvgcGKTw7NErQ0J5NhDBNUT7iRAiTQ5hdNBSnOkqAi56CY4k7ydRqGViPl2zR9j26x0fIz0lRQfQWbjsVdtH73WAwvNkqu+QqlwgBqSmf5EgrQI53SE1puvd0l1Xpiin5CRS/Z2aBOL2kaGEGwswIJ4G8zZAlgIhATBBOQ1cDgUKAhHTsPmQTepjNXx9jW/bEIDWXmyihRAiUqpeTdJRII1czM5lWB3WkAOwvriqPHO01dM1HeDRunYv8WdBBN5s/3xmn+fBj0ZkKKBlIoFKroBsESZlIEif1ABPHvx2NNtPfl3oJtvBv+ApfHyNSeBWYSlRrBkqOFBwwcSxOmpJ8pFECC6BZrGY32SLcaD7nRnh7qadNlKDX96ajXv29HQ67NzvJtgBRX6FtCcL63pIIy/y4zUCKMlIiCnH9XlEHibU06ivT1yb2Me2YJRawpUtIqal+JvCFEGYH4thpVQMd8vGTkdbA+ACwH/2QvhEGKTwrcqFa2rkRF9koFhvkCCGazJzqEyjKR7orzL6C6sySeuSEaszjEVgZKS/wOxFCjxAejRz53Lhm3UMQmoIKpA6qEiUi+7hF2wfJQXC54f2OnrPSIC+kbqmS6xWSthQ3CBMgE5V6hTlRnACc0lARHLAgypIiJe1Z/waH2/zlMUjhBaDSUalTMAYzazsLyqTQVjPbiubfpccfaQp3SwFbb77Bo9Bugm8pjEv5SEVCMoVsF7mdCO5FThwwMxUch5SWKrk5YklRTampqY2qiJIAg5wkEgipl9Ywmr8TBik8M3SGbs44Kqaz5piLRgizQ5g47gAn3RXGHSJclBGY4y5yYh87cN5ZFdzvd7Sdftp2UXWU+gHBH6rW3Sq224oSJGXc5HNXv1h9X1PwaV1b8Aj0uspuyW4eHKMPc05658eLYCaN2GwH1RgBqnzkWGJVMznjJSD+jfh4LcRwKPVo5GM1M5wHhVTgsCzr8zbwZTFcn2eHhu0awnMylnN7bJN9pFGCaZut1cypl1uuVQCQp3X1Zg632DOc94zlR8hGbd+lXTLLtQvldygTKpXn0OdUQB9Fez73ekv51HsqgKrakZ5kpWBLmJ1IoWqlrReKl0youYFSftHSlHHgy2JECs8MLllHZCWj5COIc5A5Rgphjq0t/Kn0uSnFa3HHGHePZWzj0QyerQWrOy9hw0eo0lhTtGDv39rLSOUkzcUXoCz0+pgjsBqmzsVFj8kMnlHClNXrXh2pKZp2Ghdnn29rX6jSRNAO1Kkjh0jLPl1iUzrOk+08RQ/HDj8KiKp+KTBM753eS79XRpGPkC7aNdf2QWIAIRAopJMyJRnJMSQwaKGyKRn4Fhjf1JOi2pHpjk3NZSrphJIes55CcIUQkExmEGLuepJJjkhHe88o4za3ZaNbcC2iCB0CqkdP1vMjpJHb4jksz7W/h+S13Opb+APPb+s7dIxpPa+6Q66m4WC+b2tCsJ8tpunHBOQ2J2LaXuSLKxEDXCJMZ+XKjgQ38KUxSOHZUWV/pLqE7CsoGVCOFEqPG2MyM8AuLhKOtO9+yj76JON5a5HfI5F2F73+3fXiVPkKTaRQ+zDGgL9TPorN70KXDDRKCOlzBbOIx0igH1VZf8GDEYSq8+KF089i5OFBmQo84vG01JDrFLQuJZFBbqPtSnO8oEkKWXosf2d6oZ43M/BlMUjhiUGkhEClSK1KP03SkcoCM1XVzGGK+elQQuCAiQNmCrnV8megJYSjc5zzzw7ml7ZT5BRRG0+LvuNSFa7RgpWYzI76ngIzlW+2UEUEKhclAgBQpKP2uRpRdBsK2uLCpvFeJv34mYglS0hVL6xc8Z4qnRMpZPK00UJCVcQ28GUxSOFVYCUkagzCybTKTv/og05cS/IRmdx1O2DnVmwt5lvSUZcQbLRw559wLR1JEyGgyB5218sqK5mIosG9GVkt9lqDKCrPxUQVK1JNnoR6Ffn3lRikT6RlLCdy/6MiJSkRpMr3FEFE+aiT9TYI4dtgGM3PDk5tLbRy2UYKWoRUXReTOThAJgFPcTzjxAET+egpoFx4L7PIShkbXVGPEMLe4u9RWkUElFGdW91CrfZPxizW7BkhKTp5ltxoRQiWSPbSUdvq5Xhs9RyFLB2BKv+jNZl9s7gHaUxoUZO5mM2s1+m1K7O5c9h5JCfF/kfEgpD6IKnJTJ4QJol2kwdoIiAAPDFIAoRjw0XRv79hNH8bjG/qWaH/CHMvezX9ihGYI4VkFuYq5tzeAmXRMwN2dHLZo3bFFp9VudxDdyG3EYAhBJWO8nyJjun8yDqF1jzuy0C1XFT/jDZlNOsr7CGbzasoap2Wqo/nc5OjquYYBjl8eYxv6JmhOzQzfhNp96bmcm5bYMctTjFCECcxUkgdM6fkKUysjdM+Rgpb8xX2f8dm0PRTVm/BasEjk49fSSFcNQi05HGk0tvaucHUB2gqarxN1WKu5rEtWtPIwaaiqtSUJaLmvOhz9efxcY1MJEcoAHICAVPIE9iYQ/EUJo0gzW0zujVokzzmul5BfZmBL4/xLb0CjPxR2lhYD6GkoVbZRw7RT+CQqplTsRpKQ7yP/gHdKx0d9RKOms4AtrOPTPaMSkh1RFFmS9zrtbS/tZLYdjKreg0FNW21H2EoMWyPAtXvN8prmoEk6wI2V9/ORnN7/ga+DQYpPDNas8+VayWGoOmFqYWBVBJSbIjGbE1mM6O5swAeyb2Pz9vzIfqEEIyOXp67b8ZugSmkdV+y0byqU9Cdrq3tIJOdBACdCGFPViuzErYrim3Rmv1ctj4hppoWPyHYKELWNQo2LVV9BftzoBmyk9KPXfIVUKWkmswjNZztZiP93Ym2Z2czknPgy2OQwpODTOguSQIJLmUbTchVqpLloyQNcJSQ4ATOBUzJaJ7ZrzqktrOIe0vitYlqV4vPbigK0Nz8fP9ItJDNZuQoIBZkca7tsMRhL5lcrqBXLKb1CfG4a5MZ6E+qixKTMZ8rucn+jHPBmz5eRxxrYnKoyZ+M2VwG7mj2kal8T/et11DJR8CIGL4JBik8K9qK5mwyc17wVELS1MJqJ6gzFFjSv2uJmUe5xUXKyd/4d/6IBslHJaKPjPDM2UfVg8lQjk/I6ahVnUIH1le49Yh6clGuP0Ahhq1z0kZJkRC2jeY63ZVW51AL2PJgJe2BxaWyuYoe7Pmx0aliEMK3wSCFZ4apYi6XlH2Ud3paqNYUrU0AuOl5pANYSMuijunndXuF7Xx73dXG31nLRvbxnkTSvlcPjsrMAC3Qsrn3ZZFLPksu9HPGUC1mNDh5Ltov6IMNolcL9p7MduCfb8w04nVls5TU1N7rZQmJS6QANpGCdkw1RnOOHIynIPo3WF74hrMx8FdgkMIrQVMsVTPPefm1edjLwS86823N8CxaKaRXaLX+nTUhPGpcZ+kEmsxUPQ96nbrISsqksXUKWtSH7EPbKGGfLI/6Lp8NzUAK2E5fVVRZWmz+PhgrSS0Tgn3JkXn0bTCK154dtueRlY2arJGSPYIyQyHtELWaedLsoywd3Z+Sus6rX5vL/Qih7ogaSWVfrCreRz1IRlt3UJLKynko/Xwwccq7T+m6plFgjhSoDKaxx8Y3klevad+jENNSQ4wWSIrZvFHNDNQS0ioDKY3nJK9/U9pem4BsTBvZbeDbYJDCC8BmhAAwRmqJDIpsYsxWNhICtYZkylTZed+j6aBHCUERB8cgp8fmx0018xbKLOJQtXEQjsNh6nRLQpjSe+cU3jKVDqwlDFrYF/LrH4Xu1lvc6pP03lOzlTyKb6JV3kWmktQor3gQWqcAIPd1Upmt/bvJkluOPm1leGMyj2jhW2B8S88O/UeZd3Go0irtP/L6H7tWshaz8Z6+R7fsfq9FCFsL5T1yUpHEopneVuoGm3bZjCjNzzPnxw4fOv55P4ZrBLh6P9MOo0177UGJs4oW0mYB7d9M8/djDXkZPsK3wiCFJwbZXRqwyjpqr6MJHaWBHCmw6Y7Kpe+R7ooBxCH0V2CN4GIsU9dYLr9TCKF9ndaf2CKMSjJSgzy3/Q5FPtJogQsZxLRdhsxctRYPmp3lorym1d4MGy1cOR9NKmjdI6r+jHs4amxXDfPEnv9SDW2fp4j2gNTdUq3v0vGisow0ite+JQYpvArMP067m9v6h138hNpEtdLCrbg27wCwhVs9kqh3t7fULlgUMjODZNqZAWwJtJBmPiy7I9aHPmm2xDXck/FkG++1GU8AqmJFMjKb/bvJ50LJIBnMVZQwahS+HYan8KSoooTGaC4RQ6uhW8NZd8Fx6XAUcufM3B31IDlc8xZa2ehahNC+rxe6ujNvURVopd4+tk5DI4JwiscghM4QouK3xO6x4WZJp8W9RBc/U4negsTv2YPBCGmEqSSjOYDbojfpZ4KpxJYL2FJaKvl4fiilojJTTFdVMs2bCwxC+GYYkcIrwaSjVtW5VeQgeYHUjR9XfsIDO4FiuxjLYj2knis5pHruFcnFmsx5kIz57GvjfV2/IIw805kMueTd9Q4xhI3WFreiJZ9bCLqq9dj1FEz/I5i01NZothFEJoMhG31XDFJ4dujUNTWZVxECmd1xkVBIi7JS4drEseDLts2OrS5uQ2670LaG3ogS7G7WkoF97lHY1NTY5VVyJ9AcKaRzEIzJHOZ1Omq8RPOVTfHaZ+MjkUhVRGgL2UyBm0I/Sya9lGGVowVGlZpbjHcYCRIlUh39j74NBik8MzTrQ1tcmIyjzd2wK9FC1QgPJRf/SNvsddfP7T+1a4RwBL5Z1LZg/QSmUGYG2MWOUeYQT1R1kdXzY88RU3k9NbDv+Ye1N//gHlgT3laN15EWbX43radQt7vQjqnSbDKKt9CbpzCI4etjkMKzY5WBVKSjuvmbSgGSZRHteWRTUW/LwT8wUvKAht6ShM2W6f1+uyS36aIqtdTpluib7w7rRc/IJ/kcaRTySXOrH4G2HsQazJsFbJYY2BayochHgIkQin+VX3JISd8KgxReAbbvUTaZrWyEUrSWqpkpdUd1rMVeJmLQtsobcslWS+j18+pFCujLRr379vbRfXmRj0L+TBOFurePEkEeKKNDiLTKufwcyYjXvlAz+ep9PoIj0cGRupEyO6Gcq9Jiu1zaZns2OoyJBklCcjEVN3dMtecrJzGgroUZ+FYYpPBCyANigFr7BbJOLkknjwqALVor1cO36trX8u1vJYTWW7gFOUpAqdJej5yUJuceHVNVjFwu5nVvjxRu/Sy9IjnNCOu/fk2evjmvrdfQopKQAFOUBlMMWa5HlPC9MUjhWaGjOKt0VNTyiKN6p5f6HcEJ2KXdr/NxBCeV3bBGCVFOotU8hT3knerBP72tYjX9WW6SZwzT8vO1xLRJUGmh7Ulr9e4XZelV6ekB+My+R8C6eNDOV+ilo2qGlnbILd1Sg4kWbArzep5CLmIDstk88PUxSOFVYMZJ5opUazZT2flpla5LNQoxB7/IRr8Dt/T+6XkV7S649TdWi3AijtUaL+Z69TOCPEgf2ctceoQcBTStybPh3I8M4nXd5kIH7sBcxBj0aDYepdfWIIPvhEEKzw7TnEw18dZMzamYaQdITrXylLJJgpk95lSgpbMUHrVYWRwZ09lOVgPQRAj1a9SZNnWefkBc2EUAhBgGUKCoIAXU13obAKroYz2k5hZ8xnkESmvyNv23lYvKvIXyuMvEIDli0PRdTn8jpVgNTSRKjaQ0JKTvhEEKT44yFhHFbM5T2JBy8tNOzwHk4j/8OILT58VgyrUJMZPnd0QMXXO5XdDMbjd0dsLFjK5/r8w4Trt9ExGQIObUSrlQe18ASZdyvNfnQxxFjyjsOd87/z2CynUJKNXLhST7RWxldobOag5wLtaukAvlb6jN0LJEkFurDFL4Lhik8Myw4ftGNXMuMkomsxatEZCzcyatAobJxddWFw861F5WkcWRGoSt57btHOJtMqSALAPFKMBEBkoSVj7K1xplbO/EvyrUS7CSkkWpSzGZZwTTHA9FRqr+htCpbrYvPJacr47R++jZ0eSNV/n39jKpwSxwTnCaPGYOmJ1P0lHATEVCAn5PA7helBDSB+HUwwdIejnFPj8zylAZDwLDEIMxWYNwWdQ70UGMEGKqLoFAIllays/Nx/nXEIFDqEoJ9buJPY98XPApTXsTlNkKUiQinbuQX9O0Apk4YJJU1e48fCAsLkAE8M5BJin9oLLBbNqFVN1SByF8B4xv6ZVgs2mUKDitf2nXR0km0KlkpTahFK7d0gzvFhzZYR8pgGslnJCkoq2W1JK3tKiiBCsVxXDCPG5+V9//dxODTQ2+pznh2nupmw3Wt5uZzYQSJZCsos+qr9bAt8L4yp4VVQUzATooxmQZZT9B+/k4gZuibjw7j4kCTrxgMiZzSUlVCYlw69jJI2grocPO/fj8aKja2oa2IMtW8arJXOSjYjBbHyGby6H2FfR56ikEE7F8Jm4acGRnNIhN3y3mcu88xfcpI1gnStEiG59p8uAplNRUazqnQrZq+towmr8NBik8M3r/EE1Kao4cNErQCt20IJRKXdsy+3rfo0fhWkZPazQrep7CutMqNUZziRTahT/fRvt4MlEfFCG05vIWAdw7cQ0ohrM15K91SrVpqZqJxMZXsFlsNhqtWl8MfBsMUnh2pO6oMSW1ziO33oJtbTFppMDFZFY/wZkspEd0Bb3W6bQqVutECIq48+fVbrg1sG06axAqn6AhAAqSPQVS6SgoIdCKEGxa6mdEC/dme9lqZp+PtWQi2Sl4CkbpIsuUss/y9L349zGlDrpa7Nh2SxVKf1ujeO3bYZDCKyD3PWrkI6f55VqbkIzFjnQUR3GW+oTP8BQU17yFYHe6WNcIrArXUHbDRTbhKvsIqU6BLDEoEXhkYmg9BxEgNGmp8X1+P458J5WctiLJ8rPc9TV5SpNuCFLyweQC2MXqZu2bZauZS30CxirzzTC+rmeHnafQmswmlRApFdXxWjrS+cOxkVxZAW8dVH8E3Rx7QwIW/cfK4g9sG6uVKdy73UlDzWSA8lh7nNdwZJ61xVZh2y0SXhstaOaVLebbnLqGIh+VehUrIdkoQczfGFCdjlHd/G0wUlKfGTYFUEN6EyUE3eWlNNRpCjhNC96mBSf2OLHHm1uydBQvC2ZazFyC3/ePXMnBUdgwmmP2TBAGyOeIwEFKhJAkKE1H9SFeI1BlKKuEREFTOKmQRDacKdcqfGbmESPA74wzYgrwsv65BwMSyV3PG5CIkziTmpeadLWDrJOAiT0CCIswTrIAAJaUzTVNHotzCOlvCEx1aioJxA2T+bthRArPjlWxWj1oRz0G7WtDSEVrnCSjXNFa70w/qzWDwhaategZp3vP2UOutViZo6gjK9c8B+iEDh/HXu1HLzq4pVZkaw7z1WNCHTFo1EAAtKPsKhW1Ok8jA+k7YUQKzwpbORpHg1X97q3RrF1RHQe8TQtmLiZz9hRSlGBbNFtiCBB4kc0ZxHuZRLs/25FkAmi1fw6pVM2il31UT13T1EpBmCQOo58Ifgb8Wzw2YSDMQJiAMEkp9mPJxutE/kOT1xQxsjnwPAqZ/Bxk1dNIPYaQIgOHkIvZIDH6cCTZoLf+jENAIIo/t2RAHjPHSEElJM1A0uyjymwePPDtMEjh2dHsznLBmvoJaberXVEnKr2OZvZVFgqwzoIJImjXbQ/AC3IdQH5umzraNLH7SFO5W8CILcBPLuXeTwHLFCAzI0wAnYDwBvgALG+Ud8H+RPBviRxmAc3xd2fnceKlIs4PHyOFxNg1jhJGD1FKK8TACFk6qmsaev5CABs5snRORSlgQ3+oziCG74VBCs8M2y67kpDSNZCNZu2K6rgUK+lge9sIz6Jk9ESNPyDENgoNVoVoO9LQFh4xb0BlsJkXTByzq96mJRdi+SkgnBgkgH+LJ2o5l/PlfwDhBISTQE4CN0cP5uQ83tjjjRecUpHftgOwdWxy2JfYIowelAiCUPQWGmLQ5wBNQ8GUnVU2BC69t53AhzKes5KL9DIko++IQQpPjpJ1ROtOlk7TUUPuinriuIO20lGez6yZ7SZa8Ko3i8CnXaxebHbLVifOXjrp6rEHRhCMUnOhRvrb5HGZPeSNEH4wQIzlHImUfIkUlj8A/4cg/BGAN4/TacEfpwv+mC74w53xlqKFU5Kv3AcXRO1rFG9LI4pdh0pIlhgAlAQErcaW8h1tHovJRJooYCEuGUith9DDIIdvg0EKL4KcaVkZgZJ1YK1iXnVD1SihIYNHQBep391V1CXzfOJEfs6XTJpJIEGiPBSiXAQgThY7CcKE6CVoOxAOOBnfJfeH+mKLoBIDgCpqUGy1J7fQCEFvZ1S3h5fw3TFI4dnBKMVrpg1BqW6OnVG1ivnk0u6Zl7zzndPkNV1MLQKirxAoIEg0m73ojp/yzj+3ac6Rw7ppXSszfQYcBcy04I0W/OEuWCaHn/MFPjBCIPiFISzwC0EmxJOlkcLfBOEtgH8uOL0t+NvbGX8/vePv8zv+Pr3jp3vHD7pgput7ekcEiCAQELuXRq+jZ4i7TvQU5aZ020QULfT3NGLIkPI9XmTK31OPEEqUEMBCmNhjEY0UQj/7COb+qGT+Vhik8MQgorXC30sbTKZhzjiyPfRN1KDo9d7xkHRJ0tEDtoqPnlvszC43kkPIqbdapeumEE3yUwCEq0hBZgGm1ApkigR6aslTK74feuTp+Cng0nyhkRBqf8GDVma3JYf4nDUp3wImMRmnMUMpRgwqUd30cgNfCIMUnhRUdUlFihRKm4tcyJZGb+rcBI0Q8kLHS5GRqD+CU3v1t1Rh/YFQmZkqG+3r2J8BB8GJFrxx9AEuwvg5nXMGjg+Mi3M4e0ZwApBL508gPz345PHjjzN+ni45Svjb9I6ffMYPuuBEcfZEPgdym+QWs4vWEUMPsajNLPYm2uoRA7AxwEi9HxPR5feggCAuR4qh2iyk5INmk5H3A4MYviUGKbwCtM0FUEJ7M3ydU2uL2PTMV7UJTouWcvu0epHzIlVVsxrMwRjLtu9Qfp5NVZW+tv0Z0M8wUyHAH27BIhcsgXGeLyASeM8I7Iw5K3BvHtO84Me84I/5gp/TGX+4C/5wF7zxBT/4gpmW1BLkoyaz4NJ7fKN6uYejhNsbWboFTU3VITxVWqqiQwxCNDjim2CQwrPDkgGZCCHVKRDB1CiUCWsaGRTDuW3rbAvXAKD4CRYtMRxB2xn10XAUjfOZfF7UF2EsE+MyOzAB3jMWEixATrmcTwtO84Kfc8w4UlLQKCEX91kZBTFl96HHv0EY9yB3TG2IwZK29RPiJLvSShtANprbfkdiCCE+bzRQ+A4YpPDM0H+MNhW1qmqOlczMklNR3zgapW+0NJXMawnJC8GTwEEjBJTH1WCGyX3X7qRGSrJDcT49Skim7UwLfvAFP907AOAf86/08/i53qcJRIL3acJ5CulUCv7+xzt+TAv+9e1P/JzO+Nf5T/zL9Cf+4X7hb/yOv/E7ftCCGRJ30x90Fmwa6rX+R9ewJRvpz6xstFUvYSWkKTVMdKk1ihJn5VcNfEsMUnhFNBpwLFwLuVhtZr+KEnjDTwCihKQpmLFG4XMaxD0qaohGcKlXeOMFi7sggHB2ceG9TC6ThO6Kf84XvLkFP6cz/jbFuoSffM5EOsPn3/mofPQobLUVrx4zWUdb51iznXIxm3D+rCViaH5pkMO3xCCFJ0cZiWg6pGqbC4qtj6eUa/+Hi7r4WzJiNb1SR29qZo1FFkZEqoI1oOz+69GPxWRWdIvaPmk1cZAUKRB+yjkZuwSHgDe+YKKA9+Dww11wDhP+PM0AIjH8y+lP/HAL/vPpP/CHu+A/T/+Bf3H/xD/cL/yD/0yRgsfcOXS/0RPKHlfvPGi6aZvk6kzkELugrl/HEkLbF6kcF+fus71zHhd+NZsDkLrOTho1clhFCau22UmqjC84JKSvjkEKrwAqum6bjlrGLIacVZInq6XUTW66pPaK2NpF66NZRZwWawvbAE6fcwscQirUC3ASs5ACEd74kl/3D3cG04QlOEwcP6fuiH9OZ7wl8tQIQc1lK6vtiTxbDQOPHX/tJcRmdvGc7NUq1O//cb+me95HxtHTYJDCs8PWK7U7OU7N8AhZNirFaqWthUYJwJoQfPJUOd2+pz5Bd7d5FoL9WSICJQklp1JZW0cvR4bPaLQwkwdYq30FM8Wo4I0XOBJcgsMpTZxzJPjH9AtvvOBf3J/Rk+AzfnIsWCtRlTXg487ai6z6Qnmp21YcJVFOxHbpZCDp+ds7n+X9i7FsPR9tebF+X218GD/TKvsIKJXNppBtzGf+fhik8Kxoq0htSE+SM0NizzKpooSqxUU1aa0suEEIoUlFDeZnwLpASjNzgpRdO5cc2byQZeSCK5/bZOdW0XZWtDne3rGuTg1ig7cowRBm8gjE8Ez4CcKvMMchMuTy8TiSLK/94JSCSudU97CuYPapHxQoZEIIpj9Ufl6nvuMIOJNlKiwkhpfjxNBGXdXPUkGclaW2j6POQBr4/hik8MxI+q3drVUb+YYQSuM7qVJO1+2yGagKtADXcNDeztfu5u3ipSSAVTTCRbIwkYIeL1AWJzXFe7AkpeR3AnCR2PoCAAJxjq6mNLUsHmfIfkvpcySpLkH7Q6WsLJTWH5HsakLQKOEWMnC9KKrJSHKpmK1HDJZ0QyPBefMeAK+SBNi21FBSp/I3QuZvZfQ8+v4YpPAiWI0hTuZgFSmklMNaOurPUVDEZQSl39EVGUQXMiaJ/XcIazLI0YBfLWS6BLLWU+js6E5hnT3mlhCCME7k4SH4wRc4CXFnD+To4SIOPziZuZDU22iJklEy4k/kc7tse05ilXdIC2qfEDRKsAb8Hhgh9UwCHCIxO3CUqQSxDkD6xBDPXT966EUNnFp5W6JBMqMrAu9gEMP3xiCFV0KbEWJSLjMR3NAJtVQq3z7XdUvyiMem3Tz7j1kfQbXt6nUPIFdnE+CUnAAEolhfwABLAIfSBPBHmk+tdRsaJfSgBX2x2V1NCFvY7k66X8Wsn8NrmmhDDPoanz7EaJDBU2CQwrOjNfqM2axRAqHIAS5NJVM/IbbS7mUbUe7q6fKip/MTOqmVWVsnODAuoto15Z/n3XwTKQCFdIIhg5IuW/sf1hjvwSFq/Sd4eIRoNgtn89kLpc6hjAu7TDQ/+R2OJFcvl15HS5bcPCjPlgARdExpPGclQgBKlNCe12vQcxl37iFHCJkQTcSgn7eVke6Ffue5qhlYt7lA5/7At8EghVdAbjdQ3wdaT6Ho8VY62oMXunkB0EVcd7aqYZdFzTy5ybXPxm+e8ZDMcdwe6bDGOLSAwVGSATAT4ETghXBKrRk4eQoOgh9cDOZ2bnU5VgCGDIA1IeTnyhHZLUYZW/UMwFoGUjN/K0LYM5uBWkKKxnOK6LT9xzUMYviWGKTwKmgJQYvXqIxYzLtu1Ltue20RGkKwC1ttZq5bNKjkkbVwC9NZ1EYQjHogvR4zYztLqoesiatklhY6IC7yPvkNQIwg9PWUAOy1bRqo58hOn2P0ySAX+O0I8GVnXz7XygsA5XMYDeBg7lPzOlS99hZZ2KwjJQZL3rto+j4NfD8MUnglmPxxvU9t8RoVDV2L1vYW2aCLkt6XvnwEaPSRMpekzpqpj3OfJOKxyUo2sl7DEWJQknHkoft5j0J0do7xKv0135Z+pJDu2ighvz5qMsgtJg4upjFaiMVqKt0BSJazSkZhJSPVv78fbajBvAUbXQLYbmmR9aWB74JBCq+K5t+pI61kLlJMu9DZ+1v9+o/C2ewjfU0xC1p+n9Jjpz6WkGWj9nfKY6aQzEQY9vktecz2TnuODBGU+7ZwrmQvYSUnlRf7CCHYhT8/ZqIDPaetjKQEgp26hXCgJXcv84g638/A98UghWdHGrJT+QnZaJbaU9AWFytvoW/cRsORqvubO1DVxHNqY9nJKpjWC14bRVg5R2Uj9RJ640LXx1EThvUo6seb+wcJsPR26p+H1js4ZCxnqa2WkqBKjdaNNMRgZaQj2Ue91iIATPrwuoZh4PkwSOGFsPr3nJSSnJJKx2oTIhnU949EDb0CrBbbKZ6lkjlHAoYQ9o53dRxNi4xqTGcmx5YU+pPlqvudBXPLQP5YBtDH2mhb7EUIvVGf+RhS8V8vihv43hik8MywWu6qIZ4xmVGiBdsmm7HvJwDIJmTsiJrqFq6kPbYG6RG4JsNfiavX+2hrbKhFrGYOJg23zFZ2FGUkRzESclniaQvQpDaQqWQS7X3+j+y2i+YvJjrA1WihKhTM0dp1tAazdk21EhKRoOqUit4GZEQY3wWDFAa6OLrrbnFtB2w18ayF34nWWD62zPWOyWYuIRFDjIZmS1qS/keU000jEfRf997F/54oQsd0ak+kI1BJqZWNttpdXDOfB54DgxReCbqLsw8lXyFn8nQM5t5iG3JK58FUxQZ7GTBbaGsQeplGu5lSKZtIow6NElyWjRIhpOuZGA6pwhnAhXxFDHZGQqnuphw13ZJNdAtUhrPRghrJUcoLq2ghwGXDeQ89X0ElIvs9a7Fj12TO0cKIDr4jBim8IKraMCGIaZfsoZ03C0J67F5kUxTrYTG3FJtVr9kQQu/47GM930PrLDjXW5T0TofYKC/2+om/F+9v9C8yBrMSQn9oznoR7U5Dw2PHk5Z6g1BJSFW/qSbKsC0zBl4H49t+JVzZkD5i3OWRXW8vZfQRUII48rplYH3yAHQhz4u8TpITXCTsE4KJEq5FTUoW9tJ7Tv38699Le05t1tYtUmCU4bazuI72lhr4vhiRwovhaLKIz1LLsUWgNSTt0HmLbJRuaN+3EMVelLAHjRpKXyWjq1GajkbARaSqW9jqbmqN5XYU6RZshNQdR9qY9UcmppXWIaUdBURrFFpJqR8ttN5CEFd+FyWx4MF8PvCFMCKFV8GdYyCPRA9tWqJd8K7JQ7Yi+B5CuBW6uNYLLuW23xoxXCQu/hdEMtgjBH2NIMcIQY/DXnrHuAe+MxLYfL0NX+ZIyumwDp4LI1J4ZlwhApFiHloZxUFbP3wMNltFfYVqKMwNmTK9he/owmgL3gAdvxnqYUES5Z+ZQiIJnRK3NpMtGbSmshLCNZN57W9sjM28cd9ms5BuSU/1IFNYSJuFbFsgAmTULDwFBim8KjqtFq4h1hbwzTvTNtPoWhHbza9fta/YXpis2RyJwVfEsMqIanq7qZlsM4z0dbOv0BCCElDvWFafo2qTUQihF93Y3ykLep2FdATaO6nuoRSlv3zdNMjzslPhPaKGb49BCgNdxAX08ci9/W3zthtJYMtDOCo/aR+kvHBq5g0ITpKMRbrr76SdNq0srFzULujt7XKsx4jiESgjNNfRQzAehEpI1vOxDfLuaXPx2XN9Bh6PQQqviM7aqYtaQJwpzCimZVys+jvej+JqN9Od99z73a3fy0OBTAfUqkLXkEP8SUc+6hjAW7v76pgaCav7mZoCsb0ooQdOv29rGDTN2NYorMahUpnudq05nkPAApe76g48FwYpDGQ8IiX1FvQ6furj19ASwkfTW6uoASheQ+c5VSZQJzLYksaqGRObfaX2X2crY6uV53rPszMs+tFL3UX1aOfUgefCIIUXwmpTlzIL9ySBcEOEEPXmlOaZdp69ts1tuuo9JFD97AAhWLO5JYAAI53oa6bPcem9VrOgtov3EZN5e8DN2m/Zm09R5idIVXymprHth+SrlOF+iqpGC2o0s0Yc4M12Hl0Mb+HbYpDCq+GTo/2eyVkNkFeS0Jz6O+Uhfa8ejtYt6HF2F+mdRa27g79hFax29VeykG71GfZMfDvDYrPWwZALN+R9r68w8L0wSOFF0UYNOcVStM3F/WmppQfPfhZMT+a4lwgUe4TQlV6s4Vw9d182+YjUVqfHtk3nts/Z4UZ3K/8grCSjnulsP/P1+c13+Es8yOQ7YJDCQEZvAMze0mgnj93T4G71eh+QiO7tzfQoH2Wv0Vx7bNVUtOYz30II15rbfTmEYUp/BwxSeHaIQNvdl8f0R7EZ3u+WA9ohMfeSwUea9B3Boxbd1fhM26hvjyB2COvbEcLAt8EghQEAsTDLC6d0xiYttSMl1fOOzZQyrZwFclEU0JqZps3zZuO1j/kFR2ofrkUJW9lR3dc6ECXpZ6qknQ2C6GHrWOr5zxzTis1rhfS9xkpszs/zaWZCvG68jKYPUnyf6xlWA98f45t9MeSIoYkWruH68Jz1Iv7Rttj34vBYTro+We4aCe3Npe49t0UcDXSdDHrPad+7JZWtHkxb5FM6x3akKtMO5RCGUvRtMSKFV4IOC2uIAdAGbZR3jkfNZp1p/CjcEyEcIQH7uitz11Ty3oK+Qb3fvqNnLAMlCtDPeSQq6L2nRgltqw2NEvS5bZTQvm5u9AfqkE3pmDoykZ4PgxQG7v6HvZ7QVkZUxmwXyvUKW7+/l55ZXvexaatbpvhe0Ve7SLe/f4RQqhoC8zr2GO8lg97vqmzU/swSgn3t3MxPisT0UTyggevAb8YghVeFABDKjVR1kYhRQpkj4EHVTIEWSgTOFK4pbGqq+gpeXDeX/lZC+GgxW9t8zr7utcVwjxCOZCG15GDrJfbep32v3nv6jgSUp8IZksi/qwV8W11am8gimKaAFiIACQ3Z6AkwSOFVYCWjtkahmgvAAPmqB1IPdgFzVIjhWtTR26XfQgh3ZyqZ37MLYPd4bmjpvUUIvayiViLaIodr79N7P/ucYBbyVjaKP6/NZXutBrM1mq99p3eO6hj4ohhG8yug9RLsj2wL7Y1//O3isyXJADFyaOsXerhm4N6Sbro3oIcprAzv9v4jxoJuEYLe34smrkYmNxBCrxdTfk4jG9XPH97AQMSIFF4UJKWWSBAlhjyBLC0cM/kcOfTAFAfRbC2qRwraer97NEI4Ghls/XwvYjgkI5neSe1jPa/ERgbXogb7mOIambSEYKOE4h+YqMAMBNqLElbSkbnuZq6NyOFbY5DCK8L8o91LR/VCcAc3kKwvTOuIg7U52w15//diiwxsUz9dGK8Rw63oEYK9b8nhmqTU4ighZOmo872Wxfx2aay8z/brt6ChK31LDFJ4drT/MCtvoez4NFMlCMMTY0YdHXjhw50v1XwOnf5HShBxslfTo+cDEcIRMrCPbRFD+966MOqxlpGcdZTQEkL7mnaoj4OsIoOAfnPAPTJYpZGaIjX93a0itb0oof48Q2F+NYxv/EVAHYN5D9cWA1vFrM9sf+OjA1g+QggOYbflt/1Zrzr7I+gXf/UX8z2vYZVVdIUQ2t/tZRvp7+7NkW4NZlu/0oMIVeNdB743RqTwgqBKPorXofIU6gykLdQZSIAXO25Tqp3xNdv40EyFGwhh73d7i6GNGI7KSHXLiEa+WZnzpn14J2po5SSLo2TQq0mIz9kpUtvwEjY/s/QrngFE9XArqWFISd8GI1J4VgQBQlxosrar/2iFQIGAAIRA8IGxCGMRh0uYcBGHi7i0OyWcxa3SGi3UdyjX/cX7ll34kclqRwhhLzPpyPCgW+dH34utc3srIexp/b3vQM+hSn5Hq9NjBfyYrfCMGKTw7NA1TYqElKWkFPb7QFgC4xJcJoQgHK/Nbthq6opWOrJ/UDY19dE4GiH0UEU4GzLSo3FPM7ndLqlXCOGWamQlvh4B6qKvvgTQK1wbRWvPhCEfPTlIBBT0ErNLyaf2A57gPePiHf65nPDDLfh3/5alhJ/uHT5EA/REPspCwvBEVaUzA6URNgFB+llIe9gyWo/immTU+9nuAKCtVhjmcTtFDjsafXts95DP5pyFjX1dZZLrxDUgd6t15MHpNfPIUeE0vpNzmgE3BYkhRY8xsoy3JW8yULyF6rHBGN8JI1J4Zph/jBSQogRBmrgIBEBCJAaf/pFfxOFXmJuIYUpZLRot2Gpdvd4eyPMI89ZiXXx2GyE8Aluykh7bVtTyiGjklrbVveMox2iSBQ50jAXWUUKFnSLJge+DESk8O0SiA5yIoIoWFoIsjGVx+PMy482d8B/LGxZ25S/DAbMsQAB+0KX0LTJrg0PaXRDBi2YjSTapNTW1XXL2ahas+WpxZFG95j+s+y71U1TtzIcjckw22dNrXIsQHklcPS9Bj1tnKwMAwyNI+kxgxOoRAYNwAcApWoiLP8PLur4hRwuBSwFbulijmQSjVuEbYkQKTwrJ5nK8JpEkJaV/rCGZzZ4QPEdPwTu8B4eLpPvZeE6Rgs1jzxLKGkcL3uzrAPdNEzvqIzwCPXnrs6e/teh5CUdgU3SZotejj6kB7SCb0UL2FlKWmh6HWPkI6PbWGvheGJHCE0MyISA2KQ3NtUckhUC4eMa7n/DLR6dgppDaWAT8EAeWuPsNtNbOo3QU+2W7+NLRZyD51AXiqGy0Xdhm02b3C9pstHBPE71rUcKedHMtPXYv46htm2HPmaNELKKT8VzsFSWcUopr2BkLGiEEU6OwKRulv7+B74FBCs+OACCkOc2tfORjWqosjPMy4ZcLDSlEYvjJZ7AEnMVhFl93AEUkAKaYgRII8MlovqRFgjtttS3sTIGe4XxUZjlKCLfUJKwqsk0VthJBz3DW9w3CnyIb3VNp3C8GDDhjAiRgJg+IQ6CAS2pxfmlmYah0FBAveXKfMZbJ3F4hDHb46hik8OQgKyPZtNQcLRAkUK5XOHsHhuDiLljEYQkel0QGvZTUe/HRHkifIRvZaOH6c7fJpMpQ+uQ6h5Zs78niyp7DFa5avZdQbqq4WdE8pKRvh0EKz4wggAjIB5DXtFTKKansgbAQ5EK4XBx+seDXEiOFaTnBURy1+SvMYAjOMuGHXBC0h45mHoEww+FCHiySs5AcSsTgIPAUgI0pbO0EsluxVZS1hb2eR0d+nt/3htkLm0V0B4lj73iukWyvoLCQ4ALIFCNDEDiZ68F8V8Vkjn6CNZnFpKFSGzEMfDsMo/lZ0YTpORtE6xWsvyCEEDh6C6mIbQkuFbNxHsLT63/jyLaIVm/hGKxxfQR73sBn4sjr/27D+RZYQlBzWSMthxDbn5M+vv9Z9e8AWHfY3ZKNSrT6dc/RQMGIFJ4ZEmKkEPopqewJYYmpqWFhXNjhvEwgADN7nNyCOUx4DxNm9rkD56qqmSiSg3DKaiEgpaZ6aO+jx7VDuCYd9audt3sfHTWcVx5Ck7LKCGnkKB/3Qe4qZKsrmLeihJYM9DOVx0r7ExBwpgmMACcxQmxbXuRoAZqBFCVH6ZBBfuucojrChu+CESk8O4JJSc3kICVSEACeID5GC+fFYQmxUO3sJ1yCg0eMHoIWr5nq3VjNTCnjHfkxxZHF8SMD4m+Zx/y7cHSh/119lVpCsOmnjjQlNXSJo4VNSQ1GNrIpqS0hDHwvDFJ4dohkk7mKFqosJAALIywczebF4eJdbmWwKDGkJnk9RB26yEeOjg/ouQVVSuWBbKOj09m2+iG1P9eF/KNy0b2EcMuQG2CDEJQMojuEE/lc0bwVhVnZSO+XLhYEGu2znwZDPnpWZDKQaDJ7SZKRgDyl29Fo5iUZzsy4XKK5+GvxmJ3HRAHv04QpZSHFSylms+AkGDkQgllkWRvjSWohvfIlthfIPPv5jq6pR8aEHjWU946vlZA0PbUl0Pukov1pae2Qn9Lczpx/0x11piU/Tx87C+BS1hKTwBmpJwilIsboL51DrGU5+7RxWBzEU73Z0ItGDSnhYeB7YEQKr4KVt2Aa5KXUVK1u1vTUVbSgk726ZNDHrVJSfu4NCygnCaT6/bY47Mr9W4/vCGz30c+UijZbmqM+L9XxQHKksHV8xTuIUtESorSoHXWX9LeCdCkkgNIIT2RkIX0zjEjhmaE7tBAyCbAXsAdkAfgCsAPCBaAzAcTwFwYQC9kcx8uffo4Rg0x4DzMuojMXGAEewbafTt10GMhGs4WmprKkumezY1VJJi9eJkoo2TL1Drh97Ra1LBRv31NrccvvtAVuj4KVjtZjQGO1st8oltMI4US+EEFqhIcAgEoFukeJDt7DjPcw4U8/45/LCefg8M/LCb+WCb/OMy7nCbgw+EygC0ALwAvAS/w740WqqHXg62NECk8OCpJ3bhQkRQbpsRTis6cUKcTq5mCK2XzaGS7CyXSmmIF0o+Ry6y58SzZSHIkM9uSjI+9xKx5KAHZMp+131NHtM1lcrVUIFSHMtMAlTyGer/r4I32UNtn6N/DuHS6e4T1H6SjJR+wJnP6+NP05Rwxa5TaI4ctjRArPihBKSmpbwOZ1NwfIBQgu3gYR/IkRCLhMDu8uYHIOv/yMiWPLA40UjlY3O0opqRKL0y7Q3PiQslN4N0KAPr+zgB+RgHpDfvRYtGDulijgI5lSt+J6z6PSxjwIxXYi4DznAqiNZb09k4dDamuRcE59jxQqHb37KffE+nOZ8b5MeL9MOC8TlouDnB34En0pWurkBd2AkJeaGAa+NEak8OxQXTcN2kGqZObKfE7/oBcCLQQshOAdvGcs3ujIUvsKsQ9Oz/DdHwmp0J2r3gb6hNDDkcjgUVPfri3OXdP7wcVs1eQ2cBNJUH3d/LNmFA9BIwI9X6d0+5QIQmdJ++QjXFKEoMby2cdalmVhhAsDnsrfTksGQdL8jiEdfScMUnh2iAA+VMRQ/AVTyLak0H9Rw5kSKZQK5yXo4B2qahX8AWkoZyBhvYBfI4T14/umsbaGbp9TXud65tIj8HBiMF4CUBNFTzqyg3NUNuIsHXnMFEzjw7qaWbOOtKXFJThcQvx7WNIMDiycNxJ5c+Hrinn4QQrfDUM+emYEMf2PBPASDcBFIBx3eHwRiCPwGQAIdAKICXJmLJPDZQq4eIdfHCub39N8hZKWug1to11XDMdhO5w6iuJOQuinpB7LMIpdTIupehSHBu00qahbxPDRhoBWNqo8BW2D3RyTykcn+EIIqcXFSQIuqDOQfOpvdQ4O5zDFKGFJUcJlQrgw6Mygc5SOuDKZNaFBsnxEQSASRpfUb4ARKTwpqiE7JjXQVjVzTkct15xbapMZ1Ul5XGdIbS5UPtqCFrH1nrFlEt9LCFuRQfWcnWhmy5D+SP3CNRyNInrH0COnrWO172MjgugvSMpAWktvtt9VjBSilOg9I6QKeKQIU43m/HeUfCuo0QyMSOEbYUQKTwwRo+n6ZDYvBL4IQClt8EIACWRKi/gZECLIKWrG3sVZCzOHaDq6Ge9hjrrzDbtsR4IggpAN3pCHyAO3E0JPAupr+9K9bSOXR7UDz8fRKVzrQRfsa1GD9pwC2qwkyjv63eNJcpF6CUyCmQJ+kPan8rhQMfx9IoOLRgkhRgmXxeFycZAzxzTUd45pzeeU3nwpkQJppOBTdDCM5m+DESm8ALLhp1JS1RTPRAkLcrUz8lQ2hg9pHm8arJLNZuE0w2f/H3v7R7bV5voeyUgf70UGe9HBFtrXuZcwPqNYzZJHaFJTs/FvnqPZRmzOq73EvlX98xfJJn7vPnDuoiuBspeQPakcJRSpiEwa9Kho/l4YkcIzIwTA+3gdQkpLZdASQMzRW3CAMIEnARC9heg3UKxZWKKnsAQfM1CCQ0jFTb0drqNUBQuBI6qyk9Rs9qKzE2K0sFeYthchXIsM4vE0i52UCAFUL657LS+u7fx7EYcSw7XftcVuR2A9hKMRm1Y3z/kCnIjAAGaVkIwxrfKRV+koMPziopewEOgSi9X4THA2UsjZbAG0hCJfBoGIFFlz4MtiRArPChuqp3+UlMJ5TUdlL6X69BJNZ841DFErllSkdPEcJ7FJ3RjPm7fhzuJUDdxpbvcKpoD7CKGNDOKMgI7ERPdFEC26hLgVyXxiiwvFFjnkOoUcHZQoYQZhJk63S/ZRbGuRss4kRgrqJWBh0IVibYKpT9AK5txnK5TIIctHA98CgxSeHKKyUajTUnmRVGwkdX65FiEFGAkpykiamrjVA2kLvW6p183m2wihfr9jfsPRn7c7/Xsyh24hhr3IohclWELYNJxz8VqRjTh1tXVYn7M8VCkUUhCvdQlU5MalSW02dQpazUym3crA18eQj54ZhhDIB2AJABHoknoTLWWkJgjwgRBO0fvlM8Azwc8Ev6TU1OBwDi6lpbpU2VzqFAIEXiTfj7djNGEJxC5kuWdPqi7Oi1q7iNo16xoX9dZ3skNpKPX3ie91EZePRY/rIvGfxjmNpLREcGv9wRaJbC3+1h/Q2gQlYmsu2/MYZ10IQAFnicNyPMXPOSNFEkm6mzukqcOTzqmv1buf4nftHd4XB79Eg5lULjoT3Hv8O3HvAncG3EVitLkIaAlgKyEpIQyz+ctjkMKzQ0cg2tTUIBAvxVvwQPAEZkk7P8qGM4U4gzeo2WyGrGgBW2+JtAVtIV+Xnvw1SXD1zF1yANaL/hWSYEhaXOMTlQzsohrrLiiZ54xz8kx8V5Zxu5FFGxXsLf493EMIuRFeno5WGuZ5MDxR1f6iezy5ijk2O1yCKyZzSlPOfxdNW4tSIZ/+rkx0OorXvhcGKTwrtFBIJJnNDljiMkRTanZ90clZDEdRB3Yz5UiB3gC6EMKFsbjY6uCXn1P/I5e8BYKXgCWVsQUEXCT2Tb2gRAkX4diPPy1qdhHWRfSSFttL+ghxkYs7dWtG68/Lc8r99ue9bCKNDPQYLjJlEjinKt6zmRtRm9Eqa9XtOUq7DslzI+r37dUbrEmhXcyvEYFmgwFACISZPN7DDDDAIcBx9BQuMsVzY/yF+D0RfgnwLg6/ZMY/wxv+6U+519Gvy4Tz2UHeHeid4d4J7s8YLUy/ohcVI4UUJZxD8qhSlLB4wIcoYw5i+BYYpPDsSFkfOV/cUzT/KIAcg1kAFsglZR9l0zAN30lRRDAdUy9qNqcumlrV3EpHgHY6qAve9LbuyoPYHHmbtVN25AFxJ6zvpYuuz6RR3g8o3kRbjxCEcYZZ+OEKKRgy0M+nrR7ya0rtf7gUicUCsJDbiG9GAQ059KKIHhnEr7JPCHn+tXCMinQOAnE+z54IZzj8kCWdf0EgAKnC/Aw2LdEdzkk+igazAzzVHkI2mGGSFVJtwqJ/a8ZLCEZCGvjSGKTwxIjFayktdZpAPkCIgCUuI8Rp/5o2cBQI7o0QJkptC2LaIRZCWGIG0sX0QNIdd1z4JS6JIlCP+qJRQl7kKC/IbaTgc55S0yra7rjFraIKxQWNeS2u2q1r0ZwH41eYEcD4JTO8xGvNqPolsTDvl0y4JO9EF13Oef9S9RGK5CCZJJQgWlRN7VZ1ButW2VuRAYCaFESnyMXzcUlkOosvEYLE9thn4pyBdBaBA3BOJP8rzPgVZvzpZ/zyU0xBvqQ0VM02OhP4PUYH03uKFM4CPicv4VK8BPIetPjSsRco1wNfFoMUnhQSBESmcMj7mE4IAJOP3kLqZsoa1geCOzPChJRyGHeFSG0NFh81Zo0UoinJ8BJlI48YKfhMDJQHvZ/NrvssLhu40axupZZy3zUdVy1hXFCbvq7ZndtduUpKkaRiNPArzDiLwy85ZZJ7D5Eo3mVKQ2am9HuMmXxe8GNVsF+RxEy+EIQ5tt6iD3NM7c9sG5FeVKBkYOWtGR4XJV3EzzPLggtcMpEd5kQYUWbzsU26iRLew4RziO2yz8uE4B3kwokQkEnAJWLgBXDvochGSwBdfJGOQoCEUCSkgS+PQQpPDsnGcgBNKYRfPDAB5Es7u9jumlP2CKVcc2M2+9IHR0dzllbNBTmTVbSrp5WN1JjmysS1MhGQpojlIqok3Rh5CTASE4p8dPW5Sa5SuchKReqT/ErXmmF1DlPW/hdyeeFnElzIZWKY4cHCAMeohFF3NI3Hs1789352jQzic4t5f4GLxJBmI/j0WR1JvtbvICcISHwNey4uyWBePCOkrrmcuqFq87ssG11Kk0X1EchL/BvL2W+DDL4TBik8M1Q6IgKYgGUBxMUIwUedlyaBBI6RhWeEE0f5KKUehlOsXpUptks+e5uWOqGkc0bjUqOEeCEU/0GzWsqCbNsy6E5ed9cXKXJSlIVc9dHscHlHoTafq0gj5NdSUtAI4Z/hDReZ8M9wymTwp9frExZhvPspL8hTigbe2Ofq4IljT6E3XmL0IIUoVF7q1RCsax/q3kaVgZwztgwRN1FCEMbEPp87DoJ3SBypKiEO0UFIkUI8rjNigsEvmXCBwz/DCX/6E375Cb+WCeclDtGhFCW4M+B+RYN5+iWY/gzgS4wScgrqeYlRgvegyxL/5oJPyQ4CGQTx5TFI4QVQRQsAwGlBCgFY6oxO0l1fNTAFcUeZ0lOX4KpuqVEiMjv95CX00k5zpGDSLi08XKc1Ba80+gBjJl+JNGzjOV+ZyVNcELN0pDOoGe/JO/nlp/w6J7eASWcvMwLF7J2JPFj6ldL2qO2C3z5mH7+VDALKz3JkQfr96MAcjsazMDxpxEZmJvMErxliYcKSKtkRtB9WGaKTjeVzAPtYA8NLrIOJhJDqYnxphDeko++DQQrPCgmQwHHHBsRoAYBI8hWCi03ymCHegxYHWgLcyUGm6C1EmUD73MQ22uclRgrFaNYMpJKGqhlH6iWc4XKUUEUK4NWOGYgGtcIayxYMk65KbRpqiQ5slKFE9EtOeA9zjhD+GU5ZS//Tz2n8ZNHW4+8SZj9h4oATO0wcMKVIYaaAxTlM5BGYEIgQmMAiVcfUHhnYhV/RTlJrSUBfyzePgTViSIZ3EFxSd9SzOLAEzOTgJPodl+SN6HfyLukzL3F+wrI40IWjuXwG3LtGCQHuzwD351LI4OJBIQDnSySEFCXIspT+W8Nk/hYYpPAKCCEu/Bx74AullhdATE0NnHdzfEmSgLZAXrRHfuyQqRr2kuSfnB2Dkoaqu9BcaSvWP0i71kQItUzUq7StSSOnokJ37CFL1sVLKNGG/n6smuZMZq1/oATwp5+xBMYvP0ejeZnKguxiTUYQwiQBJ15iQR7FxdUTlc8Q4uexMhCwJgGbhbT1sz0isL9/CQ4ze2jb69n5ZDpPCLikaOCSitlSqqugRE4hVjIvom0tKKUwlzRUXgA+C9w5gLOhHKJUFELMNvIhEoI3BnOe7zGI4atjkMKzI0gccCYCuSwglxZhpqjvMoE8Ay6lEJ5P4LMDX6QYiwsQFuQRnXE0o0lJFapbWlhpKZuaJcPFg3GWKVXPTkYGuv5xYipqWViiqVoXlAHoZDRpsRrjPaVe6iS5KkJYZpyDw5/LnGcSS55lQHEuxETwISA4wkkWBE7ZP+zjz4li8RhkZQqXr2WPHOrIwgutSKCOOjT7KLYiubBLEYDLprO2voiGc4wkLnDwFNJ3E8lxEU5RAiMsDKcT1TTr6Cwx2+jdg/+85MSFXAeTyEF8KF6C1yykISF9BwxSeFaIAAgQD5AQBAARxV2b9wAzyHmAGMIUeyJNE+jXBTw7uPMMdyEsZgavdkz1gXO3VK03ANRcLu0sSgFYlCe0SlcXq1zIJm7ng6xxQV2wphFCedzKR1I9pqmo7zJlD+FPn3Lzl1jFew4Of15mXHwcMKSYA8GxQBAlq0UYCzNOLlVzC8XiMSUJ8liMLLQXAQDYjQKOPAcciWEJLslDDheKslEQwgVTrFdItQueLvCpkvks8Vz88jPO3sWCtYXBC8GdjdF8FrhfHvznAvrzPRWpJUIIAbL4GA0sS9yQKCH4ESF8FwxSeBV4DyEu9QkiMX+cOd7nSBh0WVJaoelpEygPYhdB7K0vtSySq5pNdACYKlxNhZQiIWlGksW1bqYWaja3Vc2Vcy5qMjuTEktZurqkDCPNqjoHh4t3sVV4Gj8pZuH1qf4jcMhjQM8emMgDHPsqsUiSbZKEdCUKqB7fiQRCR4ayz9P3fFOD2ZjMMSKT/FhslldSX7VITzujSgDgKRnNeolVy3TxoIvPUUGuRQgSo4OU1KDzPKJ8NDyF74JBCs8MjRZC/MdPHJKnwFnjJSJIykaiSVIqYdSK2TszdxeIc5tjjk3I+fKFAHJtgpjMlyq/PnkJujjLepTk0WWjl3lkSaJtjwGg8hMu4rCkOoRF4qwIH5J0ovOIA2NZ0vEJgUggLFgSUWT/wAHnMAFYsFD0M1g4NaALNxPBcRJoi/VirYl+BzYbqch8FAnBnHv9LmK1epy0JyH6Dfr9x1qEmJ1Gl+QhXC5x8ZeSZZRJQCOEdgznyEL68hjzFF4BvR2a/YeaetLYf8CV53vg3/HeYn5kXvGtuDaXeK9QLD5mTduygOr9NAogQjRzi1LDzzo7aP997iOE9lj3HmuPvz2WgPXvA/3+TDkqkkQK5rvX2zr3O6eZ5lGvG38FI0L4VhikMDAwMDCQMUhhYGBgYCBjkMLAwMDAQMYghYGBgYGBjEEKAwMDAwMZ/z9KSLMa8blekQAAAABJRU5ErkJggg==\" id=\"image2e0bc0e93d\" transform=\"scale(1 -1) translate(0 -280.08)\" x=\"37.4225\" y=\"-11.750049\" width=\"280.08\" height=\"280.08\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 38.047357 291.830049 \nL 38.047357 11.894049 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(33.593607 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 100.533071 291.830049 \nL 100.533071 11.894049 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <g transform=\"translate(91.625571 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 163.018786 291.830049 \nL 163.018786 11.894049 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <g transform=\"translate(149.657536 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 225.5045 291.830049 \nL 225.5045 11.894049 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(212.14325 305.967862) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 287.990214 291.830049 \nL 287.990214 11.894049 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <g transform=\"translate(274.628964 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path d=\"M 37.4225 12.518906 \nL 317.3585 12.518906 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(25.015 17.837812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path d=\"M 37.4225 43.761763 \nL 317.3585 43.761763 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 25 -->\n      <g transform=\"translate(16.1075 49.08067) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path d=\"M 37.4225 75.004621 \nL 317.3585 75.004621 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_8\">\n      <!-- 50 -->\n      <g transform=\"translate(16.1075 80.323527) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path d=\"M 37.4225 106.247478 \nL 317.3585 106.247478 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_9\">\n      <!-- 75 -->\n      <g transform=\"translate(16.1075 111.566384) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path d=\"M 37.4225 137.490335 \nL 317.3585 137.490335 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_10\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 142.809241) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path d=\"M 37.4225 168.733192 \nL 317.3585 168.733192 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_11\">\n      <!-- 125 -->\n      <g transform=\"translate(7.2 174.052098) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_23\">\n      <path d=\"M 37.4225 199.976049 \nL 317.3585 199.976049 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_12\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 205.294955) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_25\">\n      <path d=\"M 37.4225 231.218906 \nL 317.3585 231.218906 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_13\">\n      <!-- 175 -->\n      <g transform=\"translate(7.2 236.537813) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_27\">\n      <path d=\"M 37.4225 262.461763 \nL 317.3585 262.461763 \n\" clip-path=\"url(#p60439d5c80)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_14\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 267.78067) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 37.4225 291.830049 \nL 37.4225 11.894049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 317.3585 291.830049 \nL 317.3585 11.894049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 37.4225 291.830049 \nL 317.3585 291.830049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 37.4225 11.894049 \nL 317.3585 11.894049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p60439d5c80\">\n   <rect x=\"37.4225\" y=\"11.894049\" width=\"279.936\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in data.train_dl:\n",
    "    print (x.shape, y.shape)\n",
    "    plt.imshow(x[0].view(224, 224))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0009, -0.0048,  0.0029,  0.0004,  0.0136, -0.0032,  0.0059,  0.0002,\n",
      "         -0.0081,  0.0050]], grad_fn=<AddmmBackward0>)\n",
      "tensor(2.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 1, 224, 224))\n",
    "y = torch.tensor([2])\n",
    "\n",
    "logits = model(x)\n",
    "print (logits)\n",
    "print (model.loss_fn(logits, y))\n",
    "print (model.accuracy(logits, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 224]) Initial x\n",
      "torch.Size([1, 96, 54, 54])  after  Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
      "torch.Size([1, 96, 54, 54])  after  ReLU()\n",
      "torch.Size([1, 96, 26, 26])  after  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 256, 26, 26])  after  Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "torch.Size([1, 256, 26, 26])  after  ReLU()\n",
      "torch.Size([1, 256, 12, 12])  after  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 384, 12, 12])  after  Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 384, 12, 12])  after  ReLU()\n",
      "torch.Size([1, 384, 12, 12])  after  Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 384, 12, 12])  after  ReLU()\n",
      "torch.Size([1, 256, 12, 12])  after  Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([1, 256, 12, 12])  after  ReLU()\n",
      "torch.Size([1, 256, 5, 5])  after  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([1, 6400])  after  Flatten(start_dim=1, end_dim=-1)\n",
      "torch.Size([1, 4096])  after  Linear(in_features=6400, out_features=4096, bias=True)\n",
      "torch.Size([1, 4096])  after  ReLU()\n",
      "torch.Size([1, 4096])  after  Dropout(p=0.5, inplace=False)\n",
      "torch.Size([1, 4096])  after  Linear(in_features=4096, out_features=4096, bias=True)\n",
      "torch.Size([1, 4096])  after  ReLU()\n",
      "torch.Size([1, 4096])  after  Dropout(p=0.5, inplace=False)\n",
      "torch.Size([1, 10])  after  Linear(in_features=4096, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Test Network\n",
    "print (x.shape, 'Initial x')\n",
    "\n",
    "y = x\n",
    "for layer in model.model:\n",
    "    y = layer(y)\n",
    "    print (y.shape, ' after ', layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Training loss: 2.3018\n",
      "Training loss: 2.2985\n",
      "Training loss: 2.3003\n",
      "Training loss: 2.2868\n",
      "Training loss: 2.3019\n",
      "Training loss: 2.2864\n",
      "Training loss: 2.2969\n",
      "Training loss: 2.2747\n",
      "Training loss: 2.2213\n",
      "Training loss: 2.2634\n",
      "Training loss: 2.1930\n",
      "Training loss: 2.2241\n",
      "Training loss: 2.0065\n",
      "Training loss: 1.9488\n",
      "Training loss: 1.8484\n",
      "Training loss: 1.6857\n",
      "Training loss: 1.6510\n",
      "Training loss: 1.5487\n",
      "Training loss: 1.7703\n",
      "Training loss: 1.3424\n",
      "Training loss: 1.6957\n",
      "Training loss: 1.4832\n",
      "Training loss: 1.3920\n",
      "Training loss: 1.4185\n",
      "Training loss: 1.3286\n",
      "Training loss: 1.4912\n",
      "Training loss: 1.3640\n",
      "Training loss: 1.3032\n",
      "Training loss: 1.3029\n",
      "Training loss: 1.3564\n",
      "Training loss: 1.2033\n",
      "Training loss: 1.2835\n",
      "Training loss: 1.1832\n",
      "Training loss: 1.4503\n",
      "Training loss: 1.1713\n",
      "Training loss: 1.2443\n",
      "Training loss: 1.3145\n",
      "Training loss: 1.3460\n",
      "Training loss: 1.1550\n",
      "Training loss: 1.1437\n",
      "Training loss: 1.2551\n",
      "Training loss: 1.1124\n",
      "Training loss: 1.1709\n",
      "Training loss: 1.1752\n",
      "Training loss: 1.1769\n",
      "Training loss: 1.3412\n",
      "Training loss: 1.0443\n",
      "Training loss: 1.2053\n",
      "Training loss: 1.4402\n",
      "Training loss: 1.1469\n",
      "Training loss: 1.2158\n",
      "Training loss: 0.9658\n",
      "Training loss: 1.0950\n",
      "Training loss: 1.0436\n",
      "Training loss: 1.1038\n",
      "Training loss: 0.8973\n",
      "Training loss: 0.9626\n",
      "Training loss: 1.1403\n",
      "Training loss: 0.8861\n",
      "Training loss: 1.1182\n",
      "Training loss: 0.9690\n",
      "Training loss: 0.9662\n",
      "Training loss: 0.6198\n",
      "Training loss: 0.9834\n",
      "Training loss: 1.0100\n",
      "Training loss: 0.8568\n",
      "Training loss: 0.8169\n",
      "Training loss: 0.9126\n",
      "Training loss: 1.0385\n",
      "Training loss: 0.9906\n",
      "Training loss: 0.7860\n",
      "Training loss: 0.9442\n",
      "Training loss: 1.1377\n",
      "Training loss: 1.0307\n",
      "Training loss: 1.1032\n",
      "Training loss: 1.0343\n",
      "Training loss: 0.7955\n",
      "Training loss: 0.7658\n",
      "Training loss: 1.0397\n",
      "Training loss: 1.0677\n",
      "Training loss: 0.8133\n",
      "Training loss: 0.9876\n",
      "Training loss: 0.8088\n",
      "Training loss: 0.9272\n",
      "Training loss: 0.8574\n",
      "Training loss: 0.9736\n",
      "Training loss: 1.0266\n",
      "Training loss: 0.6695\n",
      "Training loss: 0.7360\n",
      "Training loss: 0.9570\n",
      "Training loss: 1.0591\n",
      "Training loss: 0.9175\n",
      "Training loss: 0.7498\n",
      "Training loss: 0.7915\n",
      "Training loss: 0.9288\n",
      "Training loss: 1.0185\n",
      "Training loss: 0.9307\n",
      "Training loss: 0.7350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtrain_dl:\n\u001b[1;32m      6\u001b[0m     x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m----> 7\u001b[0m     x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     10\u001b[0m     train_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss_fn(logits, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = AlexNet().to(device)\n",
    "#model = AlexNet()\n",
    "for batch in data.train_dl:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    logits = model(x)\n",
    "    \n",
    "    train_loss = model.loss_fn(logits, y)\n",
    "\n",
    "    print (f'Training loss: {train_loss.item():.4f}')\n",
    "\n",
    "    model.optimizer.zero_grad(set_to_none=True)\n",
    "    train_loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "batch_size = 1024\n",
    "\n",
    "\n",
    "class Classifier3(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(10))\n",
    "\n",
    "        self.batch_size = 1024\n",
    "        self.learning_rate = 0.0004\n",
    "        #self.train_acc = torchmetrics.Accuracy(\n",
    "        #    task='multiclass', num_classes=10)\n",
    "        self.model(next(iter(data.train_dl))[0])\n",
    "        self.apply(self.init_cnn)\n",
    "\n",
    "    def init_cnn(self, module):  # @save\n",
    "        \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "        if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "            # nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.kaiming_uniform_(module.weight, a=2.0**0.5)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        logits = self.model(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        #self.train_acc(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=False,\n",
    "                 on_step=False, on_epoch=True)\n",
    "        #self.log('train_acc', self.train_acc, prog_bar=True,\n",
    "        #         on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        logits = self.model(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        # self.log('train_loss', loss)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True,\n",
    "                 on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # x, y = batch\n",
    "        x = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #    optimizer, patience=10)\n",
    "        #lr_scheduler = {\"scheduler\": scheduler,\n",
    "        #                \"interval\": \"epoch\", \"monitor\": \"val_loss\"}\n",
    "        return optimizer #[optimizer], [lr_scheduler]\n",
    "\n",
    "    def init_cnn(self,module):  # @save\n",
    "        \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "        if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "            nn.init.kaiming_uniform_(module.weight, a=2.0**0.5)\n",
    "\n",
    "\n",
    "model = Classifier3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817a133bc0d5437d83c1dca0d6cce02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 82 steps due to diverging loss.\n",
      "Restoring states from the checkpoint path at /Users/jsmidt/Documents/AI/scratch/d2l/.lr_find_be047c4d-b012-47b0-af88-eb8ade72a200.ckpt\n",
      "Restored all states from the checkpoint file at /Users/jsmidt/Documents/AI/scratch/d2l/.lr_find_be047c4d-b012-47b0-af88-eb8ade72a200.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004365158322401656\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"447.96275pt\" height=\"331.644625pt\" viewBox=\"0 0 447.96275 331.644625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-25T05:38:54.847984</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 331.644625 \nL 447.96275 331.644625 \nL 447.96275 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.86675 287.136 \nL 440.76275 287.136 \nL 440.76275 7.2 \nL 39.86675 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 58.089295 287.136 \nL 58.089295 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- $\\mathdefault{10^{-8}}$ -->\n      <g transform=\"translate(41.639295 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-38\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 113.645836 287.136 \nL 113.645836 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- $\\mathdefault{10^{-7}}$ -->\n      <g transform=\"translate(97.195836 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-37\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 169.202377 287.136 \nL 169.202377 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- $\\mathdefault{10^{-6}}$ -->\n      <g transform=\"translate(152.752377 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 224.758919 287.136 \nL 224.758919 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- $\\mathdefault{10^{-5}}$ -->\n      <g transform=\"translate(208.308919 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 280.31546 287.136 \nL 280.31546 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- $\\mathdefault{10^{-4}}$ -->\n      <g transform=\"translate(263.86546 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 335.872001 287.136 \nL 335.872001 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- $\\mathdefault{10^{-3}}$ -->\n      <g transform=\"translate(319.422001 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 391.428542 287.136 \nL 391.428542 7.2 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- $\\mathdefault{10^{-2}}$ -->\n      <g transform=\"translate(374.978542 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\"/>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_16\"/>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_17\"/>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_18\"/>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_19\"/>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_20\"/>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_21\"/>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_22\"/>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_23\"/>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_24\"/>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_25\"/>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_26\"/>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_27\"/>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_28\"/>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_29\"/>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_30\"/>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_31\"/>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_32\"/>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_33\"/>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_34\"/>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_35\"/>\n    </g>\n    <g id=\"xtick_29\">\n     <g id=\"line2d_36\"/>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_37\"/>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_38\"/>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_39\"/>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_40\"/>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_41\"/>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_42\"/>\n    </g>\n    <g id=\"xtick_36\">\n     <g id=\"line2d_43\"/>\n    </g>\n    <g id=\"xtick_37\">\n     <g id=\"line2d_44\"/>\n    </g>\n    <g id=\"xtick_38\">\n     <g id=\"line2d_45\"/>\n    </g>\n    <g id=\"xtick_39\">\n     <g id=\"line2d_46\"/>\n    </g>\n    <g id=\"xtick_40\">\n     <g id=\"line2d_47\"/>\n    </g>\n    <g id=\"xtick_41\">\n     <g id=\"line2d_48\"/>\n    </g>\n    <g id=\"xtick_42\">\n     <g id=\"line2d_49\"/>\n    </g>\n    <g id=\"xtick_43\">\n     <g id=\"line2d_50\"/>\n    </g>\n    <g id=\"xtick_44\">\n     <g id=\"line2d_51\"/>\n    </g>\n    <g id=\"xtick_45\">\n     <g id=\"line2d_52\"/>\n    </g>\n    <g id=\"xtick_46\">\n     <g id=\"line2d_53\"/>\n    </g>\n    <g id=\"xtick_47\">\n     <g id=\"line2d_54\"/>\n    </g>\n    <g id=\"xtick_48\">\n     <g id=\"line2d_55\"/>\n    </g>\n    <g id=\"xtick_49\">\n     <g id=\"line2d_56\"/>\n    </g>\n    <g id=\"xtick_50\">\n     <g id=\"line2d_57\"/>\n    </g>\n    <g id=\"xtick_51\">\n     <g id=\"line2d_58\"/>\n    </g>\n    <g id=\"xtick_52\">\n     <g id=\"line2d_59\"/>\n    </g>\n    <g id=\"xtick_53\">\n     <g id=\"line2d_60\"/>\n    </g>\n    <g id=\"xtick_54\">\n     <g id=\"line2d_61\"/>\n    </g>\n    <g id=\"xtick_55\">\n     <g id=\"line2d_62\"/>\n    </g>\n    <g id=\"xtick_56\">\n     <g id=\"line2d_63\"/>\n    </g>\n    <g id=\"xtick_57\">\n     <g id=\"line2d_64\"/>\n    </g>\n    <g id=\"xtick_58\">\n     <g id=\"line2d_65\"/>\n    </g>\n    <g id=\"xtick_59\">\n     <g id=\"line2d_66\"/>\n    </g>\n    <g id=\"xtick_60\">\n     <g id=\"line2d_67\"/>\n    </g>\n    <g id=\"xtick_61\">\n     <g id=\"line2d_68\"/>\n    </g>\n    <g id=\"xtick_62\">\n     <g id=\"line2d_69\"/>\n    </g>\n    <g id=\"xtick_63\">\n     <g id=\"line2d_70\"/>\n    </g>\n    <g id=\"xtick_64\">\n     <g id=\"line2d_71\"/>\n    </g>\n    <g id=\"xtick_65\">\n     <g id=\"line2d_72\"/>\n    </g>\n    <g id=\"xtick_66\">\n     <g id=\"line2d_73\"/>\n    </g>\n    <g id=\"text_8\">\n     <!-- Learning rate -->\n     <g transform=\"translate(184.1135 320.95075) scale(0.168 -0.168)\">\n      <defs>\n       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4c\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"53.962891\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"115.486328\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"176.765625\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"216.128906\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"279.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"307.291016\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"370.669922\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"434.146484\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"465.933594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"507.046875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"568.326172\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"607.535156\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_74\">\n      <path d=\"M 39.86675 283.091186 \nL 440.76275 283.091186 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_75\"/>\n     <g id=\"text_9\">\n      <!-- 1 -->\n      <g transform=\"translate(27.45925 288.410092) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_76\">\n      <path d=\"M 39.86675 229.692929 \nL 440.76275 229.692929 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_77\"/>\n     <g id=\"text_10\">\n      <!-- 2 -->\n      <g transform=\"translate(27.45925 235.011835) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_78\">\n      <path d=\"M 39.86675 176.294672 \nL 440.76275 176.294672 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_79\"/>\n     <g id=\"text_11\">\n      <!-- 3 -->\n      <g transform=\"translate(27.45925 181.613578) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_80\">\n      <path d=\"M 39.86675 122.896416 \nL 440.76275 122.896416 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_81\"/>\n     <g id=\"text_12\">\n      <!-- 4 -->\n      <g transform=\"translate(27.45925 128.215322) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_82\">\n      <path d=\"M 39.86675 69.498159 \nL 440.76275 69.498159 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_83\"/>\n     <g id=\"text_13\">\n      <!-- 5 -->\n      <g transform=\"translate(27.45925 74.817065) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_84\">\n      <path d=\"M 39.86675 16.099902 \nL 440.76275 16.099902 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_85\"/>\n     <g id=\"text_14\">\n      <!-- 6 -->\n      <g transform=\"translate(27.45925 21.418808) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- Loss -->\n     <g transform=\"translate(19.965375 165.592875) rotate(-90) scale(0.168 -0.168)\">\n      <defs>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 58.089295 274.411636 \nL 66.978342 253.696854 \nL 71.422865 243.364679 \nL 75.867389 237.153153 \nL 80.311912 233.018248 \nL 84.756435 230.078093 \nL 89.200958 227.872406 \nL 93.645482 226.158391 \nL 98.090005 224.776405 \nL 102.534528 223.642445 \nL 106.979052 222.706054 \nL 111.423575 221.922277 \nL 115.868098 221.251808 \nL 120.312621 220.671547 \nL 124.757145 220.158396 \nL 129.201668 219.709197 \nL 133.646191 219.3057 \nL 138.090715 218.949375 \nL 142.535238 218.630949 \nL 146.979761 218.339945 \nL 151.424284 218.078034 \nL 155.868808 217.839206 \nL 160.313331 217.621141 \nL 164.757854 217.42183 \nL 169.202377 217.238846 \nL 173.646901 217.073659 \nL 178.091424 216.919716 \nL 182.535947 216.78131 \nL 186.980471 216.657175 \nL 191.424994 216.533918 \nL 195.869517 216.424946 \nL 200.31404 216.328963 \nL 204.758564 216.240145 \nL 209.203087 216.161778 \nL 213.64761 216.094272 \nL 218.092134 216.036141 \nL 222.536657 215.991276 \nL 226.98118 215.954793 \nL 231.425703 215.935214 \nL 235.870227 215.930633 \nL 240.31475 215.950735 \nL 244.759273 216.002107 \nL 249.203797 216.090416 \nL 253.64832 216.229684 \nL 258.092843 216.469499 \nL 262.537366 216.859076 \nL 266.98189 217.446719 \nL 271.426413 218.395317 \nL 275.870936 219.657409 \nL 280.31546 221.088638 \nL 284.759983 222.080019 \nL 289.204506 222.628807 \nL 293.649029 223.328246 \nL 298.093553 224.205502 \nL 302.538076 225.104356 \nL 306.982599 225.946391 \nL 311.427123 226.99647 \nL 315.871646 228.387238 \nL 320.316169 229.945437 \nL 324.760692 229.671658 \nL 329.205216 229.106671 \nL 333.649739 229.878122 \nL 338.094262 230.116009 \nL 342.538785 230.439116 \nL 346.983309 231.126917 \nL 351.427832 231.263466 \nL 355.872355 227.037308 \nL 360.316879 226.982744 \nL 364.761402 226.956954 \nL 369.205925 227.112946 \nL 373.650448 227.042308 \nL 378.094972 226.315554 \nL 382.539495 226.022543 \nL 386.984018 225.743053 \nL 391.428542 225.353114 \nL 395.873065 225.020094 \nL 400.317588 224.725379 \nL 404.762111 224.425723 \nL 409.206635 124.558448 \nL 413.651158 126.716352 \nL 418.095681 109.606937 \nL 422.540205 19.924364 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #008fd5; stroke-width: 4\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 315.871646 228.387238 \n\" clip-path=\"url(#p8bf59b0434)\" style=\"fill: none; stroke: #ff0000; stroke-width: 4\"/>\n    <defs>\n     <path id=\"m5490885f06\" d=\"M 0 5 \nC 1.326016 5 2.597899 4.473168 3.535534 3.535534 \nC 4.473168 2.597899 5 1.326016 5 0 \nC 5 -1.326016 4.473168 -2.597899 3.535534 -3.535534 \nC 2.597899 -4.473168 1.326016 -5 0 -5 \nC -1.326016 -5 -2.597899 -4.473168 -3.535534 -3.535534 \nC -4.473168 -2.597899 -5 -1.326016 -5 0 \nC -5 1.326016 -4.473168 2.597899 -3.535534 3.535534 \nC -2.597899 4.473168 -1.326016 5 0 5 \nz\n\" style=\"stroke: #ff0000\"/>\n    </defs>\n    <g clip-path=\"url(#p8bf59b0434)\">\n     <use xlink:href=\"#m5490885f06\" x=\"315.871646\" y=\"228.387238\" style=\"fill: #ff0000; stroke: #ff0000\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 39.86675 287.136 \nL 39.86675 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 440.76275 287.136 \nL 440.76275 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 39.86675 287.136 \nL 440.76275 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 39.86675 7.2 \nL 440.76275 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8bf59b0434\">\n   <rect x=\"39.86675\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run learning rate finder, results override hparams.learning_rate\n",
    "trainer = pl.Trainer(auto_lr_find=True)\n",
    "\n",
    "# call tune to find the lr\n",
    "#lr_finder = trainer.tune(makemore, train_dataloaders=data)\n",
    "lr_finder = trainer.tuner.lr_find(model, train_dataloaders=data.train_dl)\n",
    "\n",
    "# Results can be found in\n",
    "#print(lr_finder.results)\n",
    "print (lr_finder.suggestion())\n",
    "\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 46.8 M\n",
      "-------------------------------------\n",
      "46.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "46.8 M    Total params\n",
      "187.059   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0ceec4b78040d6a52e212d44de4c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73c5fd06d3b40859b9b4bd8322306a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"mps\", callbacks=[TQDMProgressBar()])\n",
    "trainer.fit(model=model, train_dataloaders=data.train_dl, val_dataloaders=data.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(MyModule):\n",
    "    def __init__(self, arch, lr=0.0001, num_classes=10):\n",
    "        super().__init__()\n",
    "        conv_blks = []\n",
    "        for (num_convs, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
    "        self.model = nn.Sequential(\n",
    "            *conv_blks, nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.model.apply(self.init_cnn)\n",
    "        self.configure_optimizers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 224, 224]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"324.5585pt\" height=\"316.079424pt\" viewBox=\"0 0 324.5585 316.079424\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-25T16:49:49.374241</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 316.079424 \nL 324.5585 316.079424 \nL 324.5585 0 \nL -0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 37.4225 291.830049 \nL 317.3585 291.830049 \nL 317.3585 11.894049 \nL 37.4225 11.894049 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g clip-path=\"url(#p517b4c1f03)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"imageee0652481a\" transform=\"scale(1 -1) translate(0 -280.08)\" x=\"37.4225\" y=\"-11.750049\" width=\"280.08\" height=\"280.08\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 38.047357 291.830049 \nL 38.047357 11.894049 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(33.593607 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 100.533071 291.830049 \nL 100.533071 11.894049 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <g transform=\"translate(91.625571 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 163.018786 291.830049 \nL 163.018786 11.894049 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <g transform=\"translate(149.657536 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 225.5045 291.830049 \nL 225.5045 11.894049 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(212.14325 305.967862) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 287.990214 291.830049 \nL 287.990214 11.894049 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <g transform=\"translate(274.628964 305.967862) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path d=\"M 37.4225 12.518906 \nL 317.3585 12.518906 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(25.015 17.837812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path d=\"M 37.4225 43.761763 \nL 317.3585 43.761763 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 25 -->\n      <g transform=\"translate(16.1075 49.08067) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path d=\"M 37.4225 75.004621 \nL 317.3585 75.004621 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_8\">\n      <!-- 50 -->\n      <g transform=\"translate(16.1075 80.323527) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path d=\"M 37.4225 106.247478 \nL 317.3585 106.247478 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_9\">\n      <!-- 75 -->\n      <g transform=\"translate(16.1075 111.566384) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path d=\"M 37.4225 137.490335 \nL 317.3585 137.490335 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_10\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 142.809241) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path d=\"M 37.4225 168.733192 \nL 317.3585 168.733192 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_11\">\n      <!-- 125 -->\n      <g transform=\"translate(7.2 174.052098) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_23\">\n      <path d=\"M 37.4225 199.976049 \nL 317.3585 199.976049 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_12\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 205.294955) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_25\">\n      <path d=\"M 37.4225 231.218906 \nL 317.3585 231.218906 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_13\">\n      <!-- 175 -->\n      <g transform=\"translate(7.2 236.537813) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_27\">\n      <path d=\"M 37.4225 262.461763 \nL 317.3585 262.461763 \n\" clip-path=\"url(#p517b4c1f03)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_14\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 267.78067) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 37.4225 291.830049 \nL 37.4225 11.894049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 317.3585 291.830049 \nL 317.3585 11.894049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 37.4225 291.830049 \nL 317.3585 291.830049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 37.4225 11.894049 \nL 317.3585 11.894049 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p517b4c1f03\">\n   <rect x=\"37.4225\" y=\"11.894049\" width=\"279.936\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in data.train_dl:\n",
    "    print (x.shape, y.shape)\n",
    "    plt.imshow(x[0].view(224, 224))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-05, 1.0476e-05, 1.0975e-05, 1.1498e-05, 1.2045e-05, 1.2619e-05,\n",
       "        1.3219e-05, 1.3849e-05, 1.4508e-05, 1.5199e-05, 1.5923e-05, 1.6681e-05,\n",
       "        1.7475e-05, 1.8307e-05, 1.9179e-05, 2.0092e-05, 2.1049e-05, 2.2051e-05,\n",
       "        2.3101e-05, 2.4201e-05, 2.5354e-05, 2.6561e-05, 2.7826e-05, 2.9151e-05,\n",
       "        3.0539e-05, 3.1993e-05, 3.3516e-05, 3.5112e-05, 3.6784e-05, 3.8535e-05,\n",
       "        4.0370e-05, 4.2292e-05, 4.4306e-05, 4.6416e-05, 4.8626e-05, 5.0941e-05,\n",
       "        5.3367e-05, 5.5908e-05, 5.8570e-05, 6.1359e-05, 6.4281e-05, 6.7342e-05,\n",
       "        7.0548e-05, 7.3907e-05, 7.7426e-05, 8.1113e-05, 8.4975e-05, 8.9022e-05,\n",
       "        9.3260e-05, 9.7701e-05, 1.0235e-04, 1.0723e-04, 1.1233e-04, 1.1768e-04,\n",
       "        1.2328e-04, 1.2915e-04, 1.3530e-04, 1.4175e-04, 1.4850e-04, 1.5557e-04,\n",
       "        1.6298e-04, 1.7074e-04, 1.7886e-04, 1.8738e-04, 1.9630e-04, 2.0565e-04,\n",
       "        2.1544e-04, 2.2570e-04, 2.3645e-04, 2.4771e-04, 2.5950e-04, 2.7186e-04,\n",
       "        2.8480e-04, 2.9836e-04, 3.1257e-04, 3.2745e-04, 3.4305e-04, 3.5938e-04,\n",
       "        3.7649e-04, 3.9442e-04, 4.1320e-04, 4.3288e-04, 4.5349e-04, 4.7508e-04,\n",
       "        4.9770e-04, 5.2140e-04, 5.4623e-04, 5.7224e-04, 5.9948e-04, 6.2803e-04,\n",
       "        6.5793e-04, 6.8926e-04, 7.2208e-04, 7.5646e-04, 7.9248e-04, 8.3022e-04,\n",
       "        8.6975e-04, 9.1116e-04, 9.5455e-04, 1.0000e-03])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = torch.logspace(-5,-3,100)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Training loss: 0.5284\n",
      "Step 50, Training loss: 0.4962\n",
      "Step 100, Training loss: 0.4595\n",
      "Step 150, Training loss: 0.4739\n",
      "Step 200, Training loss: 0.4628\n",
      "Step 250, Training loss: 0.4485\n",
      "Step 300, Training loss: 0.4361\n",
      "Step 350, Training loss: 0.4438\n",
      "Step 400, Training loss: 0.4408\n",
      "Step 450, Training loss: 0.4429\n",
      "Step 500, Training loss: 0.4265\n",
      "Step 550, Training loss: 0.4347\n",
      "Step 600, Training loss: 0.4138\n",
      "Step 650, Training loss: 0.3832\n",
      "Step 700, Training loss: 0.4049\n",
      "Step 750, Training loss: 0.3952\n",
      "Step 800, Training loss: 0.3923\n",
      "Step 850, Training loss: 0.3858\n",
      "Step 900, Training loss: 0.3860\n"
     ]
    }
   ],
   "source": [
    "#device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#print(f\"Using {device} device\")\n",
    "#model = VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).to(device)\n",
    "#model = AlexNet()\n",
    "#losses = []\n",
    "model.optimizer = torch.optim.AdamW(model.parameters(), lr=1.0e-5)\n",
    "for step, batch in enumerate(data.train_dl):\n",
    "\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    logits = model(x)\n",
    "    \n",
    "    train_loss = model.loss_fn(logits, y)\n",
    "    losses.append(train_loss)\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        mlosses = torch.tensor(losses)\n",
    "        print (f'Step {step}, Training loss: {mlosses[-50:].mean().item():.4f}')\n",
    "\n",
    "    model.optimizer.zero_grad(set_to_none=True)\n",
    "    train_loss.backward()\n",
    "    model.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (model)\n",
    "del (x)\n",
    "del(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3329e-05)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"449.967875pt\" height=\"327.93475pt\" viewBox=\"0 0 449.967875 327.93475\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-25T16:38:11.041484</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 327.93475 \nL 449.967875 327.93475 \nL 449.967875 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 41.871875 287.136 \nL 442.767875 287.136 \nL 442.767875 7.2 \nL 41.871875 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 60.094428 287.136 \nL 60.094428 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <g transform=\"translate(48.96224 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 116.283629 287.136 \nL 116.283629 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 1.2 -->\n      <g transform=\"translate(105.151442 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 172.472831 287.136 \nL 172.472831 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 1.4 -->\n      <g transform=\"translate(161.340644 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 228.662033 287.136 \nL 228.662033 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 1.6 -->\n      <g transform=\"translate(217.529845 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 284.851235 287.136 \nL 284.851235 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 1.8 -->\n      <g transform=\"translate(273.719047 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 341.040436 287.136 \nL 341.040436 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 2.0 -->\n      <g transform=\"translate(329.908249 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 397.229638 287.136 \nL 397.229638 7.2 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 2.2 -->\n      <g transform=\"translate(386.097451 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- 1e−5 -->\n     <g transform=\"translate(404.606938 317.823187) scale(0.14 -0.14)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"63.623047\"/>\n      <use xlink:href=\"#DejaVuSans-2212\" x=\"125.146484\"/>\n      <use xlink:href=\"#DejaVuSans-35\" x=\"208.935547\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <path d=\"M 41.871875 272.594596 \nL 442.767875 272.594596 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_9\">\n      <!-- 1.95 -->\n      <g transform=\"translate(7.2 277.913502) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_17\">\n      <path d=\"M 41.871875 237.027287 \nL 442.767875 237.027287 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_10\">\n      <!-- 2.00 -->\n      <g transform=\"translate(7.2 242.346193) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_19\">\n      <path d=\"M 41.871875 201.459978 \nL 442.767875 201.459978 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_11\">\n      <!-- 2.05 -->\n      <g transform=\"translate(7.2 206.778885) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <path d=\"M 41.871875 165.89267 \nL 442.767875 165.89267 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_12\">\n      <!-- 2.10 -->\n      <g transform=\"translate(7.2 171.211576) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_23\">\n      <path d=\"M 41.871875 130.325361 \nL 442.767875 130.325361 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_13\">\n      <!-- 2.15 -->\n      <g transform=\"translate(7.2 135.644267) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <path d=\"M 41.871875 94.758052 \nL 442.767875 94.758052 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_14\">\n      <!-- 2.20 -->\n      <g transform=\"translate(7.2 100.076958) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_27\">\n      <path d=\"M 41.871875 59.190744 \nL 442.767875 59.190744 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_15\">\n      <!-- 2.25 -->\n      <g transform=\"translate(7.2 64.50965) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_29\">\n      <path d=\"M 41.871875 23.623435 \nL 442.767875 23.623435 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_30\"/>\n     <g id=\"text_16\">\n      <!-- 2.30 -->\n      <g transform=\"translate(7.2 28.942341) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 60.09442 21.055414 \nL 64.455029 21.15819 \nL 68.8833 21.274534 \nL 73.38033 22.216652 \nL 77.947118 23.320058 \nL 82.584811 21.522657 \nL 87.29451 21.399359 \nL 92.077262 20.829339 \nL 96.934293 21.624076 \nL 101.866677 24.176189 \nL 106.87564 23.184379 \nL 111.962331 19.95964 \nL 117.127978 21.769422 \nL 122.373807 22.633864 \nL 127.701044 23.448952 \nL 133.110967 22.724429 \nL 138.604879 19.924364 \nL 144.184032 21.262154 \nL 149.849806 22.436282 \nL 155.603504 21.205338 \nL 161.446506 22.851797 \nL 167.380217 22.532274 \nL 173.405992 22.088097 \nL 179.525337 22.430346 \nL 185.739634 21.758059 \nL 192.050388 22.756992 \nL 198.459084 20.746575 \nL 204.967252 23.245774 \nL 211.576453 23.328538 \nL 218.28822 23.885328 \nL 225.104186 24.051026 \nL 232.025887 23.436911 \nL 239.055059 23.720648 \nL 246.193337 23.372294 \nL 253.442409 26.023452 \nL 260.803959 26.597033 \nL 268.279829 29.416772 \nL 275.871705 29.230214 \nL 283.581375 32.617089 \nL 291.410781 32.140179 \nL 299.36166 35.22059 \nL 307.435955 37.274593 \nL 315.635557 39.084036 \nL 323.962458 38.743143 \nL 332.418601 48.050011 \nL 341.005978 61.761343 \nL 349.726634 61.677222 \nL 358.582613 72.024744 \nL 367.576112 84.787174 \nL 376.709175 104.752946 \nL 385.984 132.360132 \nL 395.402734 138.116293 \nL 404.967726 161.602413 \nL 414.681124 240.580792 \nL 424.54533 274.411636 \n\" clip-path=\"url(#pd3b6a94753)\" style=\"fill: none; stroke: #008fd5; stroke-width: 4\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 41.871875 287.136 \nL 41.871875 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 442.767875 287.136 \nL 442.767875 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 41.871875 287.136 \nL 442.767875 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 41.871875 7.2 \nL 442.767875 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd3b6a94753\">\n   <rect x=\"41.871875\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = torch.tensor(losses)\n",
    "plt.plot(lr[:55], ll[:55])\n",
    "lr[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.8125, device='mps:0')\n",
      "1 tensor(0.8906, device='mps:0')\n",
      "2 tensor(0.9531, device='mps:0')\n",
      "3 tensor(0.9219, device='mps:0')\n",
      "4 tensor(0.8125, device='mps:0')\n",
      "5 tensor(0.8750, device='mps:0')\n",
      "6 tensor(0.7969, device='mps:0')\n",
      "7 tensor(0.9219, device='mps:0')\n",
      "8 tensor(0.8125, device='mps:0')\n",
      "9 tensor(0.7969, device='mps:0')\n",
      "10 tensor(0.8125, device='mps:0')\n",
      "11 tensor(0.7969, device='mps:0')\n",
      "12 tensor(0.9062, device='mps:0')\n",
      "13 tensor(0.8906, device='mps:0')\n",
      "14 tensor(0.8906, device='mps:0')\n",
      "15 tensor(0.8906, device='mps:0')\n",
      "16 tensor(0.9375, device='mps:0')\n",
      "17 tensor(0.8594, device='mps:0')\n",
      "18 tensor(0.8125, device='mps:0')\n",
      "19 tensor(0.8906, device='mps:0')\n",
      "20 tensor(0.9375, device='mps:0')\n",
      "21 tensor(0.8281, device='mps:0')\n",
      "22 tensor(0.8281, device='mps:0')\n",
      "23 tensor(0.8438, device='mps:0')\n",
      "24 tensor(0.8281, device='mps:0')\n",
      "25 tensor(0.8438, device='mps:0')\n",
      "26 tensor(0.8906, device='mps:0')\n",
      "27 tensor(0.8281, device='mps:0')\n",
      "28 tensor(0.8906, device='mps:0')\n",
      "29 tensor(0.7812, device='mps:0')\n",
      "30 tensor(0.8438, device='mps:0')\n",
      "31 tensor(0.9062, device='mps:0')\n",
      "32 tensor(0.8594, device='mps:0')\n",
      "33 tensor(0.8594, device='mps:0')\n",
      "34 tensor(0.9219, device='mps:0')\n",
      "35 tensor(0.8281, device='mps:0')\n",
      "36 tensor(0.8594, device='mps:0')\n",
      "37 tensor(0.8438, device='mps:0')\n",
      "38 tensor(0.8906, device='mps:0')\n",
      "39 tensor(0.8438, device='mps:0')\n",
      "40 tensor(0.9062, device='mps:0')\n",
      "41 tensor(0.8594, device='mps:0')\n",
      "42 tensor(0.8906, device='mps:0')\n",
      "43 tensor(0.9531, device='mps:0')\n",
      "44 tensor(0.8594, device='mps:0')\n",
      "45 tensor(0.8594, device='mps:0')\n",
      "46 tensor(0.8750, device='mps:0')\n",
      "47 tensor(0.8750, device='mps:0')\n",
      "48 tensor(0.8125, device='mps:0')\n",
      "49 tensor(0.9062, device='mps:0')\n",
      "50 tensor(0.8438, device='mps:0')\n",
      "51 tensor(0.7812, device='mps:0')\n",
      "52 tensor(0.8125, device='mps:0')\n",
      "53 tensor(0.8906, device='mps:0')\n",
      "54 tensor(0.8281, device='mps:0')\n",
      "55 tensor(0.9062, device='mps:0')\n",
      "56 tensor(0.9219, device='mps:0')\n",
      "57 tensor(0.8281, device='mps:0')\n",
      "58 tensor(0.8750, device='mps:0')\n",
      "59 tensor(0.9062, device='mps:0')\n",
      "60 tensor(0.9375, device='mps:0')\n",
      "61 tensor(0.8281, device='mps:0')\n",
      "62 tensor(0.8281, device='mps:0')\n",
      "63 tensor(0.8906, device='mps:0')\n",
      "64 tensor(0.9219, device='mps:0')\n",
      "65 tensor(0.8281, device='mps:0')\n",
      "66 tensor(0.8594, device='mps:0')\n",
      "67 tensor(0.8750, device='mps:0')\n",
      "68 tensor(0.8438, device='mps:0')\n",
      "69 tensor(0.7969, device='mps:0')\n",
      "70 tensor(0.9062, device='mps:0')\n",
      "71 tensor(0.8750, device='mps:0')\n",
      "72 tensor(0.8594, device='mps:0')\n",
      "73 tensor(0.8281, device='mps:0')\n",
      "74 tensor(0.8594, device='mps:0')\n",
      "75 tensor(0.8594, device='mps:0')\n",
      "76 tensor(0.9219, device='mps:0')\n",
      "77 tensor(0.9062, device='mps:0')\n",
      "78 tensor(0.8906, device='mps:0')\n",
      "79 tensor(0.9062, device='mps:0')\n",
      "80 tensor(0.8906, device='mps:0')\n",
      "81 tensor(0.8750, device='mps:0')\n",
      "82 tensor(0.8594, device='mps:0')\n",
      "83 tensor(0.9844, device='mps:0')\n",
      "84 tensor(0.9375, device='mps:0')\n",
      "85 tensor(0.8125, device='mps:0')\n",
      "86 tensor(0.8594, device='mps:0')\n",
      "87 tensor(0.8281, device='mps:0')\n",
      "88 tensor(0.8906, device='mps:0')\n",
      "89 tensor(0.8750, device='mps:0')\n",
      "90 tensor(0.8125, device='mps:0')\n",
      "91 tensor(0.9219, device='mps:0')\n",
      "92 tensor(0.8906, device='mps:0')\n",
      "93 tensor(0.8438, device='mps:0')\n",
      "94 tensor(0.8750, device='mps:0')\n",
      "95 tensor(0.8750, device='mps:0')\n",
      "96 tensor(0.8906, device='mps:0')\n",
      "97 tensor(0.8594, device='mps:0')\n",
      "98 tensor(0.9062, device='mps:0')\n",
      "99 tensor(0.8438, device='mps:0')\n",
      "100 tensor(0.9062, device='mps:0')\n",
      "101 tensor(0.7969, device='mps:0')\n",
      "102 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39maccuracy(logits, y)\n\u001b[1;32m     11\u001b[0m accs\u001b[39m.\u001b[39mappend(acc)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m (step, acc)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:427\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    424\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor_str.py:637\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    636\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor_str.py:568\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    567\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 568\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    571\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor_str.py:328\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    325\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[1;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accs = []\n",
    "for step, batch in enumerate(data.val_dl):\n",
    "\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    logits = model(x)\n",
    "\n",
    "    acc = model.accuracy(logits, y)\n",
    "    accs.append(acc)\n",
    "    print (step, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8669599294662476\n"
     ]
    }
   ],
   "source": [
    "acccs = torch.tensor(accs)\n",
    "\n",
    "print (acccs.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Net (GoogLeNet)\n",
    "\n",
    "#### WIth Inception layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000, 118, 20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Datasets\n",
    "class FashionMNIST:\n",
    "    def __init__(self) -> None:\n",
    "        # Get datasets\n",
    "        transforms = Compose([ToTensor(), Resize(size = (96, 96))])\n",
    "        self.train = datasets.FashionMNIST(root='data', train=True, transform=transforms)\n",
    "        self.val = datasets.FashionMNIST(root='data', train=False, transform=transforms)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.train_dl = torch.utils.data.DataLoader(self.train, batch_size = 512, shuffle=True)\n",
    "        self.val_dl = torch.utils.data.DataLoader(self.val, batch_size = 512, shuffle=True)\n",
    "\n",
    "data = FashionMNIST()\n",
    "len(data.train), len(data.val), len(data.train_dl), len(data.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(MyModule):\n",
    "    # `c1`--`c4` are the number of output channels for each branch\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # Branch 1\n",
    "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
    "        # Branch 2\n",
    "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
    "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
    "        # Branch 3\n",
    "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
    "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
    "        # Branch 4\n",
    "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1, b2, b3, b4), dim=1)\n",
    "\n",
    "class GoogleNet(MyModule):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.model = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
    "                                self.b5(), nn.LazyLinear(num_classes))\n",
    "        self.model.apply(self.init_cnn)\n",
    "        self.configure_optimizers()\n",
    "\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b2(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b3(self):\n",
    "        return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
    "                            Inception(128, (128, 192), (32, 96), 64),\n",
    "                            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b4(self):\n",
    "        return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
    "                            Inception(160, (112, 224), (24, 64), 64),\n",
    "                            Inception(128, (128, 256), (24, 64), 64),\n",
    "                            Inception(112, (144, 288), (32, 64), 64),\n",
    "                            Inception(256, (160, 320), (32, 128), 128),\n",
    "                            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b5(self):\n",
    "        return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
    "                            Inception(384, (192, 384), (48, 128), 128),\n",
    "                            nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-06, 1.0139e-06, 1.0281e-06, 1.0424e-06, 1.0569e-06, 1.0717e-06,\n",
       "        1.0866e-06, 1.1018e-06, 1.1171e-06, 1.1327e-06, 1.1485e-06, 1.1645e-06,\n",
       "        1.1807e-06, 1.1972e-06, 1.2139e-06, 1.2308e-06, 1.2479e-06, 1.2653e-06,\n",
       "        1.2830e-06, 1.3009e-06, 1.3190e-06, 1.3374e-06, 1.3560e-06, 1.3749e-06,\n",
       "        1.3941e-06, 1.4135e-06, 1.4332e-06, 1.4532e-06, 1.4735e-06, 1.4940e-06,\n",
       "        1.5148e-06, 1.5359e-06, 1.5573e-06, 1.5791e-06, 1.6011e-06, 1.6234e-06,\n",
       "        1.6460e-06, 1.6690e-06, 1.6922e-06, 1.7158e-06, 1.7397e-06, 1.7640e-06,\n",
       "        1.7886e-06, 1.8135e-06, 1.8388e-06, 1.8644e-06, 1.8904e-06, 1.9167e-06,\n",
       "        1.9435e-06, 1.9706e-06, 1.9980e-06, 2.0259e-06, 2.0541e-06, 2.0828e-06,\n",
       "        2.1118e-06, 2.1412e-06, 2.1711e-06, 2.2013e-06, 2.2320e-06, 2.2631e-06,\n",
       "        2.2947e-06, 2.3267e-06, 2.3591e-06, 2.3920e-06, 2.4253e-06, 2.4591e-06,\n",
       "        2.4934e-06, 2.5282e-06, 2.5634e-06, 2.5991e-06, 2.6354e-06, 2.6721e-06,\n",
       "        2.7094e-06, 2.7471e-06, 2.7854e-06, 2.8242e-06, 2.8636e-06, 2.9035e-06,\n",
       "        2.9440e-06, 2.9850e-06, 3.0266e-06, 3.0688e-06, 3.1116e-06, 3.1550e-06,\n",
       "        3.1990e-06, 3.2436e-06, 3.2888e-06, 3.3346e-06, 3.3811e-06, 3.4282e-06,\n",
       "        3.4760e-06, 3.5245e-06, 3.5736e-06, 3.6234e-06, 3.6739e-06, 3.7251e-06,\n",
       "        3.7771e-06, 3.8297e-06, 3.8831e-06, 3.9372e-06, 3.9921e-06, 4.0478e-06,\n",
       "        4.1042e-06, 4.1614e-06, 4.2194e-06, 4.2782e-06, 4.3378e-06, 4.3983e-06,\n",
       "        4.4596e-06, 4.5218e-06, 4.5848e-06, 4.6487e-06, 4.7135e-06, 4.7792e-06,\n",
       "        4.8459e-06, 4.9134e-06, 4.9819e-06, 5.0513e-06, 5.1218e-06, 5.1931e-06,\n",
       "        5.2655e-06, 5.3389e-06, 5.4134e-06, 5.4888e-06, 5.5653e-06, 5.6429e-06,\n",
       "        5.7216e-06, 5.8013e-06, 5.8822e-06, 5.9642e-06, 6.0473e-06, 6.1316e-06,\n",
       "        6.2171e-06, 6.3038e-06, 6.3916e-06, 6.4807e-06, 6.5711e-06, 6.6627e-06,\n",
       "        6.7555e-06, 6.8497e-06, 6.9452e-06, 7.0420e-06, 7.1402e-06, 7.2397e-06,\n",
       "        7.3406e-06, 7.4429e-06, 7.5467e-06, 7.6519e-06, 7.7585e-06, 7.8667e-06,\n",
       "        7.9763e-06, 8.0875e-06, 8.2003e-06, 8.3146e-06, 8.4305e-06, 8.5480e-06,\n",
       "        8.6671e-06, 8.7880e-06, 8.9105e-06, 9.0347e-06, 9.1606e-06, 9.2883e-06,\n",
       "        9.4178e-06, 9.5490e-06, 9.6822e-06, 9.8171e-06, 9.9540e-06, 1.0093e-05,\n",
       "        1.0233e-05, 1.0376e-05, 1.0521e-05, 1.0667e-05, 1.0816e-05, 1.0967e-05,\n",
       "        1.1120e-05, 1.1275e-05, 1.1432e-05, 1.1591e-05, 1.1753e-05, 1.1917e-05,\n",
       "        1.2083e-05, 1.2251e-05, 1.2422e-05, 1.2595e-05, 1.2771e-05, 1.2949e-05,\n",
       "        1.3129e-05, 1.3312e-05, 1.3498e-05, 1.3686e-05, 1.3877e-05, 1.4070e-05,\n",
       "        1.4266e-05, 1.4465e-05, 1.4667e-05, 1.4871e-05, 1.5078e-05, 1.5289e-05,\n",
       "        1.5502e-05, 1.5718e-05, 1.5937e-05, 1.6159e-05, 1.6384e-05, 1.6613e-05,\n",
       "        1.6844e-05, 1.7079e-05, 1.7317e-05, 1.7559e-05, 1.7803e-05, 1.8051e-05,\n",
       "        1.8303e-05, 1.8558e-05, 1.8817e-05, 1.9079e-05, 1.9345e-05, 1.9615e-05,\n",
       "        1.9888e-05, 2.0166e-05, 2.0447e-05, 2.0732e-05, 2.1021e-05, 2.1314e-05,\n",
       "        2.1611e-05, 2.1912e-05, 2.2217e-05, 2.2527e-05, 2.2841e-05, 2.3160e-05,\n",
       "        2.3482e-05, 2.3810e-05, 2.4142e-05, 2.4478e-05, 2.4819e-05, 2.5165e-05,\n",
       "        2.5516e-05, 2.5872e-05, 2.6232e-05, 2.6598e-05, 2.6969e-05, 2.7345e-05,\n",
       "        2.7726e-05, 2.8112e-05, 2.8504e-05, 2.8902e-05, 2.9304e-05, 2.9713e-05,\n",
       "        3.0127e-05, 3.0547e-05, 3.0973e-05, 3.1405e-05, 3.1842e-05, 3.2286e-05,\n",
       "        3.2736e-05, 3.3193e-05, 3.3655e-05, 3.4124e-05, 3.4600e-05, 3.5082e-05,\n",
       "        3.5572e-05, 3.6067e-05, 3.6570e-05, 3.7080e-05, 3.7597e-05, 3.8121e-05,\n",
       "        3.8652e-05, 3.9191e-05, 3.9737e-05, 4.0291e-05, 4.0853e-05, 4.1422e-05,\n",
       "        4.2000e-05, 4.2585e-05, 4.3179e-05, 4.3781e-05, 4.4391e-05, 4.5010e-05,\n",
       "        4.5637e-05, 4.6273e-05, 4.6918e-05, 4.7572e-05, 4.8235e-05, 4.8908e-05,\n",
       "        4.9590e-05, 5.0281e-05, 5.0982e-05, 5.1692e-05, 5.2413e-05, 5.3144e-05,\n",
       "        5.3884e-05, 5.4636e-05, 5.5397e-05, 5.6169e-05, 5.6952e-05, 5.7746e-05,\n",
       "        5.8551e-05, 5.9367e-05, 6.0195e-05, 6.1034e-05, 6.1885e-05, 6.2747e-05,\n",
       "        6.3622e-05, 6.4509e-05, 6.5408e-05, 6.6320e-05, 6.7244e-05, 6.8182e-05,\n",
       "        6.9132e-05, 7.0096e-05, 7.1073e-05, 7.2064e-05, 7.3068e-05, 7.4087e-05,\n",
       "        7.5119e-05, 7.6166e-05, 7.7228e-05, 7.8305e-05, 7.9396e-05, 8.0503e-05,\n",
       "        8.1625e-05, 8.2763e-05, 8.3917e-05, 8.5086e-05, 8.6272e-05, 8.7475e-05,\n",
       "        8.8694e-05, 8.9931e-05, 9.1184e-05, 9.2455e-05, 9.3744e-05, 9.5051e-05,\n",
       "        9.6376e-05, 9.7719e-05, 9.9081e-05, 1.0046e-04, 1.0186e-04, 1.0328e-04,\n",
       "        1.0472e-04, 1.0618e-04, 1.0766e-04, 1.0916e-04, 1.1068e-04, 1.1223e-04,\n",
       "        1.1379e-04, 1.1538e-04, 1.1699e-04, 1.1862e-04, 1.2027e-04, 1.2195e-04,\n",
       "        1.2365e-04, 1.2537e-04, 1.2712e-04, 1.2889e-04, 1.3069e-04, 1.3251e-04,\n",
       "        1.3436e-04, 1.3623e-04, 1.3813e-04, 1.4005e-04, 1.4201e-04, 1.4398e-04,\n",
       "        1.4599e-04, 1.4803e-04, 1.5009e-04, 1.5218e-04, 1.5430e-04, 1.5645e-04,\n",
       "        1.5864e-04, 1.6085e-04, 1.6309e-04, 1.6536e-04, 1.6767e-04, 1.7000e-04,\n",
       "        1.7237e-04, 1.7478e-04, 1.7721e-04, 1.7968e-04, 1.8219e-04, 1.8473e-04,\n",
       "        1.8730e-04, 1.8991e-04, 1.9256e-04, 1.9525e-04, 1.9797e-04, 2.0073e-04,\n",
       "        2.0352e-04, 2.0636e-04, 2.0924e-04, 2.1216e-04, 2.1511e-04, 2.1811e-04,\n",
       "        2.2115e-04, 2.2423e-04, 2.2736e-04, 2.3053e-04, 2.3374e-04, 2.3700e-04,\n",
       "        2.4030e-04, 2.4365e-04, 2.4705e-04, 2.5049e-04, 2.5399e-04, 2.5753e-04,\n",
       "        2.6112e-04, 2.6476e-04, 2.6845e-04, 2.7219e-04, 2.7598e-04, 2.7983e-04,\n",
       "        2.8373e-04, 2.8769e-04, 2.9170e-04, 2.9576e-04, 2.9988e-04, 3.0406e-04,\n",
       "        3.0830e-04, 3.1260e-04, 3.1696e-04, 3.2138e-04, 3.2586e-04, 3.3040e-04,\n",
       "        3.3500e-04, 3.3967e-04, 3.4441e-04, 3.4921e-04, 3.5408e-04, 3.5901e-04,\n",
       "        3.6402e-04, 3.6909e-04, 3.7424e-04, 3.7945e-04, 3.8474e-04, 3.9011e-04,\n",
       "        3.9554e-04, 4.0106e-04, 4.0665e-04, 4.1232e-04, 4.1806e-04, 4.2389e-04,\n",
       "        4.2980e-04, 4.3579e-04, 4.4187e-04, 4.4803e-04, 4.5427e-04, 4.6060e-04,\n",
       "        4.6702e-04, 4.7353e-04, 4.8013e-04, 4.8683e-04, 4.9361e-04, 5.0049e-04,\n",
       "        5.0747e-04, 5.1454e-04, 5.2172e-04, 5.2899e-04, 5.3636e-04, 5.4384e-04,\n",
       "        5.5142e-04, 5.5911e-04, 5.6690e-04, 5.7480e-04, 5.8282e-04, 5.9094e-04,\n",
       "        5.9918e-04, 6.0753e-04, 6.1600e-04, 6.2458e-04, 6.3329e-04, 6.4212e-04,\n",
       "        6.5107e-04, 6.6014e-04, 6.6935e-04, 6.7868e-04, 6.8814e-04, 6.9773e-04,\n",
       "        7.0746e-04, 7.1732e-04, 7.2732e-04, 7.3745e-04, 7.4773e-04, 7.5816e-04,\n",
       "        7.6873e-04, 7.7944e-04, 7.9031e-04, 8.0132e-04, 8.1249e-04, 8.2382e-04,\n",
       "        8.3530e-04, 8.4695e-04, 8.5875e-04, 8.7072e-04, 8.8286e-04, 8.9517e-04,\n",
       "        9.0764e-04, 9.2030e-04, 9.3313e-04, 9.4613e-04, 9.5932e-04, 9.7269e-04,\n",
       "        9.8625e-04, 1.0000e-03])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = torch.logspace(-6,-3,500)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Step 0, Training loss: 2.3012\n",
      "Step 25, Training loss: 2.3030\n",
      "Step 50, Training loss: 2.3027\n",
      "Step 75, Training loss: 2.3028\n",
      "Step 100, Training loss: 2.2645\n",
      "Step 0, Training loss: 1.8619\n",
      "Step 25, Training loss: 1.3519\n",
      "Step 50, Training loss: 1.1141\n",
      "Step 75, Training loss: 1.0210\n",
      "Step 100, Training loss: 0.9709\n",
      "Step 0, Training loss: 0.9606\n",
      "Step 25, Training loss: 0.9112\n",
      "Step 50, Training loss: 0.9266\n",
      "Step 75, Training loss: 0.8702\n",
      "Step 100, Training loss: 0.8406\n",
      "Step 0, Training loss: 0.9287\n",
      "Step 25, Training loss: 0.7668\n",
      "Step 50, Training loss: 0.7152\n",
      "Step 75, Training loss: 0.7329\n",
      "Step 100, Training loss: 0.7128\n",
      "Step 0, Training loss: 0.6875\n",
      "Step 25, Training loss: 0.6880\n",
      "Step 50, Training loss: 0.6748\n",
      "Step 75, Training loss: 0.6450\n",
      "Step 100, Training loss: 0.6327\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = GoogleNet().to(device)\n",
    "\n",
    "losses = []\n",
    "\n",
    "i = 0\n",
    "model.optimizer = torch.optim.AdamW(model.parameters(), lr=1.0e-4)\n",
    "for epoch in range(5):\n",
    "    for step, batch in enumerate(data.train_dl):\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        \n",
    "        train_loss = model.loss_fn(logits, y)\n",
    "        losses.append(train_loss)\n",
    "    \n",
    "        if step % 25 == 0:\n",
    "            mlosses = torch.tensor(losses)\n",
    "            print (f'Step {step}, Training loss: {mlosses[-25:].mean().item():.4f}')\n",
    "\n",
    "        model.optimizer.zero_grad(set_to_none=True)\n",
    "        train_loss.backward()\n",
    "        model.optimizer.step()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x302fa03d0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"449.967875pt\" height=\"311.385375pt\" viewBox=\"0 0 449.967875 311.385375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-26T05:33:10.011805</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 311.385375 \nL 449.967875 311.385375 \nL 449.967875 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 41.871875 287.136 \nL 442.767875 287.136 \nL 442.767875 7.2 \nL 41.871875 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 74.215351 287.136 \nL 74.215351 7.2 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <g transform=\"translate(63.083164 301.273813) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 152.140858 287.136 \nL 152.140858 7.2 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 1.2 -->\n      <g transform=\"translate(141.00867 301.273813) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 230.066364 287.136 \nL 230.066364 7.2 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 1.4 -->\n      <g transform=\"translate(218.934177 301.273813) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 307.991871 287.136 \nL 307.991871 7.2 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 1.6 -->\n      <g transform=\"translate(296.859683 301.273813) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 385.917377 287.136 \nL 385.917377 7.2 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 1.8 -->\n      <g transform=\"translate(374.78519 301.273813) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path d=\"M 41.871875 271.108535 \nL 442.767875 271.108535 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 0.92 -->\n      <g transform=\"translate(7.2 276.427442) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path d=\"M 41.871875 238.900155 \nL 442.767875 238.900155 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 0.93 -->\n      <g transform=\"translate(7.2 244.219062) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path d=\"M 41.871875 206.691776 \nL 442.767875 206.691776 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_8\">\n      <!-- 0.94 -->\n      <g transform=\"translate(7.2 212.010682) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path d=\"M 41.871875 174.483396 \nL 442.767875 174.483396 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_9\">\n      <!-- 0.95 -->\n      <g transform=\"translate(7.2 179.802302) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path d=\"M 41.871875 142.275016 \nL 442.767875 142.275016 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_10\">\n      <!-- 0.96 -->\n      <g transform=\"translate(7.2 147.593922) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path d=\"M 41.871875 110.066636 \nL 442.767875 110.066636 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_11\">\n      <!-- 0.97 -->\n      <g transform=\"translate(7.2 115.385542) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_23\">\n      <path d=\"M 41.871875 77.858256 \nL 442.767875 77.858256 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_12\">\n      <!-- 0.98 -->\n      <g transform=\"translate(7.2 83.177162) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_25\">\n      <path d=\"M 41.871875 45.649876 \nL 442.767875 45.649876 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_13\">\n      <!-- 0.99 -->\n      <g transform=\"translate(7.2 50.968782) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_27\">\n      <path d=\"M 41.871875 13.441496 \nL 442.767875 13.441496 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_14\">\n      <!-- 1.00 -->\n      <g transform=\"translate(7.2 18.760402) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 60.09442 19.924364 \nL 65.328767 21.427351 \nL 70.636105 21.488975 \nL 76.01741 23.299126 \nL 81.473705 23.993122 \nL 87.006126 25.742992 \nL 92.615604 28.188969 \nL 98.303252 28.368852 \nL 104.070232 31.715969 \nL 109.917612 32.818108 \nL 115.84646 35.78492 \nL 121.857985 40.204036 \nL 127.9533 39.797429 \nL 134.133567 42.556137 \nL 140.399994 49.665618 \nL 146.753742 52.212191 \nL 153.196111 55.943454 \nL 159.728262 55.156733 \nL 166.35145 58.83693 \nL 173.067022 72.197179 \nL 179.876138 77.981059 \nL 186.780146 77.305493 \nL 193.780485 92.604516 \nL 200.878364 107.212039 \nL 208.075128 118.404868 \nL 215.372219 105.465625 \nL 222.771076 150.433335 \nL 230.273091 131.899117 \nL 237.87966 146.416218 \nL 245.592268 152.385356 \nL 253.412354 171.169145 \nL 261.341452 167.41926 \nL 269.381094 197.544276 \nL 277.532768 175.358849 \nL 285.798144 222.761978 \nL 294.178662 211.936784 \nL 302.675995 236.141232 \nL 311.291816 200.098528 \nL 320.027702 237.771884 \nL 328.885419 205.694655 \nL 337.866593 264.300597 \nL 346.972943 258.854596 \nL 356.206186 213.498516 \nL 365.568227 221.292587 \nL 375.060692 195.646968 \nL 384.685532 242.427132 \nL 394.444557 274.411636 \nL 404.339534 229.967063 \nL 414.372506 192.65424 \nL 424.54533 237.264873 \n\" clip-path=\"url(#p392c535d5d)\" style=\"fill: none; stroke: #008fd5; stroke-width: 4\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 41.871875 287.136 \nL 41.871875 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 442.767875 287.136 \nL 442.767875 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 41.871875 287.136 \nL 442.767875 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 41.871875 7.2 \nL 442.767875 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p392c535d5d\">\n   <rect x=\"41.871875\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = torch.tensor(losses)\n",
    "plt.plot(lr[330:380]/1e-4, ll[330:380]/ll[:400].max())\n",
    "#xx = ll[:400]\n",
    "#yy = lr[:400]\n",
    "\n",
    "#gg = (-(xx[1:] - xx[:-1]))#/(yy[1:] - yy[:-1])\n",
    "\n",
    "#plt.semilogx(yy[:-1], gg/gg.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data.train_dl:\n",
    "    x, y = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 96, 96])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = GoogleNet()\n",
    "\n",
    "print (x.shape)\n",
    "y = model(x)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNet(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): LazyConv2d(0, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): LazyConv2d(0, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Inception(\n",
      "        (b1_1): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Inception(\n",
      "        (b1_1): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Inception(\n",
      "        (b1_1): LazyConv2d(0, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Inception(\n",
      "        (b1_1): LazyConv2d(0, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Inception(\n",
      "        (b1_1): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): Inception(\n",
      "        (b1_1): LazyConv2d(0, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (4): Inception(\n",
      "        (b1_1): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Inception(\n",
      "        (b1_1): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Inception(\n",
      "        (b1_1): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_1): LazyConv2d(0, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b2_2): LazyConv2d(0, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (b3_1): LazyConv2d(0, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (b3_2): LazyConv2d(0, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (b4_2): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (5): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GoogleNet()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (b1_1): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (b2_1): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (b2_2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (b3_1): LazyConv2d(0, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (b3_2): LazyConv2d(0, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (b4_2): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (b1_1): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (b2_1): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (b2_2): LazyConv2d(0, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (b3_1): LazyConv2d(0, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (b3_2): LazyConv2d(0, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (b4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (b4_2): LazyConv2d(0, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (model.model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original x\n",
      "torch.Size([64, 1, 96, 96]) 0.59M params from  original x\n",
      "\n",
      "First block\n",
      "torch.Size([64, 64, 48, 48]) 9.44M params from  Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "torch.Size([64, 64, 48, 48]) 9.44M params from  ReLU()\n",
      "torch.Size([64, 64, 24, 24]) 2.36M params from  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "\n",
      "Second block\n",
      "torch.Size([64, 64, 24, 24]) 2.36M params from  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "torch.Size([64, 64, 24, 24]) 2.36M params from  ReLU()\n",
      "torch.Size([64, 192, 24, 24]) 7.08M params from  Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([64, 192, 24, 24]) 7.08M params from  ReLU()\n",
      "torch.Size([64, 192, 12, 12]) 1.77M params from  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "\n",
      "Third block, First Inception Layer\n",
      "torch.Size([64, 64, 12, 12]) 0.59M params from  Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "torch.Size([64, 96, 12, 12]) 0.88M params from  Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "torch.Size([64, 128, 12, 12]) 1.18M params from  Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "torch.Size([64, 16, 12, 12]) 0.15M params from  Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "torch.Size([64, 32, 12, 12]) 0.29M params from  Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "torch.Size([64, 192, 12, 12]) 1.77M params from  MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "torch.Size([64, 32, 12, 12]) 0.29M params from  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "torch.Size([64, 256, 12, 12]) 2.36M params from torch.cat((y1, y2, y3, y4), dim=1)\n"
     ]
    }
   ],
   "source": [
    "y = x\n",
    "\n",
    "print ('\\nOriginal x')\n",
    "print (y.shape, f'{y.numel()/1.0e6:.2f}M params from  original x')\n",
    "\n",
    "# First block\n",
    "print ('\\nFirst block')\n",
    "for layer in model.model[0]:\n",
    "    y = layer(y)\n",
    "    print (y.shape, f'{y.numel()/1.0e6:.2f}M params from ', layer)\n",
    "\n",
    "# Second block\n",
    "print ('\\nSecond block')\n",
    "for layer in model.model[1]:\n",
    "    y = layer(y)\n",
    "    print (y.shape, f'{y.numel()/1.0e6:.2f}M params from ', layer)\n",
    "\n",
    "\n",
    "# First Inception \n",
    "print ('\\nThird block, First Inception Layer')\n",
    "y1 = model.model[2][0].b1_1(y)\n",
    "print (y1.shape, f'{y1.numel()/1.0e6:.2f}M params from ', model.model[2][0].b1_1)\n",
    "y2= model.model[2][0].b2_1(y)\n",
    "print (y2.shape, f'{y2.numel()/1.0e6:.2f}M params from ', model.model[2][0].b2_1)\n",
    "y2= model.model[2][0].b2_2(y2)\n",
    "print (y2.shape, f'{y2.numel()/1.0e6:.2f}M params from ', model.model[2][0].b2_2)\n",
    "y3= model.model[2][0].b3_1(y)\n",
    "print (y3.shape, f'{y3.numel()/1.0e6:.2f}M params from ', model.model[2][0].b3_1)\n",
    "y3= model.model[2][0].b3_2(y3)\n",
    "print (y3.shape, f'{y3.numel()/1.0e6:.2f}M params from ', model.model[2][0].b3_2)\n",
    "y4= model.model[2][0].b4_1(y)\n",
    "print (y4.shape, f'{y4.numel()/1.0e6:.2f}M params from ', model.model[2][0].b4_1)\n",
    "y4= model.model[2][0].b4_2(y3)\n",
    "print (y4.shape, f'{y4.numel()/1.0e6:.2f}M params from ', model.model[2][0].b4_2)\n",
    "y = torch.cat((y1, y2, y3, y4), dim=1)\n",
    "print (y.shape, f'{y.numel()/1.0e6:.2f}M params from torch.cat((y1, y2, y3, y4), dim=1)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 32, 1, 1], expected input[64, 192, 12, 12] to have 32 channels, but got 192 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logits \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mMyModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> 7\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[76], line 21\u001b[0m, in \u001b[0;36mInception.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m b2 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2_2(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2_1(x))))\n\u001b[1;32m     20\u001b[0m b3 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb3_2(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb3_1(x))))\n\u001b[0;32m---> 21\u001b[0m b4 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb4_2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb4_1(x)))\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((b1, b2, b3, b4), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 32, 1, 1], expected input[64, 192, 12, 12] to have 32 channels, but got 192 channels instead"
     ]
    }
   ],
   "source": [
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm\n",
    "\n",
    "#### And Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000, 938, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Datasets\n",
    "class FashionMNIST:\n",
    "    def __init__(self) -> None:\n",
    "        # Get datasets\n",
    "        transforms = Compose([ToTensor(), Resize(size = (224, 224))])\n",
    "        self.train = datasets.FashionMNIST(root='data', train=True, transform=ToTensor())\n",
    "        self.val = datasets.FashionMNIST(root='data', train=False, transform=ToTensor())\n",
    "\n",
    "        # Create data loaders\n",
    "        self.train_dl = torch.utils.data.DataLoader(self.train, batch_size = 64, shuffle=True)\n",
    "        self.val_dl = torch.utils.data.DataLoader(self.val, batch_size = 1024, shuffle=True)\n",
    "\n",
    "data = FashionMNIST()\n",
    "len(data.train), len(data.val), len(data.train_dl), len(data.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    if not torch.is_grad_enabled():\n",
    "        X_hat = (X - moving_mean)/torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "\n",
    "        X_hat = (X - mean)/torch.sqrt(var + eps)\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * mean\n",
    "\n",
    "    Y = gamma * X_hat + beta\n",
    "    return Y, moving_mean.data, moving_var.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(MyModule):\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1.0e-5, momentum=0.1)\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNLeNetScratch(MyModule):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5), BatchNorm(6, num_dims=4),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), BatchNorm(16, num_dims=4),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(), nn.LazyLinear(120),\n",
    "            BatchNorm(120, num_dims=2), nn.ReLU(), nn.LazyLinear(84),\n",
    "            BatchNorm(84, num_dims=2), nn.ReLU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        \n",
    "        self.configure_optimizers()\n",
    "        #self.apply(self.init_cnn)\n",
    "\n",
    "    def init(self, x):\n",
    "        _ = self(x)\n",
    "        self.apply(self.init_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0/ 10 with train loss 0.7151, train loss 0.4871, and accuracy 0.8184\n",
      "epoch   1/ 10 with train loss 0.4407, train loss 0.4018, and accuracy 0.8555\n",
      "epoch   2/ 10 with train loss 0.3815, train loss 0.3993, and accuracy 0.8486\n",
      "epoch   3/ 10 with train loss 0.3471, train loss 0.3778, and accuracy 0.8691\n",
      "epoch   4/ 10 with train loss 0.3236, train loss 0.3524, and accuracy 0.8799\n",
      "epoch   5/ 10 with train loss 0.3059, train loss 0.3457, and accuracy 0.8828\n",
      "epoch   6/ 10 with train loss 0.2909, train loss 0.3280, and accuracy 0.8916\n",
      "epoch   7/ 10 with train loss 0.2791, train loss 0.3000, and accuracy 0.8838\n",
      "epoch   8/ 10 with train loss 0.2679, train loss 0.3219, and accuracy 0.8867\n",
      "epoch   9/ 10 with train loss 0.2579, train loss 0.2980, and accuracy 0.8848\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = BNLeNetScratch().to(device)\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "for batch in data.train_dl:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.init(x)\n",
    "\n",
    "\n",
    "lr = torch.logspace(-6, -1, 500)\n",
    "\n",
    "model.optimizer = torch.optim.AdamW(model.parameters(), lr=2.0e-4)\n",
    "for epoch in range(max_epochs):\n",
    "    train_losses = []\n",
    "    for step, batch in enumerate(data.train_dl):\n",
    "\n",
    "        # if step == 500:\n",
    "        #    break\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        train_logits = model(x)\n",
    "\n",
    "        train_loss = model.loss_fn(train_logits, y)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        # model.optimizer = torch.optim.AdamW(model.parameters(), lr=lr[step])\n",
    "        model.optimizer.zero_grad(set_to_none=True)\n",
    "        train_loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "        # if step % 100 == 0:\n",
    "        #    mtrain_loss = torch.tensor(train_losses)[-50:].mean().item()\n",
    "        #    print (f'step {step:>3d} with loss {mtrain_loss:.4f}')\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for batch in data.val_dl:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        break\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    val_logits = model(x)\n",
    "    val_loss = model.loss_fn(val_logits, y).item()\n",
    "    val_acc = model.accuracy(val_logits, y).item()\n",
    "\n",
    "    mtrain_loss = torch.tensor(train_losses).mean().item()\n",
    "    print(f'epoch {epoch:>3d}/{max_epochs:>3d} with train loss {mtrain_loss:.4f}, val loss {val_loss:.4f}, and accuracy {val_acc:.4f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNLeNet(MyModule):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(num_classes))\n",
    "\n",
    "    def init(self, x):\n",
    "        logits = self(x)\n",
    "        self.apply(self.init_cnn)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0/ 10 with train loss 2.3775, val loss 2.3775, and accuracy 0.1250\n",
      "epoch   1/ 10 with train loss 0.9219, val loss 0.6594, and accuracy 0.7871\n",
      "epoch   2/ 10 with train loss 0.5466, val loss 0.5362, and accuracy 0.8135\n",
      "epoch   3/ 10 with train loss 0.4582, val loss 0.4585, and accuracy 0.8418\n",
      "epoch   4/ 10 with train loss 0.4165, val loss 0.4630, and accuracy 0.8340\n",
      "epoch   5/ 10 with train loss 0.3935, val loss 0.3735, and accuracy 0.8594\n",
      "epoch   6/ 10 with train loss 0.3709, val loss 0.4129, and accuracy 0.8545\n",
      "epoch   7/ 10 with train loss 0.3570, val loss 0.3833, and accuracy 0.8682\n",
      "epoch   8/ 10 with train loss 0.3439, val loss 0.3687, and accuracy 0.8604\n",
      "epoch   9/ 10 with train loss 0.3331, val loss 0.3411, and accuracy 0.8691\n",
      "epoch  10/ 10 with train loss 0.3244, val loss 0.3465, and accuracy 0.8672\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = BNLeNet().to(device)\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "# Initial step\n",
    "for batch in data.train_dl:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    break\n",
    "\n",
    "init_logits = model.init(x)\n",
    "mtrain_loss = model.loss_fn(init_logits, y).item()\n",
    "val_loss = mtrain_loss\n",
    "val_acc = model.accuracy(init_logits, y)\n",
    "epoch = 0\n",
    "print(f'epoch {epoch:>3d}/{max_epochs:>3d} with train loss {mtrain_loss:.4f}, val loss {val_loss:.4f}, and accuracy {val_acc:.4f}')\n",
    "\n",
    "\n",
    "lr = torch.logspace(-6, -1, 500)\n",
    "\n",
    "model.optimizer = torch.optim.AdamW(model.parameters(), lr=3.0e-4)\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    train_losses = []\n",
    "    for step, batch in enumerate(data.train_dl):\n",
    "\n",
    "        #if step == 500:\n",
    "        #    break\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        train_logits = model(x)\n",
    "\n",
    "        train_loss = model.loss_fn(train_logits, y)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        #model.optimizer = torch.optim.AdamW(model.parameters(), lr=lr[step])\n",
    "        model.optimizer.zero_grad(set_to_none=True)\n",
    "        train_loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "        \n",
    "        # if step % 100 == 0:\n",
    "        #    mtrain_loss = torch.tensor(train_losses)[-50:].mean().item()\n",
    "        #    print (f'step {step:>3d} with loss {mtrain_loss:.4f}')\n",
    "\n",
    "    #break\n",
    "    #with torch.no_grad():\n",
    "    for batch in data.val_dl:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        break\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    val_logits = model(x)\n",
    "    val_loss = model.loss_fn(val_logits, y).item()\n",
    "    val_acc = model.accuracy(val_logits, y).item()\n",
    "\n",
    "    mtrain_loss = torch.tensor(train_losses).mean().item()\n",
    "    print(f'epoch {epoch:>3d}/{max_epochs:>3d} with train loss {mtrain_loss:.4f}, val loss {val_loss:.4f}, and accuracy {val_acc:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16dab89a0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"441.060375pt\" height=\"311.385375pt\" viewBox=\"0 0 441.060375 311.385375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-27T05:01:17.391415</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 311.385375 \nL 441.060375 311.385375 \nL 441.060375 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 32.964375 287.136 \nL 433.860375 287.136 \nL 433.860375 7.2 \nL 32.964375 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 51.186921 287.136 \nL 51.186921 7.2 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- $\\mathdefault{10^{-6}}$ -->\n      <g transform=\"translate(34.736921 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 124.077102 287.136 \nL 124.077102 7.2 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- $\\mathdefault{10^{-5}}$ -->\n      <g transform=\"translate(107.627102 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 196.967284 287.136 \nL 196.967284 7.2 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- $\\mathdefault{10^{-4}}$ -->\n      <g transform=\"translate(180.517284 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 269.857466 287.136 \nL 269.857466 7.2 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- $\\mathdefault{10^{-3}}$ -->\n      <g transform=\"translate(253.407466 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 342.747647 287.136 \nL 342.747647 7.2 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- $\\mathdefault{10^{-2}}$ -->\n      <g transform=\"translate(326.297647 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 415.637829 287.136 \nL 415.637829 7.2 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- $\\mathdefault{10^{-1}}$ -->\n      <g transform=\"translate(399.187829 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\"/>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_14\"/>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_15\"/>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_16\"/>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_17\"/>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_18\"/>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_19\"/>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_20\"/>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_21\"/>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_22\"/>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_23\"/>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_24\"/>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_25\"/>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_26\"/>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_27\"/>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_28\"/>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_29\"/>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_30\"/>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_31\"/>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_32\"/>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_33\"/>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_34\"/>\n    </g>\n    <g id=\"xtick_29\">\n     <g id=\"line2d_35\"/>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_36\"/>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_37\"/>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_38\"/>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_39\"/>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_40\"/>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_41\"/>\n    </g>\n    <g id=\"xtick_36\">\n     <g id=\"line2d_42\"/>\n    </g>\n    <g id=\"xtick_37\">\n     <g id=\"line2d_43\"/>\n    </g>\n    <g id=\"xtick_38\">\n     <g id=\"line2d_44\"/>\n    </g>\n    <g id=\"xtick_39\">\n     <g id=\"line2d_45\"/>\n    </g>\n    <g id=\"xtick_40\">\n     <g id=\"line2d_46\"/>\n    </g>\n    <g id=\"xtick_41\">\n     <g id=\"line2d_47\"/>\n    </g>\n    <g id=\"xtick_42\">\n     <g id=\"line2d_48\"/>\n    </g>\n    <g id=\"xtick_43\">\n     <g id=\"line2d_49\"/>\n    </g>\n    <g id=\"xtick_44\">\n     <g id=\"line2d_50\"/>\n    </g>\n    <g id=\"xtick_45\">\n     <g id=\"line2d_51\"/>\n    </g>\n    <g id=\"xtick_46\">\n     <g id=\"line2d_52\"/>\n    </g>\n    <g id=\"xtick_47\">\n     <g id=\"line2d_53\"/>\n    </g>\n    <g id=\"xtick_48\">\n     <g id=\"line2d_54\"/>\n    </g>\n    <g id=\"xtick_49\">\n     <g id=\"line2d_55\"/>\n    </g>\n    <g id=\"xtick_50\">\n     <g id=\"line2d_56\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_57\">\n      <path d=\"M 32.964375 282.321886 \nL 433.860375 282.321886 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_58\"/>\n     <g id=\"text_7\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 287.640792) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_59\">\n      <path d=\"M 32.964375 230.063987 \nL 433.860375 230.063987 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_60\"/>\n     <g id=\"text_8\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 235.382893) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_61\">\n      <path d=\"M 32.964375 177.806088 \nL 433.860375 177.806088 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_62\"/>\n     <g id=\"text_9\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 183.124994) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_63\">\n      <path d=\"M 32.964375 125.548188 \nL 433.860375 125.548188 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_64\"/>\n     <g id=\"text_10\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 130.867095) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_65\">\n      <path d=\"M 32.964375 73.290289 \nL 433.860375 73.290289 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_66\"/>\n     <g id=\"text_11\">\n      <!-- 2.5 -->\n      <g transform=\"translate(7.2 78.609195) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_67\">\n      <path d=\"M 32.964375 21.03239 \nL 433.860375 21.03239 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_68\"/>\n     <g id=\"text_12\">\n      <!-- 3.0 -->\n      <g transform=\"translate(7.2 26.351296) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 51.18692 75.652688 \nL 51.917284 65.176723 \nL 52.647645 86.907008 \nL 53.378007 82.453547 \nL 54.108372 70.01667 \nL 54.838733 82.47119 \nL 55.569097 69.409506 \nL 56.299459 76.617658 \nL 57.02982 74.82502 \nL 57.760184 69.860506 \nL 58.490546 72.468477 \nL 59.220908 74.397992 \nL 59.95127 82.775619 \nL 60.681634 99.105315 \nL 61.411997 79.102581 \nL 62.14236 73.991396 \nL 62.872721 80.47265 \nL 63.603084 79.478552 \nL 64.333446 76.560843 \nL 65.06381 78.442739 \nL 65.794172 82.172815 \nL 66.524534 82.857053 \nL 67.254897 87.68621 \nL 67.985258 83.735829 \nL 68.715623 78.984717 \nL 69.445984 76.664803 \nL 70.906709 95.986116 \nL 71.63707 72.694861 \nL 72.367433 78.691874 \nL 73.097798 83.321608 \nL 73.82816 102.619124 \nL 74.558522 71.413552 \nL 75.288885 82.09041 \nL 76.019247 86.689768 \nL 76.749609 86.019211 \nL 77.479971 74.366619 \nL 78.210335 78.618365 \nL 78.940696 80.910319 \nL 79.67106 60.143135 \nL 80.401422 93.15343 \nL 81.131785 87.248416 \nL 81.862147 72.34214 \nL 82.592509 85.626047 \nL 83.322873 70.399842 \nL 84.053236 79.053741 \nL 84.783598 83.018475 \nL 85.513961 72.668996 \nL 86.244323 88.036664 \nL 86.974684 91.97309 \nL 87.705047 79.444114 \nL 88.43541 94.62574 \nL 89.165772 78.642237 \nL 89.896135 77.875668 \nL 90.626498 72.057222 \nL 91.35686 84.30412 \nL 92.087222 76.656481 \nL 92.817585 96.015869 \nL 93.547947 79.671371 \nL 95.008674 91.8172 \nL 96.4694 68.381443 \nL 97.199762 90.508704 \nL 97.930124 85.078538 \nL 98.660486 73.477402 \nL 99.390848 73.334594 \nL 100.12121 81.739532 \nL 100.851574 88.176157 \nL 101.581936 73.860225 \nL 102.312299 80.281526 \nL 103.042662 89.586869 \nL 103.773023 70.58997 \nL 104.503385 82.033272 \nL 105.23375 73.317625 \nL 105.964111 93.568921 \nL 106.694474 85.27345 \nL 107.424836 97.236452 \nL 108.1552 80.713363 \nL 108.885562 80.653758 \nL 109.615924 66.929641 \nL 111.076649 77.072719 \nL 111.807012 89.025131 \nL 112.537373 73.151468 \nL 113.267736 75.225909 \nL 113.998099 93.820673 \nL 114.728461 79.543938 \nL 115.458824 92.312181 \nL 116.189188 69.037497 \nL 116.919551 95.452387 \nL 117.649912 88.925033 \nL 118.380274 86.773021 \nL 119.110636 71.249962 \nL 119.841 86.209614 \nL 120.571361 82.928469 \nL 121.301726 83.239053 \nL 122.032086 78.673833 \nL 122.762449 102.237672 \nL 123.492811 78.507502 \nL 124.223174 71.451104 \nL 124.953538 85.8087 \nL 125.683899 72.752498 \nL 126.414262 72.098312 \nL 127.144624 75.318456 \nL 127.874987 86.853134 \nL 128.605351 70.726698 \nL 129.335712 80.904787 \nL 130.066074 80.406193 \nL 130.796438 68.23871 \nL 131.526801 83.537328 \nL 132.257163 95.820608 \nL 132.987526 99.609118 \nL 133.717888 90.076144 \nL 134.448251 102.094789 \nL 135.178613 74.721309 \nL 135.908976 77.184903 \nL 136.639337 85.617351 \nL 137.3697 78.524023 \nL 138.100061 77.826604 \nL 138.830426 91.724703 \nL 139.560787 87.939681 \nL 140.291152 98.350683 \nL 141.021512 94.70391 \nL 141.751874 83.566732 \nL 142.482237 97.498944 \nL 143.212601 93.608043 \nL 143.942964 106.165526 \nL 144.673325 108.010692 \nL 145.403688 82.55808 \nL 146.134052 89.628109 \nL 146.864415 95.177835 \nL 147.594776 86.331789 \nL 148.325138 101.661755 \nL 149.055502 93.029735 \nL 149.785864 95.468758 \nL 150.516225 97.243753 \nL 151.246589 95.31379 \nL 151.976951 86.696197 \nL 152.707315 107.661409 \nL 153.437676 98.117371 \nL 154.168039 98.909506 \nL 154.898401 86.163041 \nL 155.628763 77.886059 \nL 156.359127 84.388744 \nL 157.08949 81.305826 \nL 157.819852 102.007275 \nL 158.550215 100.687192 \nL 159.280577 102.151553 \nL 160.010938 95.15952 \nL 160.741303 98.447616 \nL 161.471663 92.133864 \nL 162.202026 108.678234 \nL 162.932391 93.864006 \nL 163.662751 90.962844 \nL 164.393114 100.973182 \nL 165.123477 97.47425 \nL 165.853839 91.392489 \nL 166.584201 101.698036 \nL 167.314566 97.602032 \nL 168.044928 98.064893 \nL 168.775289 90.507134 \nL 169.505653 86.965093 \nL 170.236016 105.295173 \nL 170.966377 116.945921 \nL 171.696739 119.420777 \nL 172.427103 100.75193 \nL 173.157465 103.027538 \nL 173.887828 103.546441 \nL 174.618191 82.922788 \nL 175.348552 113.259178 \nL 176.078916 120.037809 \nL 176.809277 90.414537 \nL 177.539639 108.401414 \nL 178.270003 112.890483 \nL 179.000366 115.81163 \nL 179.730729 110.334791 \nL 180.461091 107.619671 \nL 181.191454 116.274143 \nL 181.921816 100.659283 \nL 182.652178 111.969445 \nL 183.38254 113.340213 \nL 184.112904 106.246511 \nL 184.843266 122.071957 \nL 185.57363 112.624752 \nL 186.30399 131.382483 \nL 187.034354 125.930538 \nL 187.764717 126.070144 \nL 188.495079 116.039809 \nL 189.955805 124.737091 \nL 190.686165 121.707125 \nL 191.416529 113.919867 \nL 192.877254 135.066062 \nL 193.607617 116.13273 \nL 194.337978 137.544768 \nL 195.068341 124.333212 \nL 195.798703 135.284323 \nL 196.529067 130.023141 \nL 197.259429 126.56211 \nL 197.989792 131.6563 \nL 198.720154 127.997678 \nL 199.450516 130.172092 \nL 200.18088 151.157238 \nL 200.911242 124.26663 \nL 202.371966 144.56405 \nL 203.10233 132.103064 \nL 203.832694 147.504858 \nL 204.563055 135.58175 \nL 205.293418 147.151738 \nL 206.023779 140.808632 \nL 206.754141 146.92691 \nL 207.484504 152.097339 \nL 208.945231 155.623657 \nL 209.675592 154.868215 \nL 210.405956 140.819596 \nL 211.136317 144.881163 \nL 211.866679 139.569609 \nL 212.597042 142.733063 \nL 213.327405 155.852259 \nL 214.057769 156.823134 \nL 214.78813 153.560915 \nL 215.518491 154.861711 \nL 216.248855 165.531866 \nL 216.979219 180.356198 \nL 217.709581 151.569615 \nL 218.439942 157.826503 \nL 219.170305 170.967427 \nL 219.900667 167.795712 \nL 220.631031 167.716957 \nL 221.361392 164.119298 \nL 222.091754 168.80642 \nL 222.822118 167.977306 \nL 223.55248 176.572098 \nL 225.013206 161.427302 \nL 225.74357 176.404421 \nL 226.47393 165.087108 \nL 227.204294 165.827512 \nL 227.934655 179.186124 \nL 228.665018 164.846171 \nL 229.39538 181.640149 \nL 230.125743 183.412104 \nL 230.856106 186.830612 \nL 231.586467 183.167566 \nL 232.316832 184.921356 \nL 233.047193 184.934961 \nL 233.777555 177.013617 \nL 234.507918 187.422015 \nL 235.238282 181.924943 \nL 235.968644 188.724406 \nL 236.699005 171.117636 \nL 237.429369 199.580503 \nL 238.15973 196.613905 \nL 238.890094 187.776369 \nL 239.620456 191.292856 \nL 241.081182 179.252956 \nL 241.811545 190.862713 \nL 242.541906 178.337026 \nL 243.27227 191.268399 \nL 244.002632 199.904506 \nL 244.732993 204.495928 \nL 245.463357 196.234059 \nL 246.193719 197.005786 \nL 246.924083 194.142138 \nL 247.654445 199.326272 \nL 248.384806 197.797173 \nL 249.115171 201.8366 \nL 249.845534 196.499055 \nL 250.575896 216.096615 \nL 251.306256 191.640146 \nL 252.036619 203.632551 \nL 252.766981 196.438341 \nL 253.497346 211.886222 \nL 254.227708 202.36851 \nL 254.958071 208.806356 \nL 255.688434 210.326485 \nL 256.418795 214.995366 \nL 257.149156 212.089233 \nL 257.879519 202.766309 \nL 258.609883 210.257274 \nL 259.340246 192.516181 \nL 260.070608 219.084817 \nL 260.800971 221.951891 \nL 261.531332 210.826637 \nL 262.261694 209.009691 \nL 262.992058 202.528362 \nL 263.72242 225.85079 \nL 264.452782 219.823763 \nL 265.183146 210.139596 \nL 265.913507 211.83246 \nL 266.64387 211.323948 \nL 267.374232 216.663673 \nL 268.104595 208.217133 \nL 268.834958 213.45448 \nL 269.565322 196.644206 \nL 270.295685 221.107278 \nL 271.026045 221.515568 \nL 271.75641 212.251739 \nL 272.486769 208.757628 \nL 273.217133 228.178104 \nL 273.947494 224.191467 \nL 274.677857 216.040274 \nL 275.408221 209.205576 \nL 276.138583 208.656895 \nL 276.868945 212.692148 \nL 277.599308 228.757435 \nL 278.329672 231.285143 \nL 279.060033 233.372592 \nL 279.790395 236.324538 \nL 280.520759 223.07072 \nL 281.25112 233.427138 \nL 281.981484 224.103181 \nL 282.711846 236.043843 \nL 283.442208 228.2482 \nL 284.172571 223.564393 \nL 284.902935 223.488989 \nL 285.633296 228.255439 \nL 286.363658 245.721525 \nL 287.094021 227.514911 \nL 287.824383 236.963118 \nL 288.554747 222.129298 \nL 289.28511 221.526719 \nL 290.015472 218.862856 \nL 290.745834 241.808129 \nL 291.476195 224.981757 \nL 292.206561 239.380257 \nL 292.936924 243.291815 \nL 293.667286 231.990754 \nL 294.397646 231.484952 \nL 295.12801 251.950012 \nL 295.858371 223.194639 \nL 296.588734 238.866948 \nL 297.319096 241.912114 \nL 298.049461 241.19529 \nL 298.779823 225.162853 \nL 299.510186 256.336212 \nL 300.240549 251.687496 \nL 300.970911 221.523006 \nL 301.701272 233.555356 \nL 302.431636 237.066088 \nL 303.161997 234.236684 \nL 303.89236 253.624729 \nL 304.622723 229.695766 \nL 305.353084 245.913902 \nL 306.083447 243.982543 \nL 306.813811 232.239784 \nL 307.544173 241.173804 \nL 308.274536 247.511428 \nL 309.004897 243.552886 \nL 309.73526 249.157837 \nL 310.465624 236.11901 \nL 311.195985 248.913655 \nL 311.926348 216.605015 \nL 312.65671 240.275504 \nL 313.387074 237.421214 \nL 314.117436 236.735674 \nL 314.8478 258.111026 \nL 315.578159 253.567927 \nL 316.308522 244.456543 \nL 317.038885 214.592185 \nL 317.769249 253.393018 \nL 318.499612 255.124418 \nL 319.229974 232.694958 \nL 319.960335 261.153788 \nL 320.690697 237.575733 \nL 321.421062 236.211931 \nL 322.151423 248.469202 \nL 322.881786 255.976706 \nL 323.612149 229.112175 \nL 324.342511 247.91084 \nL 325.072874 232.601401 \nL 325.803236 236.392995 \nL 326.533598 242.234448 \nL 327.263961 240.492058 \nL 327.994325 250.11895 \nL 328.724686 238.59158 \nL 329.45505 250.9332 \nL 330.185412 252.27024 \nL 330.915775 243.599646 \nL 331.646137 256.002023 \nL 332.3765 233.362911 \nL 333.106863 240.794357 \nL 333.837224 245.581502 \nL 334.567587 232.181406 \nL 335.297949 235.093239 \nL 336.028313 252.368805 \nL 336.758674 232.220846 \nL 338.219398 263.423434 \nL 338.949763 220.968868 \nL 339.680125 253.229503 \nL 340.410488 245.693772 \nL 341.871211 256.638778 \nL 342.601576 255.043034 \nL 343.331936 208.326887 \nL 344.062301 266.744106 \nL 344.792661 245.144967 \nL 345.523024 254.016155 \nL 346.253387 252.472155 \nL 346.983749 235.724002 \nL 347.714113 239.06733 \nL 348.444474 232.579859 \nL 349.174838 245.645424 \nL 349.9052 242.137652 \nL 350.635562 242.669992 \nL 351.365925 256.351007 \nL 352.096287 221.976635 \nL 352.82665 261.620835 \nL 353.557012 221.460797 \nL 354.287376 209.01551 \nL 355.017738 221.385767 \nL 355.748101 253.476869 \nL 356.478462 231.957532 \nL 357.208826 251.725883 \nL 357.939188 245.239657 \nL 358.669549 250.582927 \nL 359.399914 217.112492 \nL 360.130277 222.449289 \nL 360.86064 244.396776 \nL 361.591 234.40836 \nL 362.321364 218.252614 \nL 363.051725 247.844968 \nL 363.78209 248.034567 \nL 364.51245 215.857871 \nL 365.242814 238.491738 \nL 365.973175 225.314806 \nL 366.703538 267.355942 \nL 367.4339 226.981954 \nL 368.164263 259.086648 \nL 368.894626 274.411636 \nL 369.624989 235.752845 \nL 370.355352 260.534899 \nL 371.085713 204.129215 \nL 371.816078 248.02022 \nL 372.54644 240.410538 \nL 373.276801 208.889734 \nL 374.007165 226.932553 \nL 374.737526 216.150376 \nL 375.467888 243.049557 \nL 376.198252 197.32027 \nL 376.928614 218.689311 \nL 377.658978 220.289079 \nL 378.389339 194.190455 \nL 379.119702 159.60678 \nL 379.850065 242.738998 \nL 380.580426 113.826796 \nL 381.310789 215.56448 \nL 382.041153 168.559053 \nL 382.771516 236.562995 \nL 383.501877 237.680366 \nL 384.232241 200.975092 \nL 384.962604 233.81274 \nL 385.692965 224.500232 \nL 386.423327 244.996527 \nL 387.15369 200.262099 \nL 387.884053 184.233518 \nL 388.614415 242.252613 \nL 389.344778 194.12315 \nL 390.075141 162.116535 \nL 390.805504 218.423966 \nL 391.535865 147.977101 \nL 392.266228 241.766702 \nL 393.726953 175.368846 \nL 394.457316 204.690242 \nL 395.187678 192.393719 \nL 395.91804 121.986337 \nL 396.648403 212.751853 \nL 397.378765 184.902181 \nL 398.109128 187.756148 \nL 398.839491 87.897668 \nL 399.569853 196.074444 \nL 400.300216 184.425664 \nL 401.030577 156.456259 \nL 401.760941 181.152357 \nL 402.491303 165.861152 \nL 403.221667 178.20517 \nL 403.952028 182.848136 \nL 404.682391 137.810997 \nL 405.412755 176.418226 \nL 406.143116 95.082671 \nL 406.87348 222.428358 \nL 407.60384 53.238216 \nL 408.334205 213.736732 \nL 409.064567 142.712543 \nL 409.794929 158.299979 \nL 410.525291 176.946474 \nL 411.255653 100.438605 \nL 411.986016 154.982429 \nL 412.716379 19.924364 \nL 413.446741 198.517255 \nL 414.177105 74.441973 \nL 414.907467 151.974341 \nL 415.63783 144.483763 \nL 415.63783 144.483763 \n\" clip-path=\"url(#p7a20f35ba6)\" style=\"fill: none; stroke: #008fd5; stroke-width: 4\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 32.964375 287.136 \nL 32.964375 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 433.860375 287.136 \nL 433.860375 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 32.964375 287.136 \nL 433.860375 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 32.964375 7.2 \nL 433.860375 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7a20f35ba6\">\n   <rect x=\"32.964375\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(lr, train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 256])\n",
      "tensor(0.0884)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"463.250063pt\" height=\"311.385375pt\" viewBox=\"0 0 463.250063 311.385375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-27T04:02:38.256108</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 311.385375 \nL 463.250063 311.385375 \nL 463.250063 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 46.33 287.136 \nL 447.226 287.136 \nL 447.226 7.2 \nL 46.33 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 61.745223 287.136 \nL 61.745223 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- −0.4 -->\n      <g transform=\"translate(44.747254 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 109.641805 287.136 \nL 109.641805 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- −0.3 -->\n      <g transform=\"translate(92.643836 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 157.538386 287.136 \nL 157.538386 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- −0.2 -->\n      <g transform=\"translate(140.540417 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 205.434968 287.136 \nL 205.434968 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- −0.1 -->\n      <g transform=\"translate(188.436999 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 253.331549 287.136 \nL 253.331549 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 0.0 -->\n      <g transform=\"translate(242.199362 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 301.228131 287.136 \nL 301.228131 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 0.1 -->\n      <g transform=\"translate(290.095944 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 349.124713 287.136 \nL 349.124713 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 0.2 -->\n      <g transform=\"translate(337.992525 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 397.021294 287.136 \nL 397.021294 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_8\">\n      <!-- 0.3 -->\n      <g transform=\"translate(385.889107 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 444.917876 287.136 \nL 444.917876 7.2 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(433.785688 301.273812) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 46.33 287.136 \nL 447.226 287.136 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(33.9225 292.454906) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 46.33 237.534937 \nL 447.226 237.534937 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_22\"/>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(16.1075 242.853843) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 46.33 187.933874 \nL 447.226 187.933874 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_24\"/>\n     <g id=\"text_12\">\n      <!-- 400 -->\n      <g transform=\"translate(16.1075 193.25278) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 46.33 138.332811 \nL 447.226 138.332811 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_26\"/>\n     <g id=\"text_13\">\n      <!-- 600 -->\n      <g transform=\"translate(16.1075 143.651717) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 46.33 88.731748 \nL 447.226 88.731748 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_28\"/>\n     <g id=\"text_14\">\n      <!-- 800 -->\n      <g transform=\"translate(16.1075 94.050654) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_29\">\n      <path d=\"M 46.33 39.130684 \nL 447.226 39.130684 \n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_30\"/>\n     <g id=\"text_15\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 44.449591) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 64.552545 287.136 \nL 68.197058 287.136 \nL 68.197058 286.887995 \nL 64.552545 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 68.197058 287.136 \nL 71.841556 287.136 \nL 71.841556 287.136 \nL 68.197058 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 71.841556 287.136 \nL 75.486069 287.136 \nL 75.486069 287.136 \nL 71.841556 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 75.486069 287.136 \nL 79.130582 287.136 \nL 79.130582 287.136 \nL 75.486069 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 79.130582 287.136 \nL 82.775094 287.136 \nL 82.775094 287.136 \nL 79.130582 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 82.775094 287.136 \nL 86.419607 287.136 \nL 86.419607 286.887995 \nL 82.775094 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 86.419607 287.136 \nL 90.064106 287.136 \nL 90.064106 286.887995 \nL 86.419607 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 90.064106 287.136 \nL 93.708618 287.136 \nL 93.708618 287.136 \nL 90.064106 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 93.708618 287.136 \nL 97.353131 287.136 \nL 97.353131 286.639989 \nL 93.708618 286.639989 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 97.353131 287.136 \nL 100.997629 287.136 \nL 100.997629 286.639989 \nL 97.353131 286.639989 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 100.997629 287.136 \nL 104.642142 287.136 \nL 104.642142 286.639989 \nL 100.997629 286.639989 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 104.642142 287.136 \nL 108.286655 287.136 \nL 108.286655 286.639989 \nL 104.642142 286.639989 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 108.286655 287.136 \nL 111.931167 287.136 \nL 111.931167 286.887995 \nL 108.286655 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 111.931167 287.136 \nL 115.57568 287.136 \nL 115.57568 285.151957 \nL 111.931167 285.151957 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 115.57568 287.136 \nL 119.220178 287.136 \nL 119.220178 285.151957 \nL 115.57568 285.151957 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 119.220178 287.136 \nL 122.864691 287.136 \nL 122.864691 285.895973 \nL 119.220178 285.895973 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 122.864691 287.136 \nL 126.509204 287.136 \nL 126.509204 284.655947 \nL 122.864691 284.655947 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 126.509204 287.136 \nL 130.153702 287.136 \nL 130.153702 283.663926 \nL 126.509204 283.663926 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 130.153702 287.136 \nL 133.798215 287.136 \nL 133.798215 282.423899 \nL 130.153702 282.423899 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 133.798215 287.136 \nL 137.442727 287.136 \nL 137.442727 282.423899 \nL 133.798215 282.423899 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 137.442727 287.136 \nL 141.08724 287.136 \nL 141.08724 281.183872 \nL 137.442727 281.183872 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 141.08724 287.136 \nL 144.731745 287.136 \nL 144.731745 276.223766 \nL 141.08724 276.223766 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 144.731745 287.136 \nL 148.376251 287.136 \nL 148.376251 276.471771 \nL 144.731745 276.471771 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 148.376251 287.136 \nL 152.020764 287.136 \nL 152.020764 275.231745 \nL 148.376251 275.231745 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 152.020764 287.136 \nL 155.665276 287.136 \nL 155.665276 267.295575 \nL 152.020764 267.295575 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 155.665276 287.136 \nL 159.309782 287.136 \nL 159.309782 260.103421 \nL 155.665276 260.103421 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 159.309782 287.136 \nL 162.954287 287.136 \nL 162.954287 265.559538 \nL 159.309782 265.559538 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 162.954287 287.136 \nL 166.5988 287.136 \nL 166.5988 263.32749 \nL 162.954287 263.32749 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 166.5988 287.136 \nL 170.243313 287.136 \nL 170.243313 250.679219 \nL 166.5988 250.679219 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 170.243313 287.136 \nL 173.887818 287.136 \nL 173.887818 244.479086 \nL 170.243313 244.479086 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 173.887818 287.136 \nL 177.532324 287.136 \nL 177.532324 243.487064 \nL 173.887818 243.487064 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 177.532324 287.136 \nL 181.176836 287.136 \nL 181.176836 232.822836 \nL 177.532324 232.822836 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 181.176836 287.136 \nL 184.821349 287.136 \nL 184.821349 218.686533 \nL 181.176836 218.686533 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 184.821349 287.136 \nL 188.465855 287.136 \nL 188.465855 216.20648 \nL 184.821349 216.20648 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 188.465855 287.136 \nL 192.11036 287.136 \nL 192.11036 207.030283 \nL 188.465855 207.030283 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 192.11036 287.136 \nL 195.754873 287.136 \nL 195.754873 189.669911 \nL 192.11036 189.669911 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 195.754873 287.136 \nL 199.399382 287.136 \nL 199.399382 177.269645 \nL 195.754873 177.269645 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 199.399382 287.136 \nL 203.043891 287.136 \nL 203.043891 160.653289 \nL 199.399382 160.653289 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_41\">\n    <path d=\"M 203.043891 287.136 \nL 206.6884 287.136 \nL 206.6884 155.197172 \nL 203.043891 155.197172 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_42\">\n    <path d=\"M 206.6884 287.136 \nL 210.332909 287.136 \nL 210.332909 138.828821 \nL 206.6884 138.828821 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_43\">\n    <path d=\"M 210.332909 287.136 \nL 213.977418 287.136 \nL 213.977418 121.96446 \nL 210.332909 121.96446 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_44\">\n    <path d=\"M 213.977418 287.136 \nL 217.621927 287.136 \nL 217.621927 107.332146 \nL 213.977418 107.332146 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 217.621927 287.136 \nL 221.266436 287.136 \nL 221.266436 107.580151 \nL 217.621927 107.580151 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 221.266436 287.136 \nL 224.910945 287.136 \nL 224.910945 88.483742 \nL 221.266436 88.483742 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_47\">\n    <path d=\"M 224.910945 287.136 \nL 228.555455 287.136 \nL 228.555455 74.099434 \nL 224.910945 74.099434 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_48\">\n    <path d=\"M 228.555455 287.136 \nL 232.199964 287.136 \nL 232.199964 48.802892 \nL 228.555455 48.802892 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_49\">\n    <path d=\"M 232.199964 287.136 \nL 235.844473 287.136 \nL 235.844473 40.618716 \nL 232.199964 40.618716 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_50\">\n    <path d=\"M 235.844473 287.136 \nL 239.488982 287.136 \nL 239.488982 55.747041 \nL 235.844473 55.747041 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 239.488982 287.136 \nL 243.133491 287.136 \nL 243.133491 36.154621 \nL 239.488982 36.154621 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 243.133491 287.136 \nL 246.778 287.136 \nL 246.778 38.634674 \nL 243.133491 38.634674 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_53\">\n    <path d=\"M 246.778 287.136 \nL 250.422509 287.136 \nL 250.422509 33.674567 \nL 246.778 33.674567 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_54\">\n    <path d=\"M 250.422509 287.136 \nL 254.067018 287.136 \nL 254.067018 29.458477 \nL 250.422509 29.458477 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_55\">\n    <path d=\"M 254.067018 287.136 \nL 257.711527 287.136 \nL 257.711527 26.234408 \nL 254.067018 26.234408 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_56\">\n    <path d=\"M 257.711527 287.136 \nL 261.356036 287.136 \nL 261.356036 20.530286 \nL 257.711527 20.530286 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 261.356036 287.136 \nL 265.000545 287.136 \nL 265.000545 32.186536 \nL 261.356036 32.186536 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 265.000545 287.136 \nL 268.645055 287.136 \nL 268.645055 40.370711 \nL 265.000545 40.370711 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 268.645055 287.136 \nL 272.289564 287.136 \nL 272.289564 42.850764 \nL 268.645055 42.850764 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 272.289564 287.136 \nL 275.934073 287.136 \nL 275.934073 53.514993 \nL 272.289564 53.514993 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_61\">\n    <path d=\"M 275.934073 287.136 \nL 279.578582 287.136 \nL 279.578582 53.514993 \nL 275.934073 53.514993 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_62\">\n    <path d=\"M 279.578582 287.136 \nL 283.223091 287.136 \nL 283.223091 76.579487 \nL 279.578582 76.579487 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_63\">\n    <path d=\"M 283.223091 287.136 \nL 286.8676 287.136 \nL 286.8676 85.755684 \nL 283.223091 85.755684 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_64\">\n    <path d=\"M 286.8676 287.136 \nL 290.512109 287.136 \nL 290.512109 99.395976 \nL 286.8676 99.395976 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_65\">\n    <path d=\"M 290.512109 287.136 \nL 294.156618 287.136 \nL 294.156618 123.700497 \nL 290.512109 123.700497 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_66\">\n    <path d=\"M 294.156618 287.136 \nL 297.801127 287.136 \nL 297.801127 119.236401 \nL 294.156618 119.236401 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_67\">\n    <path d=\"M 297.801127 287.136 \nL 301.445636 287.136 \nL 301.445636 142.05289 \nL 297.801127 142.05289 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_68\">\n    <path d=\"M 301.445636 287.136 \nL 305.090145 287.136 \nL 305.090145 160.653289 \nL 301.445636 160.653289 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_69\">\n    <path d=\"M 305.090145 287.136 \nL 308.734655 287.136 \nL 308.734655 171.565523 \nL 305.090145 171.565523 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_70\">\n    <path d=\"M 308.734655 287.136 \nL 312.379164 287.136 \nL 312.379164 189.669911 \nL 308.734655 189.669911 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_71\">\n    <path d=\"M 312.379164 287.136 \nL 316.023676 287.136 \nL 316.023676 194.630017 \nL 312.379164 194.630017 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_72\">\n    <path d=\"M 316.023676 287.136 \nL 319.668182 287.136 \nL 319.668182 201.574166 \nL 316.023676 201.574166 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_73\">\n    <path d=\"M 319.668182 287.136 \nL 323.312687 287.136 \nL 323.312687 211.494379 \nL 319.668182 211.494379 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_74\">\n    <path d=\"M 323.312687 287.136 \nL 326.9572 287.136 \nL 326.9572 224.390655 \nL 323.312687 224.390655 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_75\">\n    <path d=\"M 326.9572 287.136 \nL 330.601713 287.136 \nL 330.601713 229.846772 \nL 326.9572 229.846772 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_76\">\n    <path d=\"M 330.601713 287.136 \nL 334.246218 287.136 \nL 334.246218 237.286932 \nL 330.601713 237.286932 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_77\">\n    <path d=\"M 334.246218 287.136 \nL 337.890724 287.136 \nL 337.890724 254.399298 \nL 334.246218 254.399298 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_78\">\n    <path d=\"M 337.890724 287.136 \nL 341.535236 287.136 \nL 341.535236 249.439192 \nL 337.890724 249.439192 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_79\">\n    <path d=\"M 341.535236 287.136 \nL 345.179749 287.136 \nL 345.179749 262.583474 \nL 341.535236 262.583474 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_80\">\n    <path d=\"M 345.179749 287.136 \nL 348.824255 287.136 \nL 348.824255 261.591452 \nL 345.179749 261.591452 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_81\">\n    <path d=\"M 348.824255 287.136 \nL 352.46876 287.136 \nL 352.46876 268.535601 \nL 348.824255 268.535601 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_82\">\n    <path d=\"M 352.46876 287.136 \nL 356.113273 287.136 \nL 356.113273 272.255681 \nL 352.46876 272.255681 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_83\">\n    <path d=\"M 356.113273 287.136 \nL 359.757785 287.136 \nL 359.757785 276.719777 \nL 356.113273 276.719777 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_84\">\n    <path d=\"M 359.757785 287.136 \nL 363.402291 287.136 \nL 363.402291 278.207809 \nL 359.757785 278.207809 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_85\">\n    <path d=\"M 363.402291 287.136 \nL 367.046796 287.136 \nL 367.046796 279.943846 \nL 363.402291 279.943846 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_86\">\n    <path d=\"M 367.046796 287.136 \nL 370.691309 287.136 \nL 370.691309 280.439856 \nL 367.046796 280.439856 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_87\">\n    <path d=\"M 370.691309 287.136 \nL 374.335822 287.136 \nL 374.335822 280.935867 \nL 370.691309 280.935867 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_88\">\n    <path d=\"M 374.335822 287.136 \nL 377.980334 287.136 \nL 377.980334 281.679883 \nL 374.335822 281.679883 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_89\">\n    <path d=\"M 377.980334 287.136 \nL 381.624833 287.136 \nL 381.624833 283.41592 \nL 377.980334 283.41592 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_90\">\n    <path d=\"M 381.624833 287.136 \nL 385.269345 287.136 \nL 385.269345 284.159936 \nL 381.624833 284.159936 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_91\">\n    <path d=\"M 385.269345 287.136 \nL 388.913858 287.136 \nL 388.913858 285.895973 \nL 385.269345 285.895973 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_92\">\n    <path d=\"M 388.913858 287.136 \nL 392.558356 287.136 \nL 392.558356 286.143979 \nL 388.913858 286.143979 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_93\">\n    <path d=\"M 392.558356 287.136 \nL 396.202869 287.136 \nL 396.202869 286.887995 \nL 392.558356 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_94\">\n    <path d=\"M 396.202869 287.136 \nL 399.847382 287.136 \nL 399.847382 286.391984 \nL 396.202869 286.391984 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_95\">\n    <path d=\"M 399.847382 287.136 \nL 403.491894 287.136 \nL 403.491894 286.887995 \nL 399.847382 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_96\">\n    <path d=\"M 403.491894 287.136 \nL 407.136407 287.136 \nL 407.136407 287.136 \nL 403.491894 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_97\">\n    <path d=\"M 407.136407 287.136 \nL 410.780906 287.136 \nL 410.780906 286.887995 \nL 407.136407 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_98\">\n    <path d=\"M 410.780906 287.136 \nL 414.425418 287.136 \nL 414.425418 287.136 \nL 410.780906 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_99\">\n    <path d=\"M 414.425418 287.136 \nL 418.069931 287.136 \nL 418.069931 287.136 \nL 414.425418 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_100\">\n    <path d=\"M 418.069931 287.136 \nL 421.714429 287.136 \nL 421.714429 286.887995 \nL 418.069931 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_101\">\n    <path d=\"M 421.714429 287.136 \nL 425.358942 287.136 \nL 425.358942 287.136 \nL 421.714429 287.136 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_102\">\n    <path d=\"M 425.358942 287.136 \nL 429.003455 287.136 \nL 429.003455 286.887995 \nL 425.358942 286.887995 \nz\n\" clip-path=\"url(#pcfcbe11717)\" style=\"fill: #008fd5\"/>\n   </g>\n   <g id=\"patch_103\">\n    <path d=\"M 46.33 287.136 \nL 46.33 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_104\">\n    <path d=\"M 447.226 287.136 \nL 447.226 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_105\">\n    <path d=\"M 46.33 287.136 \nL 447.226 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_106\">\n    <path d=\"M 46.33 7.2 \nL 447.226 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pcfcbe11717\">\n   <rect x=\"46.33\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BNLeNetScratch()\n",
    "for batch in data.train_dl:\n",
    "    x, y = batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.init(x)\n",
    "\n",
    "print (model.state_dict()['model.9.weight'].shape)\n",
    "print (model.state_dict()['model.9.weight'].std())\n",
    "\n",
    "plt.hist(model.state_dict()['model.9.weight'].flatten(),100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000, 469, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Datasets\n",
    "class FashionMNIST:\n",
    "    def __init__(self) -> None:\n",
    "        # Get datasets\n",
    "        transforms = Compose([ToTensor(), Resize(size = (96, 96))])\n",
    "        self.train = datasets.FashionMNIST(root='data', train=True, transform=transforms)\n",
    "        self.val = datasets.FashionMNIST(root='data', train=False, transform=transforms)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.train_dl = torch.utils.data.DataLoader(self.train, batch_size = 128, shuffle=True)\n",
    "        self.val_dl = torch.utils.data.DataLoader(self.val, batch_size = 128, shuffle=True)\n",
    "\n",
    "data = FashionMNIST()\n",
    "len(data.train), len(data.val), len(data.train_dl), len(data.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Residual(nn.Module):  #@save\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(MyModule):\n",
    "\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model = nn.Sequential(self.b1())\n",
    "        for i, b in enumerate(arch):\n",
    "            self.model.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
    "        self.model.add_module('last', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "\n",
    "    def init(self, x):\n",
    "        logits = self.model(x)\n",
    "        self.model.apply(self.init_cnn)\n",
    "        return logits\n",
    "\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def block(self, num_residuals, num_channels, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels))\n",
    "        return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0/ 10 with train loss 2.4354, val loss 2.4354, and accuracy 0.0859\n",
      "step   0 with loss 5.8961\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[1;32m     32\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 34\u001b[0m train_logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     36\u001b[0m train_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss_fn(train_logits, y)\n\u001b[1;32m     37\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mMyModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> 7\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mResidual.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> 17\u001b[0m     Y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(X)))\n\u001b[1;32m     18\u001b[0m     Y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(Y))\n\u001b[1;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = ResNet(((2, 64), (2, 128), (2, 256), (2, 512))).to(device)\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "# Initial step\n",
    "for batch in data.train_dl:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    break\n",
    "\n",
    "init_logits = model.init(x)\n",
    "mtrain_loss = model.loss_fn(init_logits, y).item()\n",
    "val_loss = mtrain_loss\n",
    "val_acc = model.accuracy(init_logits, y)\n",
    "epoch = 0\n",
    "print(f'epoch {epoch:>3d}/{max_epochs:>3d} with train loss {mtrain_loss:.4f}, val loss {val_loss:.4f}, and accuracy {val_acc:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "lr = torch.logspace(-6, -1, 500)\n",
    "\n",
    "model.optimizer = torch.optim.AdamW(model.parameters(), lr=1.0e-5)\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    train_losses = []\n",
    "    for step, batch in enumerate(data.train_dl):\n",
    "\n",
    "        if step == 500:\n",
    "            break\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        train_logits = model(x)\n",
    "\n",
    "        train_loss = model.loss_fn(train_logits, y)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        model.optimizer = torch.optim.AdamW(model.parameters(), lr=lr[step])\n",
    "        model.optimizer.zero_grad(set_to_none=True)\n",
    "        train_loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            mtrain_loss = torch.tensor(train_losses)[-50:].mean().item()\n",
    "            print (f'step {step:>3d} with loss {mtrain_loss:.4f}')\n",
    "\n",
    "    break\n",
    "    #with torch.no_grad():\n",
    "    for batch in data.val_dl:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        break\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    val_logits = model(x)\n",
    "    val_loss = model.loss_fn(val_logits, y).item()\n",
    "    val_acc = model.accuracy(val_logits, y).item()\n",
    "\n",
    "    mtrain_loss = torch.tensor(train_losses).mean().item()\n",
    "    print(f'epoch {epoch:>3d}/{max_epochs:>3d} with train loss {mtrain_loss:.4f}, val loss {val_loss:.4f}, and accuracy {val_acc:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x167c5b370>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"427.7035pt\" height=\"311.385375pt\" viewBox=\"0 0 427.7035 311.385375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-01-27T05:45:26.096492</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 311.385375 \nL 427.7035 311.385375 \nL 427.7035 0 \nL 0 0 \nz\n\" style=\"fill: #f0f0f0\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 19.6075 287.136 \nL 420.5035 287.136 \nL 420.5035 7.2 \nL 19.6075 7.2 \nz\n\" style=\"fill: #f0f0f0\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 37.830046 287.136 \nL 37.830046 7.2 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- $\\mathdefault{10^{-6}}$ -->\n      <g transform=\"translate(21.380046 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 180.466127 287.136 \nL 180.466127 7.2 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- $\\mathdefault{10^{-5}}$ -->\n      <g transform=\"translate(164.016127 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 323.102208 287.136 \nL 323.102208 7.2 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- $\\mathdefault{10^{-4}}$ -->\n      <g transform=\"translate(306.652208 301.273812) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\"/>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_8\"/>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_9\"/>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_10\"/>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_11\"/>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_12\"/>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_13\"/>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_14\"/>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_15\"/>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_16\"/>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_17\"/>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_18\"/>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_19\"/>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_20\"/>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_21\"/>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_22\"/>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_23\"/>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_24\"/>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_25\"/>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_26\"/>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_27\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_28\">\n      <path d=\"M 19.6075 236.540972 \nL 420.5035 236.540972 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_29\"/>\n     <g id=\"text_4\">\n      <!-- 1 -->\n      <g transform=\"translate(7.2 241.859878) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_30\">\n      <path d=\"M 19.6075 185.587565 \nL 420.5035 185.587565 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_31\"/>\n     <g id=\"text_5\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 190.906471) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_32\">\n      <path d=\"M 19.6075 134.634158 \nL 420.5035 134.634158 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_33\"/>\n     <g id=\"text_6\">\n      <!-- 3 -->\n      <g transform=\"translate(7.2 139.953064) scale(0.14 -0.14)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_34\">\n      <path d=\"M 19.6075 83.680751 \nL 420.5035 83.680751 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_35\"/>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 88.999657) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_36\">\n      <path d=\"M 19.6075 32.727344 \nL 420.5035 32.727344 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #cbcbcb\"/>\n     </g>\n     <g id=\"line2d_37\"/>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(7.2 38.04625) scale(0.14 -0.14)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 37.830045 56.931495 \nL 39.259267 59.82127 \nL 40.688483 57.167851 \nL 42.117701 76.48513 \nL 43.546925 30.948672 \nL 44.976142 35.918954 \nL 46.405364 73.967165 \nL 47.834581 32.012517 \nL 49.263797 55.731662 \nL 50.693021 47.713266 \nL 52.122238 36.568811 \nL 53.551457 53.673143 \nL 54.980674 64.184868 \nL 56.409896 58.81542 \nL 57.839116 65.063721 \nL 59.268337 66.028922 \nL 60.697553 68.955652 \nL 62.126773 61.615905 \nL 63.555991 82.117005 \nL 64.985214 46.920034 \nL 66.414432 19.924364 \nL 69.272871 93.486992 \nL 70.702087 81.594874 \nL 72.13131 32.265808 \nL 73.560527 73.479996 \nL 74.989746 60.006846 \nL 77.848181 25.963958 \nL 79.277401 41.844962 \nL 80.706626 76.448321 \nL 82.135844 71.253929 \nL 83.565063 77.422318 \nL 84.994282 75.12256 \nL 86.423501 53.317588 \nL 87.852718 81.244835 \nL 89.281936 46.423584 \nL 90.711158 61.804907 \nL 92.140375 87.316184 \nL 93.569596 100.678081 \nL 94.998816 99.868559 \nL 96.428036 103.063072 \nL 97.857254 121.363312 \nL 99.286471 72.180766 \nL 100.715694 86.233825 \nL 102.144913 88.503687 \nL 103.574132 57.082668 \nL 105.003352 100.657453 \nL 106.43257 100.803341 \nL 107.861787 92.505936 \nL 109.291006 142.983229 \nL 110.720226 127.637149 \nL 112.149446 88.540824 \nL 113.578665 116.449666 \nL 115.007885 129.898774 \nL 116.437104 110.073128 \nL 117.866323 102.75215 \nL 119.295543 98.547012 \nL 120.724761 129.740957 \nL 122.153978 106.10838 \nL 123.583202 131.348606 \nL 125.012417 137.232788 \nL 126.441642 129.148584 \nL 127.870862 116.964447 \nL 129.300079 126.479592 \nL 130.729297 118.419976 \nL 132.158516 120.113866 \nL 133.587734 146.944989 \nL 135.016956 111.199428 \nL 136.446175 144.352664 \nL 137.875394 144.812657 \nL 139.304614 153.345458 \nL 140.733831 149.205897 \nL 142.163049 150.515308 \nL 143.592272 162.020941 \nL 145.02149 160.375341 \nL 146.450709 163.682808 \nL 147.879928 153.714716 \nL 149.309149 156.604151 \nL 150.738368 165.348745 \nL 152.167586 187.700028 \nL 153.596807 168.619391 \nL 155.026025 178.731815 \nL 156.455244 177.595506 \nL 157.884461 180.360821 \nL 159.313681 179.434846 \nL 160.7429 185.052896 \nL 162.172119 173.992022 \nL 163.601339 200.125429 \nL 165.030561 200.068399 \nL 166.459781 202.006742 \nL 167.888997 199.496405 \nL 169.318216 218.93216 \nL 170.747433 209.861265 \nL 172.176656 208.364668 \nL 173.605872 208.188379 \nL 175.035097 207.117785 \nL 176.46431 214.181282 \nL 177.89353 212.819804 \nL 179.32275 209.281538 \nL 180.751969 221.836774 \nL 182.181192 223.347103 \nL 183.610407 220.841019 \nL 185.039628 223.248101 \nL 186.468846 228.676803 \nL 187.898066 225.749685 \nL 189.327289 229.856834 \nL 190.756505 223.078488 \nL 192.185723 231.228146 \nL 193.614944 224.632011 \nL 195.044164 232.256774 \nL 196.473383 230.823397 \nL 197.902602 233.263462 \nL 199.331822 234.031334 \nL 200.761041 240.944389 \nL 202.19026 246.176095 \nL 203.61948 241.205765 \nL 205.048696 235.327867 \nL 206.477916 245.85619 \nL 207.907133 224.931665 \nL 209.336357 245.454441 \nL 210.765573 243.271102 \nL 212.194796 233.570745 \nL 213.624011 251.172074 \nL 215.05323 239.082757 \nL 216.482449 243.655815 \nL 217.911672 238.681361 \nL 219.340892 240.688314 \nL 220.770108 246.072134 \nL 222.199328 253.115364 \nL 223.62855 236.81626 \nL 225.05777 239.698396 \nL 226.486987 240.645691 \nL 227.916205 243.001429 \nL 229.345427 238.182299 \nL 232.203862 254.359407 \nL 233.633084 231.567513 \nL 235.062302 249.093018 \nL 236.491523 250.261363 \nL 237.920739 245.24025 \nL 239.34996 243.182909 \nL 240.779179 249.862038 \nL 242.208397 252.342839 \nL 243.637618 251.780491 \nL 245.066839 242.656544 \nL 246.496057 247.735826 \nL 247.925277 251.066226 \nL 249.354495 251.976384 \nL 250.783711 245.888489 \nL 252.212936 255.840502 \nL 253.64215 248.39095 \nL 255.07137 243.281048 \nL 256.500594 250.935727 \nL 257.929808 248.691318 \nL 259.359029 253.544734 \nL 260.788249 247.555254 \nL 262.217467 248.663101 \nL 263.646685 252.858009 \nL 265.075908 253.772583 \nL 266.505127 253.600491 \nL 267.934343 259.739267 \nL 269.363566 262.524929 \nL 270.792785 252.946792 \nL 272.222003 264.226734 \nL 273.651221 258.227172 \nL 275.080443 259.546781 \nL 277.938881 262.790595 \nL 279.368101 261.713884 \nL 280.797316 238.411485 \nL 282.226538 253.853983 \nL 283.655755 254.081182 \nL 285.084974 244.600985 \nL 286.514196 255.295022 \nL 287.943417 259.840802 \nL 289.372636 261.530889 \nL 292.231074 262.189775 \nL 293.660293 254.995288 \nL 295.089511 260.01731 \nL 296.51873 263.988672 \nL 297.947952 255.381848 \nL 299.377169 250.494384 \nL 300.80639 259.859501 \nL 302.235606 259.682975 \nL 303.664827 262.523856 \nL 305.094049 259.119066 \nL 306.523266 263.307171 \nL 307.952486 261.011121 \nL 309.381706 269.391035 \nL 310.810921 257.123499 \nL 312.240143 260.805867 \nL 313.669362 261.796665 \nL 315.09858 255.018741 \nL 316.527801 252.269576 \nL 317.957018 255.860328 \nL 319.386238 256.882025 \nL 320.815456 260.04403 \nL 322.244678 249.662594 \nL 323.673896 260.936755 \nL 325.103117 261.396013 \nL 326.532335 249.662989 \nL 327.961553 274.411636 \nL 329.390774 261.509915 \nL 330.819994 258.404761 \nL 332.249212 252.598893 \nL 333.678429 266.503487 \nL 335.107651 260.154597 \nL 336.536873 262.418541 \nL 337.966089 250.266629 \nL 339.395311 269.850298 \nL 340.824527 250.635009 \nL 342.253744 258.775823 \nL 343.682964 256.777632 \nL 345.112185 269.123127 \nL 346.541407 246.733569 \nL 347.970624 257.869859 \nL 349.399845 255.554742 \nL 350.829061 246.220023 \nL 352.25828 247.195326 \nL 353.687499 261.594558 \nL 355.116719 264.315726 \nL 356.545941 252.994118 \nL 357.975159 262.381033 \nL 359.404375 259.328319 \nL 360.833596 244.137994 \nL 362.262818 258.754181 \nL 363.692036 252.399544 \nL 365.121254 240.50274 \nL 366.550473 243.09782 \nL 367.979691 254.118274 \nL 369.408914 251.917037 \nL 370.83813 257.753112 \nL 372.267348 258.723786 \nL 373.69657 248.382212 \nL 375.125787 255.404739 \nL 376.555007 250.761178 \nL 377.984228 233.859758 \nL 379.41345 255.107696 \nL 380.842664 251.115247 \nL 382.271887 258.450961 \nL 383.701102 246.20041 \nL 385.130324 249.61149 \nL 386.559542 243.968702 \nL 387.988761 261.14757 \nL 389.417981 243.385848 \nL 390.847199 241.925521 \nL 392.276423 238.520548 \nL 393.705639 253.455821 \nL 395.134856 242.898245 \nL 396.564077 237.221571 \nL 397.993299 258.862595 \nL 399.422518 252.932718 \nL 400.851733 256.387805 \nL 402.280955 248.490575 \nL 402.280955 248.490575 \n\" clip-path=\"url(#pa03fd7b439)\" style=\"fill: none; stroke: #008fd5; stroke-width: 4\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 19.6075 287.136 \nL 19.6075 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 420.5035 287.136 \nL 420.5035 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 19.6075 287.136 \nL 420.5035 287.136 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 19.6075 7.2 \nL 420.5035 7.2 \n\" style=\"fill: none; stroke: #f0f0f0; stroke-width: 3; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa03fd7b439\">\n   <rect x=\"19.6075\" y=\"7.2\" width=\"400.896\" height=\"279.936\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(lr[:256], train_losses[:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
